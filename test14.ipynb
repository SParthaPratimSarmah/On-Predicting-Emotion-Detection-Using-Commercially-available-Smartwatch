{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 19:18:39.465129: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-24 19:18:39.518663: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 19:18:39.564752: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 19:18:39.586331: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 19:18:39.649574: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 19:18:41.629518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling: Counter({0: 5443, 3: 587, 5: 480, 4: 451, 8: 207, 7: 204, 6: 59, 1: 2, 2: 1})\n",
      "Class distribution after oversampling: Counter({0: 5443, 3: 5443, 7: 5443, 8: 5443, 4: 5443, 5: 5443, 6: 5443, 1: 5443, 2: 5443})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2024-09-24 19:18:44.943474: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - accuracy: 0.2775 - loss: 2.5913 - val_accuracy: 0.5250 - val_loss: 1.3850\n",
      "Epoch 2/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.4285 - loss: 1.8788 - val_accuracy: 0.5860 - val_loss: 1.2164\n",
      "Epoch 3/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.4609 - loss: 1.6650 - val_accuracy: 0.6246 - val_loss: 1.1177\n",
      "Epoch 4/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.4931 - loss: 1.5218 - val_accuracy: 0.6454 - val_loss: 1.0482\n",
      "Epoch 5/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.5137 - loss: 1.4198 - val_accuracy: 0.6689 - val_loss: 0.9918\n",
      "Epoch 6/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.5290 - loss: 1.3572 - val_accuracy: 0.6838 - val_loss: 0.9465\n",
      "Epoch 7/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.5507 - loss: 1.2881 - val_accuracy: 0.6962 - val_loss: 0.9076\n",
      "Epoch 8/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.5687 - loss: 1.2149 - val_accuracy: 0.7128 - val_loss: 0.8683\n",
      "Epoch 9/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.5765 - loss: 1.1842 - val_accuracy: 0.7233 - val_loss: 0.8392\n",
      "Epoch 10/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.5977 - loss: 1.1277 - val_accuracy: 0.7312 - val_loss: 0.8081\n",
      "Epoch 11/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.6036 - loss: 1.0990 - val_accuracy: 0.7379 - val_loss: 0.7820\n",
      "Epoch 12/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.6157 - loss: 1.0621 - val_accuracy: 0.7442 - val_loss: 0.7565\n",
      "Epoch 13/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6331 - loss: 1.0183 - val_accuracy: 0.7535 - val_loss: 0.7329\n",
      "Epoch 14/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6411 - loss: 0.9937 - val_accuracy: 0.7654 - val_loss: 0.7071\n",
      "Epoch 15/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6506 - loss: 0.9770 - val_accuracy: 0.7701 - val_loss: 0.6880\n",
      "Epoch 16/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.6588 - loss: 0.9490 - val_accuracy: 0.7755 - val_loss: 0.6663\n",
      "Epoch 17/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6635 - loss: 0.9301 - val_accuracy: 0.7826 - val_loss: 0.6484\n",
      "Epoch 18/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6783 - loss: 0.8981 - val_accuracy: 0.7901 - val_loss: 0.6259\n",
      "Epoch 19/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.6826 - loss: 0.8844 - val_accuracy: 0.7956 - val_loss: 0.6119\n",
      "Epoch 20/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6915 - loss: 0.8621 - val_accuracy: 0.8067 - val_loss: 0.5943\n",
      "Epoch 21/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.7006 - loss: 0.8388 - val_accuracy: 0.8105 - val_loss: 0.5786\n",
      "Epoch 22/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.6995 - loss: 0.8261 - val_accuracy: 0.8239 - val_loss: 0.5625\n",
      "Epoch 23/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.7072 - loss: 0.8073 - val_accuracy: 0.8210 - val_loss: 0.5476\n",
      "Epoch 24/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.7094 - loss: 0.8017 - val_accuracy: 0.8248 - val_loss: 0.5342\n",
      "Epoch 25/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.7187 - loss: 0.7855 - val_accuracy: 0.8336 - val_loss: 0.5173\n",
      "Epoch 26/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.7273 - loss: 0.7654 - val_accuracy: 0.8381 - val_loss: 0.5048\n",
      "Epoch 27/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.7279 - loss: 0.7553 - val_accuracy: 0.8394 - val_loss: 0.4950\n",
      "Epoch 28/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7372 - loss: 0.7374 - val_accuracy: 0.8440 - val_loss: 0.4830\n",
      "Epoch 29/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7440 - loss: 0.7244 - val_accuracy: 0.8436 - val_loss: 0.4729\n",
      "Epoch 30/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7437 - loss: 0.7173 - val_accuracy: 0.8487 - val_loss: 0.4624\n",
      "Epoch 31/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.7455 - loss: 0.7063 - val_accuracy: 0.8539 - val_loss: 0.4509\n",
      "Epoch 32/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.6946 - val_accuracy: 0.8589 - val_loss: 0.4408\n",
      "Epoch 33/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.7586 - loss: 0.6765 - val_accuracy: 0.8579 - val_loss: 0.4333\n",
      "Epoch 34/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.7609 - loss: 0.6743 - val_accuracy: 0.8657 - val_loss: 0.4219\n",
      "Epoch 35/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.7660 - loss: 0.6547 - val_accuracy: 0.8662 - val_loss: 0.4147\n",
      "Epoch 36/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.7648 - loss: 0.6576 - val_accuracy: 0.8722 - val_loss: 0.4050\n",
      "Epoch 37/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7725 - loss: 0.6472 - val_accuracy: 0.8755 - val_loss: 0.3956\n",
      "Epoch 38/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7753 - loss: 0.6338 - val_accuracy: 0.8780 - val_loss: 0.3899\n",
      "Epoch 39/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.7801 - loss: 0.6225 - val_accuracy: 0.8822 - val_loss: 0.3808\n",
      "Epoch 40/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.7841 - loss: 0.6116 - val_accuracy: 0.8858 - val_loss: 0.3750\n",
      "Epoch 41/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7810 - loss: 0.6091 - val_accuracy: 0.8875 - val_loss: 0.3686\n",
      "Epoch 42/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.7842 - loss: 0.6095 - val_accuracy: 0.8933 - val_loss: 0.3599\n",
      "Epoch 43/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.7928 - loss: 0.5856 - val_accuracy: 0.8886 - val_loss: 0.3558\n",
      "Epoch 44/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 24ms/step - accuracy: 0.7931 - loss: 0.5873 - val_accuracy: 0.8919 - val_loss: 0.3496\n",
      "Epoch 45/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.7877 - loss: 0.5911 - val_accuracy: 0.8951 - val_loss: 0.3438\n",
      "Epoch 46/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.7966 - loss: 0.5687 - val_accuracy: 0.8990 - val_loss: 0.3375\n",
      "Epoch 47/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.7973 - loss: 0.5729 - val_accuracy: 0.8988 - val_loss: 0.3287\n",
      "Epoch 48/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8010 - loss: 0.5602 - val_accuracy: 0.9014 - val_loss: 0.3231\n",
      "Epoch 49/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.7983 - loss: 0.5611 - val_accuracy: 0.9021 - val_loss: 0.3199\n",
      "Epoch 50/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.8057 - loss: 0.5454 - val_accuracy: 0.9053 - val_loss: 0.3150\n",
      "Epoch 51/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8058 - loss: 0.5436 - val_accuracy: 0.9069 - val_loss: 0.3120\n",
      "Epoch 52/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8109 - loss: 0.5384 - val_accuracy: 0.9092 - val_loss: 0.3060\n",
      "Epoch 53/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8116 - loss: 0.5364 - val_accuracy: 0.9061 - val_loss: 0.3023\n",
      "Epoch 54/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.8103 - loss: 0.5361 - val_accuracy: 0.9093 - val_loss: 0.2987\n",
      "Epoch 55/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8182 - loss: 0.5164 - val_accuracy: 0.9099 - val_loss: 0.2932\n",
      "Epoch 56/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8200 - loss: 0.5101 - val_accuracy: 0.9127 - val_loss: 0.2872\n",
      "Epoch 57/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8232 - loss: 0.5120 - val_accuracy: 0.9109 - val_loss: 0.2840\n",
      "Epoch 58/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8280 - loss: 0.5015 - val_accuracy: 0.9185 - val_loss: 0.2790\n",
      "Epoch 59/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8234 - loss: 0.4974 - val_accuracy: 0.9187 - val_loss: 0.2753\n",
      "Epoch 60/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8274 - loss: 0.4957 - val_accuracy: 0.9163 - val_loss: 0.2736\n",
      "Epoch 61/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8279 - loss: 0.4861 - val_accuracy: 0.9192 - val_loss: 0.2693\n",
      "Epoch 62/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8269 - loss: 0.4833 - val_accuracy: 0.9218 - val_loss: 0.2645\n",
      "Epoch 63/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8345 - loss: 0.4708 - val_accuracy: 0.9205 - val_loss: 0.2594\n",
      "Epoch 64/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8341 - loss: 0.4697 - val_accuracy: 0.9236 - val_loss: 0.2592\n",
      "Epoch 65/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8362 - loss: 0.4716 - val_accuracy: 0.9205 - val_loss: 0.2547\n",
      "Epoch 66/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8360 - loss: 0.4717 - val_accuracy: 0.9254 - val_loss: 0.2529\n",
      "Epoch 67/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.8346 - loss: 0.4708 - val_accuracy: 0.9288 - val_loss: 0.2492\n",
      "Epoch 68/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8402 - loss: 0.4604 - val_accuracy: 0.9293 - val_loss: 0.2455\n",
      "Epoch 69/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8385 - loss: 0.4668 - val_accuracy: 0.9247 - val_loss: 0.2459\n",
      "Epoch 70/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8460 - loss: 0.4439 - val_accuracy: 0.9278 - val_loss: 0.2388\n",
      "Epoch 71/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8436 - loss: 0.4467 - val_accuracy: 0.9325 - val_loss: 0.2374\n",
      "Epoch 72/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8405 - loss: 0.4494 - val_accuracy: 0.9315 - val_loss: 0.2344\n",
      "Epoch 73/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8447 - loss: 0.4471 - val_accuracy: 0.9308 - val_loss: 0.2323\n",
      "Epoch 74/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8394 - loss: 0.4456 - val_accuracy: 0.9310 - val_loss: 0.2316\n",
      "Epoch 75/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.8455 - loss: 0.4402 - val_accuracy: 0.9321 - val_loss: 0.2268\n",
      "Epoch 76/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8479 - loss: 0.4310 - val_accuracy: 0.9339 - val_loss: 0.2231\n",
      "Epoch 77/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8485 - loss: 0.4266 - val_accuracy: 0.9347 - val_loss: 0.2206\n",
      "Epoch 78/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.8502 - loss: 0.4374 - val_accuracy: 0.9361 - val_loss: 0.2196\n",
      "Epoch 79/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8505 - loss: 0.4198 - val_accuracy: 0.9367 - val_loss: 0.2181\n",
      "Epoch 80/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8540 - loss: 0.4168 - val_accuracy: 0.9405 - val_loss: 0.2145\n",
      "Epoch 81/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8542 - loss: 0.4130 - val_accuracy: 0.9382 - val_loss: 0.2131\n",
      "Epoch 82/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8542 - loss: 0.4184 - val_accuracy: 0.9388 - val_loss: 0.2119\n",
      "Epoch 83/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8549 - loss: 0.4107 - val_accuracy: 0.9405 - val_loss: 0.2088\n",
      "Epoch 84/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8564 - loss: 0.4139 - val_accuracy: 0.9403 - val_loss: 0.2091\n",
      "Epoch 85/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8580 - loss: 0.4025 - val_accuracy: 0.9439 - val_loss: 0.2047\n",
      "Epoch 86/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8600 - loss: 0.4042 - val_accuracy: 0.9409 - val_loss: 0.2041\n",
      "Epoch 87/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8612 - loss: 0.3977 - val_accuracy: 0.9421 - val_loss: 0.2024\n",
      "Epoch 88/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8616 - loss: 0.3995 - val_accuracy: 0.9419 - val_loss: 0.1987\n",
      "Epoch 89/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8625 - loss: 0.3932 - val_accuracy: 0.9455 - val_loss: 0.1979\n",
      "Epoch 90/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8633 - loss: 0.3887 - val_accuracy: 0.9453 - val_loss: 0.1960\n",
      "Epoch 91/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8649 - loss: 0.3889 - val_accuracy: 0.9450 - val_loss: 0.1949\n",
      "Epoch 92/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8623 - loss: 0.3957 - val_accuracy: 0.9467 - val_loss: 0.1916\n",
      "Epoch 93/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8617 - loss: 0.3964 - val_accuracy: 0.9449 - val_loss: 0.1908\n",
      "Epoch 94/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8646 - loss: 0.3848 - val_accuracy: 0.9442 - val_loss: 0.1882\n",
      "Epoch 95/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8673 - loss: 0.3840 - val_accuracy: 0.9476 - val_loss: 0.1869\n",
      "Epoch 96/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.8706 - loss: 0.3727 - val_accuracy: 0.9451 - val_loss: 0.1858\n",
      "Epoch 97/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8664 - loss: 0.3767 - val_accuracy: 0.9471 - val_loss: 0.1847\n",
      "Epoch 98/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8706 - loss: 0.3731 - val_accuracy: 0.9481 - val_loss: 0.1832\n",
      "Epoch 99/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8694 - loss: 0.3686 - val_accuracy: 0.9500 - val_loss: 0.1817\n",
      "Epoch 100/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8722 - loss: 0.3680 - val_accuracy: 0.9499 - val_loss: 0.1773\n",
      "Epoch 101/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8693 - loss: 0.3751 - val_accuracy: 0.9487 - val_loss: 0.1764\n",
      "Epoch 102/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8750 - loss: 0.3610 - val_accuracy: 0.9509 - val_loss: 0.1755\n",
      "Epoch 103/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8786 - loss: 0.3565 - val_accuracy: 0.9492 - val_loss: 0.1737\n",
      "Epoch 104/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8745 - loss: 0.3546 - val_accuracy: 0.9514 - val_loss: 0.1720\n",
      "Epoch 105/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8734 - loss: 0.3634 - val_accuracy: 0.9511 - val_loss: 0.1719\n",
      "Epoch 106/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8757 - loss: 0.3672 - val_accuracy: 0.9527 - val_loss: 0.1699\n",
      "Epoch 107/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8767 - loss: 0.3520 - val_accuracy: 0.9501 - val_loss: 0.1681\n",
      "Epoch 108/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8757 - loss: 0.3552 - val_accuracy: 0.9515 - val_loss: 0.1662\n",
      "Epoch 109/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8798 - loss: 0.3479 - val_accuracy: 0.9532 - val_loss: 0.1651\n",
      "Epoch 110/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8792 - loss: 0.3398 - val_accuracy: 0.9522 - val_loss: 0.1633\n",
      "Epoch 111/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8796 - loss: 0.3360 - val_accuracy: 0.9530 - val_loss: 0.1634\n",
      "Epoch 112/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8815 - loss: 0.3357 - val_accuracy: 0.9560 - val_loss: 0.1613\n",
      "Epoch 113/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8823 - loss: 0.3397 - val_accuracy: 0.9532 - val_loss: 0.1609\n",
      "Epoch 114/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8806 - loss: 0.3424 - val_accuracy: 0.9527 - val_loss: 0.1606\n",
      "Epoch 115/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8812 - loss: 0.3414 - val_accuracy: 0.9537 - val_loss: 0.1583\n",
      "Epoch 116/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8824 - loss: 0.3348 - val_accuracy: 0.9548 - val_loss: 0.1578\n",
      "Epoch 117/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8835 - loss: 0.3362 - val_accuracy: 0.9571 - val_loss: 0.1569\n",
      "Epoch 118/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8798 - loss: 0.3448 - val_accuracy: 0.9567 - val_loss: 0.1564\n",
      "Epoch 119/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8875 - loss: 0.3293 - val_accuracy: 0.9573 - val_loss: 0.1551\n",
      "Epoch 120/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8878 - loss: 0.3258 - val_accuracy: 0.9557 - val_loss: 0.1533\n",
      "Epoch 121/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8810 - loss: 0.3398 - val_accuracy: 0.9571 - val_loss: 0.1536\n",
      "Epoch 122/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.8864 - loss: 0.3289 - val_accuracy: 0.9593 - val_loss: 0.1517\n",
      "Epoch 123/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8824 - loss: 0.3285 - val_accuracy: 0.9556 - val_loss: 0.1517\n",
      "Epoch 124/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8903 - loss: 0.3204 - val_accuracy: 0.9553 - val_loss: 0.1532\n",
      "Epoch 125/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8880 - loss: 0.3253 - val_accuracy: 0.9576 - val_loss: 0.1486\n",
      "Epoch 126/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8906 - loss: 0.3229 - val_accuracy: 0.9574 - val_loss: 0.1489\n",
      "Epoch 127/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8916 - loss: 0.3181 - val_accuracy: 0.9573 - val_loss: 0.1472\n",
      "Epoch 128/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8889 - loss: 0.3281 - val_accuracy: 0.9598 - val_loss: 0.1461\n",
      "Epoch 129/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8909 - loss: 0.3170 - val_accuracy: 0.9597 - val_loss: 0.1449\n",
      "Epoch 130/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8888 - loss: 0.3203 - val_accuracy: 0.9582 - val_loss: 0.1450\n",
      "Epoch 131/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8938 - loss: 0.3077 - val_accuracy: 0.9598 - val_loss: 0.1443\n",
      "Epoch 132/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8915 - loss: 0.3151 - val_accuracy: 0.9615 - val_loss: 0.1431\n",
      "Epoch 133/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8919 - loss: 0.3085 - val_accuracy: 0.9604 - val_loss: 0.1425\n",
      "Epoch 134/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8893 - loss: 0.3201 - val_accuracy: 0.9606 - val_loss: 0.1415\n",
      "Epoch 135/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8901 - loss: 0.3139 - val_accuracy: 0.9622 - val_loss: 0.1391\n",
      "Epoch 136/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8942 - loss: 0.3103 - val_accuracy: 0.9598 - val_loss: 0.1411\n",
      "Epoch 137/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8896 - loss: 0.3202 - val_accuracy: 0.9608 - val_loss: 0.1394\n",
      "Epoch 138/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8958 - loss: 0.3074 - val_accuracy: 0.9620 - val_loss: 0.1394\n",
      "Epoch 139/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8936 - loss: 0.3054 - val_accuracy: 0.9622 - val_loss: 0.1380\n",
      "Epoch 140/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8972 - loss: 0.3028 - val_accuracy: 0.9631 - val_loss: 0.1360\n",
      "Epoch 141/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8961 - loss: 0.3021 - val_accuracy: 0.9622 - val_loss: 0.1362\n",
      "Epoch 142/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8966 - loss: 0.3001 - val_accuracy: 0.9626 - val_loss: 0.1355\n",
      "Epoch 143/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8967 - loss: 0.2951 - val_accuracy: 0.9626 - val_loss: 0.1351\n",
      "Epoch 144/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8984 - loss: 0.2968 - val_accuracy: 0.9613 - val_loss: 0.1344\n",
      "Epoch 145/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8965 - loss: 0.3003 - val_accuracy: 0.9630 - val_loss: 0.1338\n",
      "Epoch 146/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8992 - loss: 0.2918 - val_accuracy: 0.9639 - val_loss: 0.1312\n",
      "Epoch 147/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8942 - loss: 0.3108 - val_accuracy: 0.9636 - val_loss: 0.1307\n",
      "Epoch 148/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9005 - loss: 0.2906 - val_accuracy: 0.9633 - val_loss: 0.1319\n",
      "Epoch 149/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8997 - loss: 0.2935 - val_accuracy: 0.9659 - val_loss: 0.1309\n",
      "Epoch 150/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9046 - loss: 0.2892 - val_accuracy: 0.9647 - val_loss: 0.1307\n",
      "Epoch 151/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8986 - loss: 0.2931 - val_accuracy: 0.9656 - val_loss: 0.1293\n",
      "Epoch 152/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8983 - loss: 0.2911 - val_accuracy: 0.9636 - val_loss: 0.1299\n",
      "Epoch 153/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8999 - loss: 0.2884 - val_accuracy: 0.9634 - val_loss: 0.1284\n",
      "Epoch 154/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9012 - loss: 0.2921 - val_accuracy: 0.9654 - val_loss: 0.1279\n",
      "Epoch 155/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8969 - loss: 0.3004 - val_accuracy: 0.9668 - val_loss: 0.1257\n",
      "Epoch 156/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8966 - loss: 0.2948 - val_accuracy: 0.9677 - val_loss: 0.1252\n",
      "Epoch 157/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.9026 - loss: 0.2866 - val_accuracy: 0.9684 - val_loss: 0.1260\n",
      "Epoch 158/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9042 - loss: 0.2750 - val_accuracy: 0.9648 - val_loss: 0.1254\n",
      "Epoch 159/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.9018 - loss: 0.2845 - val_accuracy: 0.9657 - val_loss: 0.1252\n",
      "Epoch 160/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9021 - loss: 0.2778 - val_accuracy: 0.9691 - val_loss: 0.1236\n",
      "Epoch 161/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9035 - loss: 0.2859 - val_accuracy: 0.9686 - val_loss: 0.1229\n",
      "Epoch 162/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9014 - loss: 0.2768 - val_accuracy: 0.9678 - val_loss: 0.1226\n",
      "Epoch 163/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9040 - loss: 0.2767 - val_accuracy: 0.9654 - val_loss: 0.1219\n",
      "Epoch 164/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9001 - loss: 0.2884 - val_accuracy: 0.9663 - val_loss: 0.1224\n",
      "Epoch 165/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9031 - loss: 0.2835 - val_accuracy: 0.9667 - val_loss: 0.1216\n",
      "Epoch 166/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9036 - loss: 0.2768 - val_accuracy: 0.9650 - val_loss: 0.1212\n",
      "Epoch 167/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9069 - loss: 0.2779 - val_accuracy: 0.9639 - val_loss: 0.1216\n",
      "Epoch 168/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9064 - loss: 0.2713 - val_accuracy: 0.9654 - val_loss: 0.1189\n",
      "Epoch 169/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9077 - loss: 0.2643 - val_accuracy: 0.9667 - val_loss: 0.1184\n",
      "Epoch 170/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.2753 - val_accuracy: 0.9667 - val_loss: 0.1189\n",
      "Epoch 171/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9056 - loss: 0.2733 - val_accuracy: 0.9667 - val_loss: 0.1169\n",
      "Epoch 172/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9068 - loss: 0.2724 - val_accuracy: 0.9677 - val_loss: 0.1176\n",
      "Epoch 173/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9058 - loss: 0.2729 - val_accuracy: 0.9676 - val_loss: 0.1166\n",
      "Epoch 174/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9102 - loss: 0.2664 - val_accuracy: 0.9676 - val_loss: 0.1181\n",
      "Epoch 175/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9077 - loss: 0.2673 - val_accuracy: 0.9667 - val_loss: 0.1172\n",
      "Epoch 176/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9066 - loss: 0.2655 - val_accuracy: 0.9664 - val_loss: 0.1144\n",
      "Epoch 177/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9103 - loss: 0.2592 - val_accuracy: 0.9694 - val_loss: 0.1148\n",
      "Epoch 178/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9086 - loss: 0.2622 - val_accuracy: 0.9696 - val_loss: 0.1140\n",
      "Epoch 179/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9087 - loss: 0.2681 - val_accuracy: 0.9673 - val_loss: 0.1143\n",
      "Epoch 180/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9100 - loss: 0.2591 - val_accuracy: 0.9690 - val_loss: 0.1131\n",
      "Epoch 181/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9102 - loss: 0.2604 - val_accuracy: 0.9666 - val_loss: 0.1139\n",
      "Epoch 182/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9114 - loss: 0.2564 - val_accuracy: 0.9650 - val_loss: 0.1149\n",
      "Epoch 183/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9102 - loss: 0.2607 - val_accuracy: 0.9698 - val_loss: 0.1124\n",
      "Epoch 184/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9124 - loss: 0.2565 - val_accuracy: 0.9698 - val_loss: 0.1119\n",
      "Epoch 185/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.9094 - loss: 0.2621 - val_accuracy: 0.9695 - val_loss: 0.1118\n",
      "Epoch 186/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.9085 - loss: 0.2688 - val_accuracy: 0.9691 - val_loss: 0.1128\n",
      "Epoch 187/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.9112 - loss: 0.2603 - val_accuracy: 0.9684 - val_loss: 0.1126\n",
      "Epoch 188/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9115 - loss: 0.2616 - val_accuracy: 0.9675 - val_loss: 0.1127\n",
      "Epoch 189/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9134 - loss: 0.2539 - val_accuracy: 0.9682 - val_loss: 0.1109\n",
      "Epoch 190/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.9124 - loss: 0.2578 - val_accuracy: 0.9695 - val_loss: 0.1106\n",
      "Epoch 191/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9132 - loss: 0.2559 - val_accuracy: 0.9705 - val_loss: 0.1091\n",
      "Epoch 192/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9126 - loss: 0.2561 - val_accuracy: 0.9689 - val_loss: 0.1098\n",
      "Epoch 193/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9112 - loss: 0.2604 - val_accuracy: 0.9691 - val_loss: 0.1098\n",
      "Epoch 194/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9137 - loss: 0.2491 - val_accuracy: 0.9698 - val_loss: 0.1092\n",
      "Epoch 195/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9165 - loss: 0.2455 - val_accuracy: 0.9718 - val_loss: 0.1083\n",
      "Epoch 196/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.9090 - loss: 0.2620 - val_accuracy: 0.9685 - val_loss: 0.1087\n",
      "Epoch 197/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9165 - loss: 0.2486 - val_accuracy: 0.9708 - val_loss: 0.1083\n",
      "Epoch 198/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.9104 - loss: 0.2595 - val_accuracy: 0.9708 - val_loss: 0.1079\n",
      "Epoch 199/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9144 - loss: 0.2475 - val_accuracy: 0.9707 - val_loss: 0.1078\n",
      "Epoch 200/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9159 - loss: 0.2466 - val_accuracy: 0.9708 - val_loss: 0.1059\n",
      "Epoch 201/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9104 - loss: 0.2576 - val_accuracy: 0.9681 - val_loss: 0.1073\n",
      "Epoch 202/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9120 - loss: 0.2543 - val_accuracy: 0.9699 - val_loss: 0.1076\n",
      "Epoch 203/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9162 - loss: 0.2436 - val_accuracy: 0.9723 - val_loss: 0.1058\n",
      "Epoch 204/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9183 - loss: 0.2421 - val_accuracy: 0.9705 - val_loss: 0.1073\n",
      "Epoch 205/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9182 - loss: 0.2421 - val_accuracy: 0.9708 - val_loss: 0.1049\n",
      "Epoch 206/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9167 - loss: 0.2435 - val_accuracy: 0.9723 - val_loss: 0.1048\n",
      "Epoch 207/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9156 - loss: 0.2420 - val_accuracy: 0.9730 - val_loss: 0.1029\n",
      "Epoch 208/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9182 - loss: 0.2414 - val_accuracy: 0.9721 - val_loss: 0.1046\n",
      "Epoch 209/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9175 - loss: 0.2435 - val_accuracy: 0.9698 - val_loss: 0.1050\n",
      "Epoch 210/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 17ms/step - accuracy: 0.9158 - loss: 0.2462 - val_accuracy: 0.9698 - val_loss: 0.1055\n",
      "Epoch 211/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.9128 - loss: 0.2477 - val_accuracy: 0.9714 - val_loss: 0.1029\n",
      "Epoch 212/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.9149 - loss: 0.2410 - val_accuracy: 0.9730 - val_loss: 0.1039\n",
      "Epoch 213/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 24ms/step - accuracy: 0.9192 - loss: 0.2368 - val_accuracy: 0.9722 - val_loss: 0.1027\n",
      "Epoch 214/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9190 - loss: 0.2390 - val_accuracy: 0.9713 - val_loss: 0.1040\n",
      "Epoch 215/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9184 - loss: 0.2366 - val_accuracy: 0.9713 - val_loss: 0.1023\n",
      "Epoch 216/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9165 - loss: 0.2376 - val_accuracy: 0.9714 - val_loss: 0.1033\n",
      "Epoch 217/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9214 - loss: 0.2292 - val_accuracy: 0.9701 - val_loss: 0.1021\n",
      "Epoch 218/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9162 - loss: 0.2455 - val_accuracy: 0.9703 - val_loss: 0.1029\n",
      "Epoch 219/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9190 - loss: 0.2394 - val_accuracy: 0.9713 - val_loss: 0.1027\n",
      "Epoch 220/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9167 - loss: 0.2409 - val_accuracy: 0.9735 - val_loss: 0.1015\n",
      "Epoch 221/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9134 - loss: 0.2490 - val_accuracy: 0.9715 - val_loss: 0.1017\n",
      "Epoch 222/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9157 - loss: 0.2428 - val_accuracy: 0.9719 - val_loss: 0.1018\n",
      "Epoch 223/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9182 - loss: 0.2430 - val_accuracy: 0.9727 - val_loss: 0.1011\n",
      "Epoch 224/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9171 - loss: 0.2401 - val_accuracy: 0.9728 - val_loss: 0.1005\n",
      "Epoch 225/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.9162 - loss: 0.2469 - val_accuracy: 0.9738 - val_loss: 0.1002\n",
      "Epoch 226/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9184 - loss: 0.2326 - val_accuracy: 0.9708 - val_loss: 0.0987\n",
      "Epoch 227/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9173 - loss: 0.2406 - val_accuracy: 0.9700 - val_loss: 0.1004\n",
      "Epoch 228/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9184 - loss: 0.2431 - val_accuracy: 0.9731 - val_loss: 0.1001\n",
      "Epoch 229/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9209 - loss: 0.2319 - val_accuracy: 0.9721 - val_loss: 0.0988\n",
      "Epoch 230/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.9198 - loss: 0.2321 - val_accuracy: 0.9721 - val_loss: 0.0993\n",
      "Epoch 231/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9200 - loss: 0.2349 - val_accuracy: 0.9731 - val_loss: 0.0986\n",
      "Epoch 232/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9214 - loss: 0.2287 - val_accuracy: 0.9730 - val_loss: 0.0989\n",
      "Epoch 233/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9186 - loss: 0.2335 - val_accuracy: 0.9726 - val_loss: 0.0973\n",
      "Epoch 234/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9220 - loss: 0.2384 - val_accuracy: 0.9730 - val_loss: 0.0986\n",
      "Epoch 235/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9203 - loss: 0.2315 - val_accuracy: 0.9731 - val_loss: 0.0974\n",
      "Epoch 236/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9231 - loss: 0.2234 - val_accuracy: 0.9726 - val_loss: 0.0964\n",
      "Epoch 237/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9232 - loss: 0.2309 - val_accuracy: 0.9717 - val_loss: 0.0985\n",
      "Epoch 238/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9254 - loss: 0.2233 - val_accuracy: 0.9721 - val_loss: 0.0975\n",
      "Epoch 239/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9237 - loss: 0.2225 - val_accuracy: 0.9727 - val_loss: 0.0955\n",
      "Epoch 240/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9239 - loss: 0.2272 - val_accuracy: 0.9741 - val_loss: 0.0970\n",
      "Epoch 241/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9210 - loss: 0.2326 - val_accuracy: 0.9736 - val_loss: 0.0956\n",
      "Epoch 242/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.9230 - loss: 0.2236 - val_accuracy: 0.9736 - val_loss: 0.0967\n",
      "Epoch 243/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.9229 - loss: 0.2299 - val_accuracy: 0.9728 - val_loss: 0.0967\n",
      "Epoch 244/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9194 - loss: 0.2386 - val_accuracy: 0.9741 - val_loss: 0.0965\n",
      "Epoch 245/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9214 - loss: 0.2290 - val_accuracy: 0.9745 - val_loss: 0.0956\n",
      "Epoch 246/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9232 - loss: 0.2228 - val_accuracy: 0.9742 - val_loss: 0.0953\n",
      "Epoch 247/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9251 - loss: 0.2214 - val_accuracy: 0.9730 - val_loss: 0.0954\n",
      "Epoch 248/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9196 - loss: 0.2311 - val_accuracy: 0.9717 - val_loss: 0.0970\n",
      "Epoch 249/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9198 - loss: 0.2345 - val_accuracy: 0.9727 - val_loss: 0.0955\n",
      "Epoch 250/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9259 - loss: 0.2160 - val_accuracy: 0.9741 - val_loss: 0.0952\n",
      "Epoch 251/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9261 - loss: 0.2174 - val_accuracy: 0.9731 - val_loss: 0.0939\n",
      "Epoch 252/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9221 - loss: 0.2278 - val_accuracy: 0.9745 - val_loss: 0.0948\n",
      "Epoch 253/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9256 - loss: 0.2200 - val_accuracy: 0.9741 - val_loss: 0.0951\n",
      "Epoch 254/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9236 - loss: 0.2228 - val_accuracy: 0.9742 - val_loss: 0.0949\n",
      "Epoch 255/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9272 - loss: 0.2102 - val_accuracy: 0.9747 - val_loss: 0.0943\n",
      "Epoch 256/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9225 - loss: 0.2251 - val_accuracy: 0.9745 - val_loss: 0.0933\n",
      "Epoch 257/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9257 - loss: 0.2168 - val_accuracy: 0.9744 - val_loss: 0.0954\n",
      "Epoch 258/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9249 - loss: 0.2207 - val_accuracy: 0.9732 - val_loss: 0.0935\n",
      "Epoch 259/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 22ms/step - accuracy: 0.9267 - loss: 0.2136 - val_accuracy: 0.9724 - val_loss: 0.0944\n",
      "Epoch 260/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9247 - loss: 0.2178 - val_accuracy: 0.9735 - val_loss: 0.0946\n",
      "Epoch 261/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9226 - loss: 0.2250 - val_accuracy: 0.9737 - val_loss: 0.0934\n",
      "Epoch 262/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9241 - loss: 0.2167 - val_accuracy: 0.9740 - val_loss: 0.0935\n",
      "Epoch 263/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9260 - loss: 0.2122 - val_accuracy: 0.9733 - val_loss: 0.0941\n",
      "Epoch 264/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.9250 - loss: 0.2177 - val_accuracy: 0.9742 - val_loss: 0.0918\n",
      "Epoch 265/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9248 - loss: 0.2163 - val_accuracy: 0.9730 - val_loss: 0.0926\n",
      "Epoch 266/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9244 - loss: 0.2218 - val_accuracy: 0.9744 - val_loss: 0.0934\n",
      "Epoch 267/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9285 - loss: 0.2115 - val_accuracy: 0.9730 - val_loss: 0.0944\n",
      "Epoch 268/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9238 - loss: 0.2174 - val_accuracy: 0.9749 - val_loss: 0.0915\n",
      "Epoch 269/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9275 - loss: 0.2127 - val_accuracy: 0.9731 - val_loss: 0.0932\n",
      "Epoch 270/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9261 - loss: 0.2182 - val_accuracy: 0.9740 - val_loss: 0.0944\n",
      "Epoch 271/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9238 - loss: 0.2236 - val_accuracy: 0.9732 - val_loss: 0.0915\n",
      "Epoch 272/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9286 - loss: 0.2125 - val_accuracy: 0.9726 - val_loss: 0.0918\n",
      "Epoch 273/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9255 - loss: 0.2168 - val_accuracy: 0.9744 - val_loss: 0.0932\n",
      "Epoch 274/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9278 - loss: 0.2098 - val_accuracy: 0.9749 - val_loss: 0.0919\n",
      "Epoch 275/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9297 - loss: 0.2105 - val_accuracy: 0.9728 - val_loss: 0.0915\n",
      "Epoch 276/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9288 - loss: 0.2105 - val_accuracy: 0.9752 - val_loss: 0.0924\n",
      "Epoch 277/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9283 - loss: 0.2143 - val_accuracy: 0.9747 - val_loss: 0.0905\n",
      "Epoch 278/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 24ms/step - accuracy: 0.9277 - loss: 0.2150 - val_accuracy: 0.9754 - val_loss: 0.0908\n",
      "Epoch 279/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9275 - loss: 0.2112 - val_accuracy: 0.9747 - val_loss: 0.0916\n",
      "Epoch 280/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9262 - loss: 0.2118 - val_accuracy: 0.9742 - val_loss: 0.0921\n",
      "Epoch 281/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.9271 - loss: 0.2193 - val_accuracy: 0.9747 - val_loss: 0.0919\n",
      "Epoch 282/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9286 - loss: 0.2102 - val_accuracy: 0.9735 - val_loss: 0.0910\n",
      "Epoch 283/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9250 - loss: 0.2112 - val_accuracy: 0.9737 - val_loss: 0.0921\n",
      "Epoch 284/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9311 - loss: 0.2008 - val_accuracy: 0.9756 - val_loss: 0.0910\n",
      "Epoch 285/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9260 - loss: 0.2131 - val_accuracy: 0.9742 - val_loss: 0.0902\n",
      "Epoch 286/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9259 - loss: 0.2157 - val_accuracy: 0.9741 - val_loss: 0.0919\n",
      "Epoch 287/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9276 - loss: 0.2127 - val_accuracy: 0.9742 - val_loss: 0.0898\n",
      "Epoch 288/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9308 - loss: 0.2088 - val_accuracy: 0.9751 - val_loss: 0.0907\n",
      "Epoch 289/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9280 - loss: 0.2138 - val_accuracy: 0.9737 - val_loss: 0.0901\n",
      "Epoch 290/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9294 - loss: 0.2084 - val_accuracy: 0.9764 - val_loss: 0.0903\n",
      "Epoch 291/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9277 - loss: 0.2082 - val_accuracy: 0.9750 - val_loss: 0.0898\n",
      "Epoch 292/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9301 - loss: 0.2071 - val_accuracy: 0.9751 - val_loss: 0.0894\n",
      "Epoch 293/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9264 - loss: 0.2108 - val_accuracy: 0.9764 - val_loss: 0.0902\n",
      "Epoch 294/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9293 - loss: 0.2098 - val_accuracy: 0.9749 - val_loss: 0.0903\n",
      "Epoch 295/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9280 - loss: 0.2043 - val_accuracy: 0.9754 - val_loss: 0.0894\n",
      "Epoch 296/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9321 - loss: 0.2037 - val_accuracy: 0.9760 - val_loss: 0.0889\n",
      "Epoch 297/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9316 - loss: 0.2041 - val_accuracy: 0.9763 - val_loss: 0.0890\n",
      "Epoch 298/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9276 - loss: 0.2068 - val_accuracy: 0.9746 - val_loss: 0.0892\n",
      "Epoch 299/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9265 - loss: 0.2125 - val_accuracy: 0.9756 - val_loss: 0.0888\n",
      "Epoch 300/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9290 - loss: 0.2028 - val_accuracy: 0.9755 - val_loss: 0.0889\n",
      "Epoch 301/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9300 - loss: 0.2066 - val_accuracy: 0.9752 - val_loss: 0.0886\n",
      "Epoch 302/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - accuracy: 0.9326 - loss: 0.1989 - val_accuracy: 0.9755 - val_loss: 0.0883\n",
      "Epoch 303/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.9288 - loss: 0.2087 - val_accuracy: 0.9751 - val_loss: 0.0886\n",
      "Epoch 304/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.9289 - loss: 0.2080 - val_accuracy: 0.9746 - val_loss: 0.0871\n",
      "Epoch 305/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.9256 - loss: 0.2109 - val_accuracy: 0.9764 - val_loss: 0.0887\n",
      "Epoch 306/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.9284 - loss: 0.2063 - val_accuracy: 0.9763 - val_loss: 0.0874\n",
      "Epoch 307/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9307 - loss: 0.1986 - val_accuracy: 0.9740 - val_loss: 0.0882\n",
      "Epoch 308/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9342 - loss: 0.1912 - val_accuracy: 0.9741 - val_loss: 0.0875\n",
      "Epoch 309/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9291 - loss: 0.2057 - val_accuracy: 0.9751 - val_loss: 0.0880\n",
      "Epoch 310/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9325 - loss: 0.1989 - val_accuracy: 0.9760 - val_loss: 0.0864\n",
      "Epoch 311/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9294 - loss: 0.2022 - val_accuracy: 0.9759 - val_loss: 0.0874\n",
      "Epoch 312/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9314 - loss: 0.1952 - val_accuracy: 0.9750 - val_loss: 0.0874\n",
      "Epoch 313/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9308 - loss: 0.1996 - val_accuracy: 0.9752 - val_loss: 0.0876\n",
      "Epoch 314/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9336 - loss: 0.2010 - val_accuracy: 0.9744 - val_loss: 0.0867\n",
      "Epoch 315/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9316 - loss: 0.2020 - val_accuracy: 0.9741 - val_loss: 0.0870\n",
      "Epoch 316/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9265 - loss: 0.2090 - val_accuracy: 0.9767 - val_loss: 0.0854\n",
      "Epoch 317/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9327 - loss: 0.1960 - val_accuracy: 0.9747 - val_loss: 0.0871\n",
      "Epoch 318/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9312 - loss: 0.2042 - val_accuracy: 0.9747 - val_loss: 0.0866\n",
      "Epoch 319/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9315 - loss: 0.2034 - val_accuracy: 0.9742 - val_loss: 0.0875\n",
      "Epoch 320/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9289 - loss: 0.1993 - val_accuracy: 0.9768 - val_loss: 0.0853\n",
      "Epoch 321/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9300 - loss: 0.1975 - val_accuracy: 0.9750 - val_loss: 0.0874\n",
      "Epoch 322/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9308 - loss: 0.2010 - val_accuracy: 0.9751 - val_loss: 0.0871\n",
      "Epoch 323/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9270 - loss: 0.2062 - val_accuracy: 0.9755 - val_loss: 0.0855\n",
      "Epoch 324/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9338 - loss: 0.1973 - val_accuracy: 0.9758 - val_loss: 0.0857\n",
      "Epoch 325/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9321 - loss: 0.1934 - val_accuracy: 0.9752 - val_loss: 0.0870\n",
      "Epoch 326/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.9310 - loss: 0.2022 - val_accuracy: 0.9751 - val_loss: 0.0856\n",
      "Epoch 327/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9331 - loss: 0.1977 - val_accuracy: 0.9759 - val_loss: 0.0854\n",
      "Epoch 328/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9317 - loss: 0.1994 - val_accuracy: 0.9758 - val_loss: 0.0854\n",
      "Epoch 329/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.9323 - loss: 0.1975 - val_accuracy: 0.9756 - val_loss: 0.0852\n",
      "Epoch 330/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9338 - loss: 0.1934 - val_accuracy: 0.9763 - val_loss: 0.0848\n",
      "Epoch 331/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9330 - loss: 0.1980 - val_accuracy: 0.9755 - val_loss: 0.0854\n",
      "Epoch 332/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9334 - loss: 0.1946 - val_accuracy: 0.9751 - val_loss: 0.0852\n",
      "Epoch 333/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9316 - loss: 0.1983 - val_accuracy: 0.9747 - val_loss: 0.0852\n",
      "Epoch 334/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.9315 - loss: 0.1927 - val_accuracy: 0.9755 - val_loss: 0.0855\n",
      "Epoch 335/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9344 - loss: 0.1948 - val_accuracy: 0.9765 - val_loss: 0.0846\n",
      "Epoch 336/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9333 - loss: 0.1936 - val_accuracy: 0.9754 - val_loss: 0.0859\n",
      "Epoch 337/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9336 - loss: 0.1908 - val_accuracy: 0.9749 - val_loss: 0.0859\n",
      "Epoch 338/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9339 - loss: 0.1955 - val_accuracy: 0.9758 - val_loss: 0.0840\n",
      "Epoch 339/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9263 - loss: 0.2107 - val_accuracy: 0.9750 - val_loss: 0.0849\n",
      "Epoch 340/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9331 - loss: 0.1922 - val_accuracy: 0.9758 - val_loss: 0.0845\n",
      "Epoch 341/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9330 - loss: 0.1995 - val_accuracy: 0.9761 - val_loss: 0.0844\n",
      "Epoch 342/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9319 - loss: 0.1951 - val_accuracy: 0.9752 - val_loss: 0.0834\n",
      "Epoch 343/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9337 - loss: 0.1909 - val_accuracy: 0.9751 - val_loss: 0.0855\n",
      "Epoch 344/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.9343 - loss: 0.1941 - val_accuracy: 0.9755 - val_loss: 0.0845\n",
      "Epoch 345/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9331 - loss: 0.1997 - val_accuracy: 0.9746 - val_loss: 0.0834\n",
      "Epoch 346/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9328 - loss: 0.1975 - val_accuracy: 0.9759 - val_loss: 0.0826\n",
      "Epoch 347/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9313 - loss: 0.1942 - val_accuracy: 0.9747 - val_loss: 0.0852\n",
      "Epoch 348/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9328 - loss: 0.2012 - val_accuracy: 0.9761 - val_loss: 0.0841\n",
      "Epoch 349/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9365 - loss: 0.1890 - val_accuracy: 0.9759 - val_loss: 0.0836\n",
      "Epoch 350/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9326 - loss: 0.1926 - val_accuracy: 0.9752 - val_loss: 0.0839\n",
      "Epoch 351/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9300 - loss: 0.2018 - val_accuracy: 0.9742 - val_loss: 0.0847\n",
      "Epoch 352/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9334 - loss: 0.1948 - val_accuracy: 0.9752 - val_loss: 0.0836\n",
      "Epoch 353/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9313 - loss: 0.1980 - val_accuracy: 0.9751 - val_loss: 0.0838\n",
      "Epoch 354/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9343 - loss: 0.1871 - val_accuracy: 0.9749 - val_loss: 0.0833\n",
      "Epoch 355/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9355 - loss: 0.1896 - val_accuracy: 0.9768 - val_loss: 0.0838\n",
      "Epoch 356/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9343 - loss: 0.1924 - val_accuracy: 0.9751 - val_loss: 0.0841\n",
      "Epoch 357/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9324 - loss: 0.1990 - val_accuracy: 0.9758 - val_loss: 0.0839\n",
      "Epoch 358/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9363 - loss: 0.1868 - val_accuracy: 0.9758 - val_loss: 0.0839\n",
      "Epoch 359/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9311 - loss: 0.2070 - val_accuracy: 0.9760 - val_loss: 0.0837\n",
      "Epoch 360/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9337 - loss: 0.1925 - val_accuracy: 0.9769 - val_loss: 0.0814\n",
      "Epoch 361/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9361 - loss: 0.1918 - val_accuracy: 0.9761 - val_loss: 0.0836\n",
      "Epoch 362/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9363 - loss: 0.1859 - val_accuracy: 0.9767 - val_loss: 0.0835\n",
      "Epoch 363/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9392 - loss: 0.1802 - val_accuracy: 0.9764 - val_loss: 0.0822\n",
      "Epoch 364/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9350 - loss: 0.1885 - val_accuracy: 0.9767 - val_loss: 0.0821\n",
      "Epoch 365/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9341 - loss: 0.1951 - val_accuracy: 0.9759 - val_loss: 0.0822\n",
      "Epoch 366/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9329 - loss: 0.1968 - val_accuracy: 0.9764 - val_loss: 0.0818\n",
      "Epoch 367/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9341 - loss: 0.1907 - val_accuracy: 0.9769 - val_loss: 0.0819\n",
      "Epoch 368/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9368 - loss: 0.1801 - val_accuracy: 0.9760 - val_loss: 0.0831\n",
      "Epoch 369/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9344 - loss: 0.1922 - val_accuracy: 0.9763 - val_loss: 0.0826\n",
      "Epoch 370/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9368 - loss: 0.1824 - val_accuracy: 0.9777 - val_loss: 0.0814\n",
      "Epoch 371/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9362 - loss: 0.1827 - val_accuracy: 0.9756 - val_loss: 0.0821\n",
      "Epoch 372/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9370 - loss: 0.1862 - val_accuracy: 0.9765 - val_loss: 0.0817\n",
      "Epoch 373/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9343 - loss: 0.1931 - val_accuracy: 0.9767 - val_loss: 0.0818\n",
      "Epoch 374/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9374 - loss: 0.1831 - val_accuracy: 0.9751 - val_loss: 0.0832\n",
      "Epoch 375/1000\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9367 - loss: 0.1849 - val_accuracy: 0.9756 - val_loss: 0.0832\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9812 - loss: 0.0611\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9777 - loss: 0.0783\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9692 - loss: 0.0974\n",
      "Training Accuracy: 98.11%\n",
      "Validation Accuracy: 97.69%\n",
      "Test Accuracy: 96.90%\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
      "Test Accuracy with emotion labels: 96.90%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler  # Using RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Raw_MAIN_DATASET_IMPUTATION_after_deleting_stai_badge_activity_step_goal.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "df = df.drop(['id', 'date'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Emotions', axis=1)\n",
    "y = df['Emotions']\n",
    "\n",
    "# Convert categorical target to numeric using label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Check the initial class distribution\n",
    "print(\"Class distribution before oversampling:\", Counter(y))\n",
    "\n",
    "# Oversampling to handle class imbalance using RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after oversampling\n",
    "print(\"Class distribution after oversampling:\", Counter(y))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Feature Selection\n",
    "selector = SelectKBest(f_classif, k=60)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_val = selector.transform(X_val)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  # Output layer (number of unique emotions)\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=1000,  # Increased epochs\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Convert numeric predictions back to emotion labels\n",
    "y_test_pred_labels = le.inverse_transform(y_test_pred_classes)\n",
    "y_test_true_labels = le.inverse_transform(y_test)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "test_acc = accuracy_score(y_test_true_labels, y_test_pred_labels)\n",
    "print(f\"Test Accuracy with emotion labels: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling: Counter({0: 5443, 3: 587, 5: 480, 4: 451, 8: 207, 7: 204, 6: 59, 1: 2, 2: 1})\n",
      "Class distribution after oversampling: Counter({0: 5443, 3: 5443, 7: 5443, 8: 5443, 4: 5443, 5: 5443, 6: 5443, 1: 5443, 2: 5443})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.2916 - loss: 2.5218 - val_accuracy: 0.4816 - val_loss: 1.4554\n",
      "Epoch 2/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.4244 - loss: 1.8520 - val_accuracy: 0.5515 - val_loss: 1.2614\n",
      "Epoch 3/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 32ms/step - accuracy: 0.4601 - loss: 1.6437 - val_accuracy: 0.5911 - val_loss: 1.1494\n",
      "Epoch 4/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.5012 - loss: 1.4938 - val_accuracy: 0.6277 - val_loss: 1.0724\n",
      "Epoch 5/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.5150 - loss: 1.4020 - val_accuracy: 0.6442 - val_loss: 1.0173\n",
      "Epoch 6/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.5343 - loss: 1.3265 - val_accuracy: 0.6660 - val_loss: 0.9651\n",
      "Epoch 7/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - accuracy: 0.5537 - loss: 1.2643 - val_accuracy: 0.6870 - val_loss: 0.9224\n",
      "Epoch 8/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.5673 - loss: 1.2140 - val_accuracy: 0.7050 - val_loss: 0.8867\n",
      "Epoch 9/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.5831 - loss: 1.1682 - val_accuracy: 0.7151 - val_loss: 0.8529\n",
      "Epoch 10/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.6001 - loss: 1.1237 - val_accuracy: 0.7237 - val_loss: 0.8247\n",
      "Epoch 11/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.6142 - loss: 1.0707 - val_accuracy: 0.7349 - val_loss: 0.7949\n",
      "Epoch 12/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.6218 - loss: 1.0546 - val_accuracy: 0.7442 - val_loss: 0.7645\n",
      "Epoch 13/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.6320 - loss: 1.0183 - val_accuracy: 0.7581 - val_loss: 0.7374\n",
      "Epoch 14/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.6402 - loss: 0.9976 - val_accuracy: 0.7638 - val_loss: 0.7162\n",
      "Epoch 15/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.6558 - loss: 0.9558 - val_accuracy: 0.7721 - val_loss: 0.6918\n",
      "Epoch 16/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.6575 - loss: 0.9432 - val_accuracy: 0.7788 - val_loss: 0.6712\n",
      "Epoch 17/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.6669 - loss: 0.9223 - val_accuracy: 0.7860 - val_loss: 0.6503\n",
      "Epoch 18/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.6789 - loss: 0.8937 - val_accuracy: 0.7932 - val_loss: 0.6313\n",
      "Epoch 19/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.6858 - loss: 0.8820 - val_accuracy: 0.7975 - val_loss: 0.6140\n",
      "Epoch 20/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.6911 - loss: 0.8547 - val_accuracy: 0.8020 - val_loss: 0.5993\n",
      "Epoch 21/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.6953 - loss: 0.8451 - val_accuracy: 0.8104 - val_loss: 0.5801\n",
      "Epoch 22/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7125 - loss: 0.8087 - val_accuracy: 0.8150 - val_loss: 0.5620\n",
      "Epoch 23/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.7108 - loss: 0.8014 - val_accuracy: 0.8150 - val_loss: 0.5477\n",
      "Epoch 24/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.7257 - loss: 0.7775 - val_accuracy: 0.8237 - val_loss: 0.5328\n",
      "Epoch 25/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.7234 - loss: 0.7710 - val_accuracy: 0.8308 - val_loss: 0.5201\n",
      "Epoch 26/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.7208 - loss: 0.7719 - val_accuracy: 0.8366 - val_loss: 0.5082\n",
      "Epoch 27/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7368 - loss: 0.7365 - val_accuracy: 0.8415 - val_loss: 0.4940\n",
      "Epoch 28/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.7361 - loss: 0.7390 - val_accuracy: 0.8433 - val_loss: 0.4797\n",
      "Epoch 29/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7465 - loss: 0.7130 - val_accuracy: 0.8464 - val_loss: 0.4700\n",
      "Epoch 30/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.7442 - loss: 0.7084 - val_accuracy: 0.8511 - val_loss: 0.4607\n",
      "Epoch 31/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.7531 - loss: 0.6911 - val_accuracy: 0.8579 - val_loss: 0.4509\n",
      "Epoch 32/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.7559 - loss: 0.6815 - val_accuracy: 0.8588 - val_loss: 0.4394\n",
      "Epoch 33/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.7586 - loss: 0.6800 - val_accuracy: 0.8606 - val_loss: 0.4319\n",
      "Epoch 34/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.7693 - loss: 0.6502 - val_accuracy: 0.8655 - val_loss: 0.4218\n",
      "Epoch 35/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 38ms/step - accuracy: 0.7669 - loss: 0.6581 - val_accuracy: 0.8668 - val_loss: 0.4153\n",
      "Epoch 36/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.7658 - loss: 0.6463 - val_accuracy: 0.8720 - val_loss: 0.4057\n",
      "Epoch 37/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 38ms/step - accuracy: 0.7691 - loss: 0.6482 - val_accuracy: 0.8756 - val_loss: 0.3970\n",
      "Epoch 38/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.7825 - loss: 0.6191 - val_accuracy: 0.8762 - val_loss: 0.3911\n",
      "Epoch 39/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.7788 - loss: 0.6156 - val_accuracy: 0.8791 - val_loss: 0.3826\n",
      "Epoch 40/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.7839 - loss: 0.6118 - val_accuracy: 0.8847 - val_loss: 0.3744\n",
      "Epoch 41/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.7875 - loss: 0.5994 - val_accuracy: 0.8835 - val_loss: 0.3678\n",
      "Epoch 42/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.7855 - loss: 0.5941 - val_accuracy: 0.8905 - val_loss: 0.3601\n",
      "Epoch 43/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.7912 - loss: 0.5897 - val_accuracy: 0.8916 - val_loss: 0.3545\n",
      "Epoch 44/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.7912 - loss: 0.5899 - val_accuracy: 0.8949 - val_loss: 0.3463\n",
      "Epoch 45/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.8035 - loss: 0.5599 - val_accuracy: 0.8953 - val_loss: 0.3417\n",
      "Epoch 46/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.7990 - loss: 0.5708 - val_accuracy: 0.8961 - val_loss: 0.3379\n",
      "Epoch 47/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.7992 - loss: 0.5640 - val_accuracy: 0.9011 - val_loss: 0.3308\n",
      "Epoch 48/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8026 - loss: 0.5546 - val_accuracy: 0.9013 - val_loss: 0.3251\n",
      "Epoch 49/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.8059 - loss: 0.5509 - val_accuracy: 0.9014 - val_loss: 0.3208\n",
      "Epoch 50/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8079 - loss: 0.5392 - val_accuracy: 0.9029 - val_loss: 0.3158\n",
      "Epoch 51/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8097 - loss: 0.5407 - val_accuracy: 0.9050 - val_loss: 0.3098\n",
      "Epoch 52/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.8180 - loss: 0.5244 - val_accuracy: 0.9104 - val_loss: 0.3045\n",
      "Epoch 53/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.8140 - loss: 0.5316 - val_accuracy: 0.9070 - val_loss: 0.3017\n",
      "Epoch 54/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.8093 - loss: 0.5292 - val_accuracy: 0.9098 - val_loss: 0.2965\n",
      "Epoch 55/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8147 - loss: 0.5140 - val_accuracy: 0.9103 - val_loss: 0.2926\n",
      "Epoch 56/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8193 - loss: 0.5070 - val_accuracy: 0.9104 - val_loss: 0.2862\n",
      "Epoch 57/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8179 - loss: 0.5210 - val_accuracy: 0.9131 - val_loss: 0.2833\n",
      "Epoch 58/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.8223 - loss: 0.4941 - val_accuracy: 0.9150 - val_loss: 0.2803\n",
      "Epoch 59/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8257 - loss: 0.4904 - val_accuracy: 0.9187 - val_loss: 0.2755\n",
      "Epoch 60/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.8268 - loss: 0.4862 - val_accuracy: 0.9190 - val_loss: 0.2717\n",
      "Epoch 61/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8281 - loss: 0.4941 - val_accuracy: 0.9218 - val_loss: 0.2680\n",
      "Epoch 62/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8282 - loss: 0.4849 - val_accuracy: 0.9200 - val_loss: 0.2651\n",
      "Epoch 63/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8313 - loss: 0.4797 - val_accuracy: 0.9260 - val_loss: 0.2614\n",
      "Epoch 64/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.8305 - loss: 0.4783 - val_accuracy: 0.9251 - val_loss: 0.2574\n",
      "Epoch 65/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.8387 - loss: 0.4624 - val_accuracy: 0.9246 - val_loss: 0.2550\n",
      "Epoch 66/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8364 - loss: 0.4670 - val_accuracy: 0.9252 - val_loss: 0.2515\n",
      "Epoch 67/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8360 - loss: 0.4678 - val_accuracy: 0.9268 - val_loss: 0.2485\n",
      "Epoch 68/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8348 - loss: 0.4646 - val_accuracy: 0.9297 - val_loss: 0.2463\n",
      "Epoch 69/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.8425 - loss: 0.4531 - val_accuracy: 0.9266 - val_loss: 0.2434\n",
      "Epoch 70/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.8399 - loss: 0.4551 - val_accuracy: 0.9292 - val_loss: 0.2388\n",
      "Epoch 71/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.8384 - loss: 0.4523 - val_accuracy: 0.9323 - val_loss: 0.2354\n",
      "Epoch 72/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8457 - loss: 0.4371 - val_accuracy: 0.9315 - val_loss: 0.2336\n",
      "Epoch 73/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8464 - loss: 0.4421 - val_accuracy: 0.9328 - val_loss: 0.2314\n",
      "Epoch 74/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.8468 - loss: 0.4366 - val_accuracy: 0.9317 - val_loss: 0.2277\n",
      "Epoch 75/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8464 - loss: 0.4414 - val_accuracy: 0.9370 - val_loss: 0.2260\n",
      "Epoch 76/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8475 - loss: 0.4308 - val_accuracy: 0.9372 - val_loss: 0.2227\n",
      "Epoch 77/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8452 - loss: 0.4366 - val_accuracy: 0.9363 - val_loss: 0.2206\n",
      "Epoch 78/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8524 - loss: 0.4190 - val_accuracy: 0.9344 - val_loss: 0.2189\n",
      "Epoch 79/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8492 - loss: 0.4237 - val_accuracy: 0.9370 - val_loss: 0.2171\n",
      "Epoch 80/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.8569 - loss: 0.4104 - val_accuracy: 0.9384 - val_loss: 0.2140\n",
      "Epoch 81/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.8541 - loss: 0.4216 - val_accuracy: 0.9397 - val_loss: 0.2120\n",
      "Epoch 82/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8564 - loss: 0.4097 - val_accuracy: 0.9409 - val_loss: 0.2110\n",
      "Epoch 83/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8571 - loss: 0.4065 - val_accuracy: 0.9397 - val_loss: 0.2087\n",
      "Epoch 84/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8558 - loss: 0.4108 - val_accuracy: 0.9405 - val_loss: 0.2077\n",
      "Epoch 85/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8594 - loss: 0.4017 - val_accuracy: 0.9413 - val_loss: 0.2059\n",
      "Epoch 86/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8608 - loss: 0.4019 - val_accuracy: 0.9436 - val_loss: 0.2016\n",
      "Epoch 87/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8550 - loss: 0.4072 - val_accuracy: 0.9442 - val_loss: 0.2020\n",
      "Epoch 88/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8604 - loss: 0.3971 - val_accuracy: 0.9432 - val_loss: 0.1995\n",
      "Epoch 89/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8629 - loss: 0.3905 - val_accuracy: 0.9439 - val_loss: 0.1970\n",
      "Epoch 90/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8634 - loss: 0.3929 - val_accuracy: 0.9448 - val_loss: 0.1947\n",
      "Epoch 91/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8637 - loss: 0.3912 - val_accuracy: 0.9460 - val_loss: 0.1916\n",
      "Epoch 92/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8668 - loss: 0.3839 - val_accuracy: 0.9458 - val_loss: 0.1902\n",
      "Epoch 93/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8673 - loss: 0.3843 - val_accuracy: 0.9450 - val_loss: 0.1890\n",
      "Epoch 94/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8681 - loss: 0.3819 - val_accuracy: 0.9465 - val_loss: 0.1895\n",
      "Epoch 95/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8699 - loss: 0.3735 - val_accuracy: 0.9448 - val_loss: 0.1870\n",
      "Epoch 96/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8697 - loss: 0.3739 - val_accuracy: 0.9469 - val_loss: 0.1860\n",
      "Epoch 97/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8671 - loss: 0.3749 - val_accuracy: 0.9467 - val_loss: 0.1812\n",
      "Epoch 98/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8691 - loss: 0.3746 - val_accuracy: 0.9497 - val_loss: 0.1812\n",
      "Epoch 99/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8704 - loss: 0.3758 - val_accuracy: 0.9491 - val_loss: 0.1804\n",
      "Epoch 100/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8682 - loss: 0.3740 - val_accuracy: 0.9500 - val_loss: 0.1788\n",
      "Epoch 101/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8717 - loss: 0.3674 - val_accuracy: 0.9495 - val_loss: 0.1779\n",
      "Epoch 102/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8699 - loss: 0.3676 - val_accuracy: 0.9496 - val_loss: 0.1773\n",
      "Epoch 103/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8750 - loss: 0.3557 - val_accuracy: 0.9516 - val_loss: 0.1754\n",
      "Epoch 104/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8767 - loss: 0.3540 - val_accuracy: 0.9510 - val_loss: 0.1741\n",
      "Epoch 105/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8771 - loss: 0.3534 - val_accuracy: 0.9501 - val_loss: 0.1736\n",
      "Epoch 106/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8772 - loss: 0.3528 - val_accuracy: 0.9510 - val_loss: 0.1711\n",
      "Epoch 107/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8791 - loss: 0.3561 - val_accuracy: 0.9525 - val_loss: 0.1695\n",
      "Epoch 108/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8771 - loss: 0.3599 - val_accuracy: 0.9532 - val_loss: 0.1690\n",
      "Epoch 109/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8807 - loss: 0.3453 - val_accuracy: 0.9530 - val_loss: 0.1666\n",
      "Epoch 110/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.8778 - loss: 0.3465 - val_accuracy: 0.9522 - val_loss: 0.1636\n",
      "Epoch 111/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8788 - loss: 0.3456 - val_accuracy: 0.9538 - val_loss: 0.1653\n",
      "Epoch 112/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8837 - loss: 0.3438 - val_accuracy: 0.9530 - val_loss: 0.1625\n",
      "Epoch 113/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8781 - loss: 0.3476 - val_accuracy: 0.9553 - val_loss: 0.1603\n",
      "Epoch 114/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8814 - loss: 0.3418 - val_accuracy: 0.9551 - val_loss: 0.1598\n",
      "Epoch 115/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8828 - loss: 0.3390 - val_accuracy: 0.9560 - val_loss: 0.1584\n",
      "Epoch 116/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8864 - loss: 0.3265 - val_accuracy: 0.9551 - val_loss: 0.1565\n",
      "Epoch 117/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.8796 - loss: 0.3372 - val_accuracy: 0.9548 - val_loss: 0.1564\n",
      "Epoch 118/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8851 - loss: 0.3313 - val_accuracy: 0.9561 - val_loss: 0.1546\n",
      "Epoch 119/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8797 - loss: 0.3420 - val_accuracy: 0.9542 - val_loss: 0.1551\n",
      "Epoch 120/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8841 - loss: 0.3324 - val_accuracy: 0.9576 - val_loss: 0.1530\n",
      "Epoch 121/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8889 - loss: 0.3257 - val_accuracy: 0.9574 - val_loss: 0.1511\n",
      "Epoch 122/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8862 - loss: 0.3307 - val_accuracy: 0.9590 - val_loss: 0.1522\n",
      "Epoch 123/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8846 - loss: 0.3370 - val_accuracy: 0.9579 - val_loss: 0.1499\n",
      "Epoch 124/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8862 - loss: 0.3208 - val_accuracy: 0.9567 - val_loss: 0.1488\n",
      "Epoch 125/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8871 - loss: 0.3210 - val_accuracy: 0.9569 - val_loss: 0.1482\n",
      "Epoch 126/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8887 - loss: 0.3222 - val_accuracy: 0.9570 - val_loss: 0.1475\n",
      "Epoch 127/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8855 - loss: 0.3304 - val_accuracy: 0.9576 - val_loss: 0.1472\n",
      "Epoch 128/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8914 - loss: 0.3198 - val_accuracy: 0.9575 - val_loss: 0.1456\n",
      "Epoch 129/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8946 - loss: 0.3093 - val_accuracy: 0.9593 - val_loss: 0.1429\n",
      "Epoch 130/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8895 - loss: 0.3101 - val_accuracy: 0.9589 - val_loss: 0.1447\n",
      "Epoch 131/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8887 - loss: 0.3157 - val_accuracy: 0.9590 - val_loss: 0.1417\n",
      "Epoch 132/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8886 - loss: 0.3229 - val_accuracy: 0.9604 - val_loss: 0.1424\n",
      "Epoch 133/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8916 - loss: 0.3102 - val_accuracy: 0.9583 - val_loss: 0.1417\n",
      "Epoch 134/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8941 - loss: 0.3085 - val_accuracy: 0.9574 - val_loss: 0.1425\n",
      "Epoch 135/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8896 - loss: 0.3146 - val_accuracy: 0.9587 - val_loss: 0.1407\n",
      "Epoch 136/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8909 - loss: 0.3188 - val_accuracy: 0.9593 - val_loss: 0.1395\n",
      "Epoch 137/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8914 - loss: 0.3069 - val_accuracy: 0.9606 - val_loss: 0.1382\n",
      "Epoch 138/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8948 - loss: 0.3025 - val_accuracy: 0.9603 - val_loss: 0.1389\n",
      "Epoch 139/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8916 - loss: 0.3112 - val_accuracy: 0.9620 - val_loss: 0.1381\n",
      "Epoch 140/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8943 - loss: 0.3049 - val_accuracy: 0.9613 - val_loss: 0.1361\n",
      "Epoch 141/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.8955 - loss: 0.3007 - val_accuracy: 0.9599 - val_loss: 0.1361\n",
      "Epoch 142/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.8944 - loss: 0.3036 - val_accuracy: 0.9616 - val_loss: 0.1350\n",
      "Epoch 143/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9003 - loss: 0.2886 - val_accuracy: 0.9638 - val_loss: 0.1327\n",
      "Epoch 144/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8980 - loss: 0.3014 - val_accuracy: 0.9619 - val_loss: 0.1326\n",
      "Epoch 145/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8943 - loss: 0.3057 - val_accuracy: 0.9625 - val_loss: 0.1331\n",
      "Epoch 146/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8953 - loss: 0.3026 - val_accuracy: 0.9622 - val_loss: 0.1306\n",
      "Epoch 147/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8998 - loss: 0.2931 - val_accuracy: 0.9631 - val_loss: 0.1308\n",
      "Epoch 148/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9006 - loss: 0.2894 - val_accuracy: 0.9629 - val_loss: 0.1315\n",
      "Epoch 149/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8957 - loss: 0.2968 - val_accuracy: 0.9627 - val_loss: 0.1303\n",
      "Epoch 150/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8984 - loss: 0.2948 - val_accuracy: 0.9629 - val_loss: 0.1288\n",
      "Epoch 151/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8974 - loss: 0.2942 - val_accuracy: 0.9633 - val_loss: 0.1286\n",
      "Epoch 152/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.9017 - loss: 0.2822 - val_accuracy: 0.9629 - val_loss: 0.1265\n",
      "Epoch 153/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8987 - loss: 0.2901 - val_accuracy: 0.9627 - val_loss: 0.1267\n",
      "Epoch 154/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8973 - loss: 0.2994 - val_accuracy: 0.9624 - val_loss: 0.1275\n",
      "Epoch 155/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8996 - loss: 0.2915 - val_accuracy: 0.9627 - val_loss: 0.1275\n",
      "Epoch 156/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9010 - loss: 0.2869 - val_accuracy: 0.9633 - val_loss: 0.1262\n",
      "Epoch 157/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9012 - loss: 0.2888 - val_accuracy: 0.9624 - val_loss: 0.1261\n",
      "Epoch 158/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8970 - loss: 0.2948 - val_accuracy: 0.9639 - val_loss: 0.1244\n",
      "Epoch 159/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8982 - loss: 0.2923 - val_accuracy: 0.9636 - val_loss: 0.1246\n",
      "Epoch 160/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9004 - loss: 0.2853 - val_accuracy: 0.9653 - val_loss: 0.1231\n",
      "Epoch 161/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9031 - loss: 0.2774 - val_accuracy: 0.9643 - val_loss: 0.1239\n",
      "Epoch 162/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9029 - loss: 0.2775 - val_accuracy: 0.9616 - val_loss: 0.1247\n",
      "Epoch 163/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9007 - loss: 0.2874 - val_accuracy: 0.9645 - val_loss: 0.1226\n",
      "Epoch 164/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.2715 - val_accuracy: 0.9650 - val_loss: 0.1218\n",
      "Epoch 165/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9053 - loss: 0.2796 - val_accuracy: 0.9649 - val_loss: 0.1218\n",
      "Epoch 166/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9014 - loss: 0.2867 - val_accuracy: 0.9643 - val_loss: 0.1224\n",
      "Epoch 167/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9041 - loss: 0.2768 - val_accuracy: 0.9647 - val_loss: 0.1205\n",
      "Epoch 168/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.9042 - loss: 0.2817 - val_accuracy: 0.9644 - val_loss: 0.1200\n",
      "Epoch 169/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9057 - loss: 0.2745 - val_accuracy: 0.9645 - val_loss: 0.1198\n",
      "Epoch 170/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9095 - loss: 0.2683 - val_accuracy: 0.9654 - val_loss: 0.1183\n",
      "Epoch 171/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9055 - loss: 0.2747 - val_accuracy: 0.9652 - val_loss: 0.1195\n",
      "Epoch 172/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9079 - loss: 0.2716 - val_accuracy: 0.9649 - val_loss: 0.1187\n",
      "Epoch 173/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9095 - loss: 0.2686 - val_accuracy: 0.9659 - val_loss: 0.1166\n",
      "Epoch 174/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9040 - loss: 0.2747 - val_accuracy: 0.9658 - val_loss: 0.1170\n",
      "Epoch 175/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9086 - loss: 0.2666 - val_accuracy: 0.9659 - val_loss: 0.1157\n",
      "Epoch 176/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9100 - loss: 0.2623 - val_accuracy: 0.9670 - val_loss: 0.1161\n",
      "Epoch 177/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9035 - loss: 0.2743 - val_accuracy: 0.9667 - val_loss: 0.1150\n",
      "Epoch 178/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9112 - loss: 0.2613 - val_accuracy: 0.9656 - val_loss: 0.1152\n",
      "Epoch 179/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9117 - loss: 0.2642 - val_accuracy: 0.9672 - val_loss: 0.1145\n",
      "Epoch 180/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9099 - loss: 0.2649 - val_accuracy: 0.9676 - val_loss: 0.1135\n",
      "Epoch 181/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9081 - loss: 0.2642 - val_accuracy: 0.9687 - val_loss: 0.1122\n",
      "Epoch 182/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9097 - loss: 0.2660 - val_accuracy: 0.9662 - val_loss: 0.1133\n",
      "Epoch 183/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9091 - loss: 0.2631 - val_accuracy: 0.9680 - val_loss: 0.1125\n",
      "Epoch 184/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9088 - loss: 0.2650 - val_accuracy: 0.9676 - val_loss: 0.1124\n",
      "Epoch 185/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9111 - loss: 0.2551 - val_accuracy: 0.9680 - val_loss: 0.1128\n",
      "Epoch 186/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9091 - loss: 0.2618 - val_accuracy: 0.9673 - val_loss: 0.1119\n",
      "Epoch 187/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9086 - loss: 0.2619 - val_accuracy: 0.9695 - val_loss: 0.1112\n",
      "Epoch 188/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9102 - loss: 0.2582 - val_accuracy: 0.9693 - val_loss: 0.1094\n",
      "Epoch 189/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9101 - loss: 0.2523 - val_accuracy: 0.9700 - val_loss: 0.1095\n",
      "Epoch 190/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9145 - loss: 0.2502 - val_accuracy: 0.9696 - val_loss: 0.1107\n",
      "Epoch 191/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9157 - loss: 0.2544 - val_accuracy: 0.9682 - val_loss: 0.1094\n",
      "Epoch 192/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9144 - loss: 0.2506 - val_accuracy: 0.9712 - val_loss: 0.1080\n",
      "Epoch 193/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9131 - loss: 0.2527 - val_accuracy: 0.9690 - val_loss: 0.1086\n",
      "Epoch 194/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9139 - loss: 0.2535 - val_accuracy: 0.9677 - val_loss: 0.1083\n",
      "Epoch 195/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9142 - loss: 0.2479 - val_accuracy: 0.9687 - val_loss: 0.1076\n",
      "Epoch 196/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9110 - loss: 0.2583 - val_accuracy: 0.9691 - val_loss: 0.1071\n",
      "Epoch 197/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9134 - loss: 0.2540 - val_accuracy: 0.9691 - val_loss: 0.1069\n",
      "Epoch 198/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9133 - loss: 0.2513 - val_accuracy: 0.9680 - val_loss: 0.1072\n",
      "Epoch 199/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9159 - loss: 0.2478 - val_accuracy: 0.9693 - val_loss: 0.1058\n",
      "Epoch 200/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9126 - loss: 0.2516 - val_accuracy: 0.9687 - val_loss: 0.1061\n",
      "Epoch 201/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9140 - loss: 0.2439 - val_accuracy: 0.9685 - val_loss: 0.1055\n",
      "Epoch 202/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9157 - loss: 0.2478 - val_accuracy: 0.9686 - val_loss: 0.1065\n",
      "Epoch 203/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9168 - loss: 0.2393 - val_accuracy: 0.9713 - val_loss: 0.1056\n",
      "Epoch 204/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9115 - loss: 0.2514 - val_accuracy: 0.9708 - val_loss: 0.1042\n",
      "Epoch 205/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9161 - loss: 0.2447 - val_accuracy: 0.9700 - val_loss: 0.1054\n",
      "Epoch 206/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9152 - loss: 0.2475 - val_accuracy: 0.9721 - val_loss: 0.1038\n",
      "Epoch 207/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9112 - loss: 0.2499 - val_accuracy: 0.9714 - val_loss: 0.1026\n",
      "Epoch 208/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9176 - loss: 0.2398 - val_accuracy: 0.9717 - val_loss: 0.1018\n",
      "Epoch 209/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.9166 - loss: 0.2447 - val_accuracy: 0.9712 - val_loss: 0.1019\n",
      "Epoch 210/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9187 - loss: 0.2363 - val_accuracy: 0.9717 - val_loss: 0.1019\n",
      "Epoch 211/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9138 - loss: 0.2439 - val_accuracy: 0.9714 - val_loss: 0.1019\n",
      "Epoch 212/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9146 - loss: 0.2441 - val_accuracy: 0.9707 - val_loss: 0.1014\n",
      "Epoch 213/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9154 - loss: 0.2461 - val_accuracy: 0.9696 - val_loss: 0.1037\n",
      "Epoch 214/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.9149 - loss: 0.2423 - val_accuracy: 0.9704 - val_loss: 0.1029\n",
      "Epoch 215/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9171 - loss: 0.2401 - val_accuracy: 0.9717 - val_loss: 0.1011\n",
      "Epoch 216/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9187 - loss: 0.2384 - val_accuracy: 0.9721 - val_loss: 0.1025\n",
      "Epoch 217/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9190 - loss: 0.2362 - val_accuracy: 0.9714 - val_loss: 0.1005\n",
      "Epoch 218/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9204 - loss: 0.2341 - val_accuracy: 0.9705 - val_loss: 0.1008\n",
      "Epoch 219/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9186 - loss: 0.2390 - val_accuracy: 0.9713 - val_loss: 0.0999\n",
      "Epoch 220/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9182 - loss: 0.2383 - val_accuracy: 0.9704 - val_loss: 0.1002\n",
      "Epoch 221/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9186 - loss: 0.2388 - val_accuracy: 0.9707 - val_loss: 0.0994\n",
      "Epoch 222/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9195 - loss: 0.2350 - val_accuracy: 0.9721 - val_loss: 0.0997\n",
      "Epoch 223/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9194 - loss: 0.2387 - val_accuracy: 0.9718 - val_loss: 0.0991\n",
      "Epoch 224/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9211 - loss: 0.2322 - val_accuracy: 0.9715 - val_loss: 0.0994\n",
      "Epoch 225/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9165 - loss: 0.2430 - val_accuracy: 0.9704 - val_loss: 0.0991\n",
      "Epoch 226/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9182 - loss: 0.2368 - val_accuracy: 0.9713 - val_loss: 0.0984\n",
      "Epoch 227/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9212 - loss: 0.2296 - val_accuracy: 0.9724 - val_loss: 0.0985\n",
      "Epoch 228/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9195 - loss: 0.2372 - val_accuracy: 0.9714 - val_loss: 0.0980\n",
      "Epoch 229/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9182 - loss: 0.2391 - val_accuracy: 0.9740 - val_loss: 0.0976\n",
      "Epoch 230/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9210 - loss: 0.2301 - val_accuracy: 0.9722 - val_loss: 0.0984\n",
      "Epoch 231/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9196 - loss: 0.2349 - val_accuracy: 0.9731 - val_loss: 0.0974\n",
      "Epoch 232/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9234 - loss: 0.2340 - val_accuracy: 0.9728 - val_loss: 0.0976\n",
      "Epoch 233/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9191 - loss: 0.2323 - val_accuracy: 0.9730 - val_loss: 0.0969\n",
      "Epoch 234/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9197 - loss: 0.2384 - val_accuracy: 0.9721 - val_loss: 0.0992\n",
      "Epoch 235/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9207 - loss: 0.2312 - val_accuracy: 0.9728 - val_loss: 0.0968\n",
      "Epoch 236/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9188 - loss: 0.2369 - val_accuracy: 0.9735 - val_loss: 0.0979\n",
      "Epoch 237/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9210 - loss: 0.2238 - val_accuracy: 0.9718 - val_loss: 0.0963\n",
      "Epoch 238/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9226 - loss: 0.2289 - val_accuracy: 0.9727 - val_loss: 0.0962\n",
      "Epoch 239/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9201 - loss: 0.2316 - val_accuracy: 0.9723 - val_loss: 0.0971\n",
      "Epoch 240/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9199 - loss: 0.2300 - val_accuracy: 0.9731 - val_loss: 0.0970\n",
      "Epoch 241/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9207 - loss: 0.2285 - val_accuracy: 0.9742 - val_loss: 0.0946\n",
      "Epoch 242/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9204 - loss: 0.2233 - val_accuracy: 0.9730 - val_loss: 0.0950\n",
      "Epoch 243/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9212 - loss: 0.2238 - val_accuracy: 0.9723 - val_loss: 0.0950\n",
      "Epoch 244/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9229 - loss: 0.2249 - val_accuracy: 0.9735 - val_loss: 0.0944\n",
      "Epoch 245/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9229 - loss: 0.2224 - val_accuracy: 0.9726 - val_loss: 0.0941\n",
      "Epoch 246/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9232 - loss: 0.2170 - val_accuracy: 0.9735 - val_loss: 0.0944\n",
      "Epoch 247/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9200 - loss: 0.2253 - val_accuracy: 0.9732 - val_loss: 0.0935\n",
      "Epoch 248/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9250 - loss: 0.2206 - val_accuracy: 0.9737 - val_loss: 0.0943\n",
      "Epoch 249/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9256 - loss: 0.2215 - val_accuracy: 0.9746 - val_loss: 0.0935\n",
      "Epoch 250/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9247 - loss: 0.2232 - val_accuracy: 0.9749 - val_loss: 0.0936\n",
      "Epoch 251/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9264 - loss: 0.2217 - val_accuracy: 0.9722 - val_loss: 0.0944\n",
      "Epoch 252/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9224 - loss: 0.2314 - val_accuracy: 0.9733 - val_loss: 0.0932\n",
      "Epoch 253/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9277 - loss: 0.2115 - val_accuracy: 0.9736 - val_loss: 0.0929\n",
      "Epoch 254/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9237 - loss: 0.2173 - val_accuracy: 0.9754 - val_loss: 0.0913\n",
      "Epoch 255/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9264 - loss: 0.2146 - val_accuracy: 0.9735 - val_loss: 0.0935\n",
      "Epoch 256/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9213 - loss: 0.2289 - val_accuracy: 0.9751 - val_loss: 0.0917\n",
      "Epoch 257/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9258 - loss: 0.2210 - val_accuracy: 0.9735 - val_loss: 0.0931\n",
      "Epoch 258/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9239 - loss: 0.2249 - val_accuracy: 0.9732 - val_loss: 0.0925\n",
      "Epoch 259/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9251 - loss: 0.2172 - val_accuracy: 0.9756 - val_loss: 0.0914\n",
      "Epoch 260/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9237 - loss: 0.2153 - val_accuracy: 0.9759 - val_loss: 0.0908\n",
      "Epoch 261/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9247 - loss: 0.2197 - val_accuracy: 0.9746 - val_loss: 0.0907\n",
      "Epoch 262/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.9241 - loss: 0.2159 - val_accuracy: 0.9737 - val_loss: 0.0920\n",
      "Epoch 263/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9278 - loss: 0.2169 - val_accuracy: 0.9751 - val_loss: 0.0908\n",
      "Epoch 264/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9218 - loss: 0.2231 - val_accuracy: 0.9749 - val_loss: 0.0900\n",
      "Epoch 265/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9250 - loss: 0.2174 - val_accuracy: 0.9752 - val_loss: 0.0903\n",
      "Epoch 266/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - accuracy: 0.9234 - loss: 0.2253 - val_accuracy: 0.9758 - val_loss: 0.0897\n",
      "Epoch 267/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9233 - loss: 0.2167 - val_accuracy: 0.9740 - val_loss: 0.0910\n",
      "Epoch 268/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9264 - loss: 0.2156 - val_accuracy: 0.9756 - val_loss: 0.0901\n",
      "Epoch 269/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9279 - loss: 0.2146 - val_accuracy: 0.9749 - val_loss: 0.0903\n",
      "Epoch 270/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9249 - loss: 0.2166 - val_accuracy: 0.9747 - val_loss: 0.0897\n",
      "Epoch 271/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9258 - loss: 0.2150 - val_accuracy: 0.9755 - val_loss: 0.0893\n",
      "Epoch 272/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9249 - loss: 0.2136 - val_accuracy: 0.9759 - val_loss: 0.0887\n",
      "Epoch 273/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9228 - loss: 0.2213 - val_accuracy: 0.9750 - val_loss: 0.0895\n",
      "Epoch 274/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9235 - loss: 0.2188 - val_accuracy: 0.9754 - val_loss: 0.0892\n",
      "Epoch 275/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9287 - loss: 0.2094 - val_accuracy: 0.9752 - val_loss: 0.0892\n",
      "Epoch 276/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9280 - loss: 0.2089 - val_accuracy: 0.9735 - val_loss: 0.0904\n",
      "Epoch 277/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9270 - loss: 0.2091 - val_accuracy: 0.9755 - val_loss: 0.0882\n",
      "Epoch 278/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9261 - loss: 0.2143 - val_accuracy: 0.9750 - val_loss: 0.0881\n",
      "Epoch 279/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9255 - loss: 0.2182 - val_accuracy: 0.9761 - val_loss: 0.0874\n",
      "Epoch 280/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9305 - loss: 0.2073 - val_accuracy: 0.9751 - val_loss: 0.0888\n",
      "Epoch 281/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9297 - loss: 0.2057 - val_accuracy: 0.9744 - val_loss: 0.0895\n",
      "Epoch 282/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9283 - loss: 0.2108 - val_accuracy: 0.9750 - val_loss: 0.0891\n",
      "Epoch 283/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9308 - loss: 0.2030 - val_accuracy: 0.9745 - val_loss: 0.0894\n",
      "Epoch 284/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9277 - loss: 0.2113 - val_accuracy: 0.9760 - val_loss: 0.0887\n",
      "Epoch 285/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9274 - loss: 0.2102 - val_accuracy: 0.9749 - val_loss: 0.0889\n",
      "Epoch 286/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9273 - loss: 0.2104 - val_accuracy: 0.9763 - val_loss: 0.0868\n",
      "Epoch 287/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9253 - loss: 0.2073 - val_accuracy: 0.9764 - val_loss: 0.0879\n",
      "Epoch 288/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9298 - loss: 0.2053 - val_accuracy: 0.9747 - val_loss: 0.0871\n",
      "Epoch 289/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9261 - loss: 0.2144 - val_accuracy: 0.9747 - val_loss: 0.0893\n",
      "Epoch 290/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9310 - loss: 0.2045 - val_accuracy: 0.9756 - val_loss: 0.0869\n",
      "Epoch 291/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.9310 - loss: 0.2016 - val_accuracy: 0.9764 - val_loss: 0.0872\n",
      "Epoch 292/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9281 - loss: 0.2046 - val_accuracy: 0.9760 - val_loss: 0.0874\n",
      "Epoch 293/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9292 - loss: 0.2069 - val_accuracy: 0.9754 - val_loss: 0.0878\n",
      "Epoch 294/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9298 - loss: 0.2099 - val_accuracy: 0.9758 - val_loss: 0.0872\n",
      "Epoch 295/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9317 - loss: 0.1996 - val_accuracy: 0.9758 - val_loss: 0.0863\n",
      "Epoch 296/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9298 - loss: 0.2032 - val_accuracy: 0.9758 - val_loss: 0.0875\n",
      "Epoch 297/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9303 - loss: 0.1996 - val_accuracy: 0.9756 - val_loss: 0.0866\n",
      "Epoch 298/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9286 - loss: 0.2062 - val_accuracy: 0.9747 - val_loss: 0.0880\n",
      "Epoch 299/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.9295 - loss: 0.2024 - val_accuracy: 0.9760 - val_loss: 0.0868\n",
      "Epoch 300/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.9283 - loss: 0.2086 - val_accuracy: 0.9756 - val_loss: 0.0875\n",
      "Epoch 301/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9309 - loss: 0.2022 - val_accuracy: 0.9765 - val_loss: 0.0853\n",
      "Epoch 302/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9285 - loss: 0.2021 - val_accuracy: 0.9751 - val_loss: 0.0866\n",
      "Epoch 303/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9307 - loss: 0.2125 - val_accuracy: 0.9763 - val_loss: 0.0864\n",
      "Epoch 304/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9324 - loss: 0.1967 - val_accuracy: 0.9760 - val_loss: 0.0860\n",
      "Epoch 305/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9329 - loss: 0.1918 - val_accuracy: 0.9761 - val_loss: 0.0844\n",
      "Epoch 306/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9312 - loss: 0.1977 - val_accuracy: 0.9767 - val_loss: 0.0850\n",
      "Epoch 307/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.9337 - loss: 0.1919 - val_accuracy: 0.9764 - val_loss: 0.0849\n",
      "Epoch 308/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9305 - loss: 0.2014 - val_accuracy: 0.9760 - val_loss: 0.0854\n",
      "Epoch 309/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9324 - loss: 0.1969 - val_accuracy: 0.9768 - val_loss: 0.0854\n",
      "Epoch 310/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.9281 - loss: 0.2042 - val_accuracy: 0.9752 - val_loss: 0.0857\n",
      "Epoch 311/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9328 - loss: 0.1974 - val_accuracy: 0.9751 - val_loss: 0.0851\n",
      "Epoch 312/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 29ms/step - accuracy: 0.9339 - loss: 0.1949 - val_accuracy: 0.9763 - val_loss: 0.0849\n",
      "Epoch 313/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9350 - loss: 0.1952 - val_accuracy: 0.9747 - val_loss: 0.0845\n",
      "Epoch 314/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9328 - loss: 0.1937 - val_accuracy: 0.9756 - val_loss: 0.0851\n",
      "Epoch 315/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9276 - loss: 0.2020 - val_accuracy: 0.9758 - val_loss: 0.0845\n",
      "Epoch 316/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9303 - loss: 0.2001 - val_accuracy: 0.9763 - val_loss: 0.0837\n",
      "Epoch 317/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 32ms/step - accuracy: 0.9325 - loss: 0.1995 - val_accuracy: 0.9759 - val_loss: 0.0840\n",
      "Epoch 318/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9349 - loss: 0.1930 - val_accuracy: 0.9750 - val_loss: 0.0851\n",
      "Epoch 319/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9313 - loss: 0.2033 - val_accuracy: 0.9754 - val_loss: 0.0836\n",
      "Epoch 320/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9325 - loss: 0.1992 - val_accuracy: 0.9737 - val_loss: 0.0857\n",
      "Epoch 321/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9329 - loss: 0.1953 - val_accuracy: 0.9754 - val_loss: 0.0844\n",
      "Epoch 322/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 33ms/step - accuracy: 0.9295 - loss: 0.2065 - val_accuracy: 0.9755 - val_loss: 0.0840\n",
      "Epoch 323/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9355 - loss: 0.1930 - val_accuracy: 0.9767 - val_loss: 0.0837\n",
      "Epoch 324/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9340 - loss: 0.1920 - val_accuracy: 0.9767 - val_loss: 0.0836\n",
      "Epoch 325/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9334 - loss: 0.1951 - val_accuracy: 0.9774 - val_loss: 0.0830\n",
      "Epoch 326/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9341 - loss: 0.1913 - val_accuracy: 0.9770 - val_loss: 0.0833\n",
      "Epoch 327/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 33ms/step - accuracy: 0.9332 - loss: 0.1983 - val_accuracy: 0.9769 - val_loss: 0.0839\n",
      "Epoch 328/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9312 - loss: 0.1953 - val_accuracy: 0.9754 - val_loss: 0.0858\n",
      "Epoch 329/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9331 - loss: 0.1972 - val_accuracy: 0.9765 - val_loss: 0.0848\n",
      "Epoch 330/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9349 - loss: 0.1906 - val_accuracy: 0.9772 - val_loss: 0.0847\n",
      "Epoch 331/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9318 - loss: 0.1966 - val_accuracy: 0.9769 - val_loss: 0.0850\n",
      "Epoch 332/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9345 - loss: 0.1894 - val_accuracy: 0.9758 - val_loss: 0.0844\n",
      "Epoch 333/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 32ms/step - accuracy: 0.9328 - loss: 0.1954 - val_accuracy: 0.9763 - val_loss: 0.0836\n",
      "Epoch 334/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.9311 - loss: 0.1951 - val_accuracy: 0.9769 - val_loss: 0.0834\n",
      "Epoch 335/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9357 - loss: 0.1930 - val_accuracy: 0.9763 - val_loss: 0.0844\n",
      "Epoch 336/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 27ms/step - accuracy: 0.9344 - loss: 0.1909 - val_accuracy: 0.9767 - val_loss: 0.0824\n",
      "Epoch 337/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.9342 - loss: 0.1929 - val_accuracy: 0.9770 - val_loss: 0.0828\n",
      "Epoch 338/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.9375 - loss: 0.1833 - val_accuracy: 0.9758 - val_loss: 0.0833\n",
      "Epoch 339/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9330 - loss: 0.1909 - val_accuracy: 0.9768 - val_loss: 0.0834\n",
      "Epoch 340/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.9344 - loss: 0.1953 - val_accuracy: 0.9772 - val_loss: 0.0834\n",
      "Epoch 341/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.9385 - loss: 0.1825 - val_accuracy: 0.9778 - val_loss: 0.0815\n",
      "Epoch 342/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9356 - loss: 0.1862 - val_accuracy: 0.9774 - val_loss: 0.0822\n",
      "Epoch 343/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 32ms/step - accuracy: 0.9351 - loss: 0.1869 - val_accuracy: 0.9772 - val_loss: 0.0827\n",
      "Epoch 344/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9344 - loss: 0.1910 - val_accuracy: 0.9765 - val_loss: 0.0823\n",
      "Epoch 345/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9358 - loss: 0.1894 - val_accuracy: 0.9772 - val_loss: 0.0823\n",
      "Epoch 346/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.9357 - loss: 0.1872 - val_accuracy: 0.9775 - val_loss: 0.0825\n",
      "Epoch 347/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9356 - loss: 0.1852 - val_accuracy: 0.9775 - val_loss: 0.0826\n",
      "Epoch 348/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9343 - loss: 0.1918 - val_accuracy: 0.9774 - val_loss: 0.0818\n",
      "Epoch 349/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9351 - loss: 0.1870 - val_accuracy: 0.9770 - val_loss: 0.0826\n",
      "Epoch 350/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.9366 - loss: 0.1787 - val_accuracy: 0.9772 - val_loss: 0.0823\n",
      "Epoch 351/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.9361 - loss: 0.1859 - val_accuracy: 0.9767 - val_loss: 0.0812\n",
      "Epoch 352/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9349 - loss: 0.1881 - val_accuracy: 0.9773 - val_loss: 0.0812\n",
      "Epoch 353/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9356 - loss: 0.1828 - val_accuracy: 0.9775 - val_loss: 0.0809\n",
      "Epoch 354/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9365 - loss: 0.1810 - val_accuracy: 0.9772 - val_loss: 0.0811\n",
      "Epoch 355/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9344 - loss: 0.1873 - val_accuracy: 0.9764 - val_loss: 0.0819\n",
      "Epoch 356/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9336 - loss: 0.1947 - val_accuracy: 0.9770 - val_loss: 0.0816\n",
      "Epoch 357/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9392 - loss: 0.1802 - val_accuracy: 0.9781 - val_loss: 0.0815\n",
      "Epoch 358/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.9345 - loss: 0.1887 - val_accuracy: 0.9779 - val_loss: 0.0818\n",
      "Epoch 359/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9356 - loss: 0.1878 - val_accuracy: 0.9775 - val_loss: 0.0813\n",
      "Epoch 360/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9362 - loss: 0.1847 - val_accuracy: 0.9759 - val_loss: 0.0823\n",
      "Epoch 361/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9357 - loss: 0.1852 - val_accuracy: 0.9772 - val_loss: 0.0814\n",
      "Epoch 362/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9381 - loss: 0.1874 - val_accuracy: 0.9772 - val_loss: 0.0819\n",
      "Epoch 363/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 36ms/step - accuracy: 0.9373 - loss: 0.1828 - val_accuracy: 0.9772 - val_loss: 0.0804\n",
      "Epoch 364/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9336 - loss: 0.1924 - val_accuracy: 0.9767 - val_loss: 0.0811\n",
      "Epoch 365/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9382 - loss: 0.1848 - val_accuracy: 0.9770 - val_loss: 0.0803\n",
      "Epoch 366/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9362 - loss: 0.1868 - val_accuracy: 0.9767 - val_loss: 0.0813\n",
      "Epoch 367/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9365 - loss: 0.1866 - val_accuracy: 0.9778 - val_loss: 0.0804\n",
      "Epoch 368/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9397 - loss: 0.1825 - val_accuracy: 0.9765 - val_loss: 0.0818\n",
      "Epoch 369/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9372 - loss: 0.1816 - val_accuracy: 0.9772 - val_loss: 0.0809\n",
      "Epoch 370/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9375 - loss: 0.1829 - val_accuracy: 0.9773 - val_loss: 0.0805\n",
      "Epoch 371/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9366 - loss: 0.1830 - val_accuracy: 0.9768 - val_loss: 0.0799\n",
      "Epoch 372/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9366 - loss: 0.1909 - val_accuracy: 0.9779 - val_loss: 0.0791\n",
      "Epoch 373/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9360 - loss: 0.1841 - val_accuracy: 0.9765 - val_loss: 0.0810\n",
      "Epoch 374/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9341 - loss: 0.1888 - val_accuracy: 0.9772 - val_loss: 0.0805\n",
      "Epoch 375/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9341 - loss: 0.1889 - val_accuracy: 0.9769 - val_loss: 0.0801\n",
      "Epoch 376/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9339 - loss: 0.1935 - val_accuracy: 0.9781 - val_loss: 0.0794\n",
      "Epoch 377/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9345 - loss: 0.1851 - val_accuracy: 0.9778 - val_loss: 0.0799\n",
      "Epoch 378/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9376 - loss: 0.1836 - val_accuracy: 0.9788 - val_loss: 0.0784\n",
      "Epoch 379/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9394 - loss: 0.1807 - val_accuracy: 0.9779 - val_loss: 0.0804\n",
      "Epoch 380/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9383 - loss: 0.1836 - val_accuracy: 0.9778 - val_loss: 0.0800\n",
      "Epoch 381/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9384 - loss: 0.1820 - val_accuracy: 0.9783 - val_loss: 0.0798\n",
      "Epoch 382/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9387 - loss: 0.1780 - val_accuracy: 0.9770 - val_loss: 0.0813\n",
      "Epoch 383/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9381 - loss: 0.1833 - val_accuracy: 0.9786 - val_loss: 0.0790\n",
      "Epoch 384/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9402 - loss: 0.1761 - val_accuracy: 0.9778 - val_loss: 0.0805\n",
      "Epoch 385/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9365 - loss: 0.1808 - val_accuracy: 0.9772 - val_loss: 0.0801\n",
      "Epoch 386/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9394 - loss: 0.1801 - val_accuracy: 0.9772 - val_loss: 0.0812\n",
      "Epoch 387/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9406 - loss: 0.1775 - val_accuracy: 0.9778 - val_loss: 0.0800\n",
      "Epoch 388/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9346 - loss: 0.1855 - val_accuracy: 0.9773 - val_loss: 0.0806\n",
      "Epoch 389/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9368 - loss: 0.1824 - val_accuracy: 0.9781 - val_loss: 0.0797\n",
      "Epoch 390/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9366 - loss: 0.1839 - val_accuracy: 0.9778 - val_loss: 0.0807\n",
      "Epoch 391/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9377 - loss: 0.1797 - val_accuracy: 0.9765 - val_loss: 0.0807\n",
      "Epoch 392/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9363 - loss: 0.1878 - val_accuracy: 0.9770 - val_loss: 0.0801\n",
      "Epoch 393/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9393 - loss: 0.1793 - val_accuracy: 0.9778 - val_loss: 0.0791\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.9803 - loss: 0.0588\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9809 - loss: 0.0736\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9681 - loss: 0.0948\n",
      "Training Accuracy: 98.07%\n",
      "Validation Accuracy: 97.88%\n",
      "Test Accuracy: 96.85%\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
      "Test Accuracy with emotion labels: 96.85%\n",
      "Weighted Precision: 96.87%\n",
      "Weighted F1 Score: 96.83%\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         ALERT       0.96      0.88      0.92      1149\n",
      "         ANGER       0.98      1.00      0.99      1022\n",
      "          FEAR       1.00      1.00      1.00      1039\n",
      "         HAPPY       0.91      0.96      0.93      1074\n",
      "       NEUTRAL       0.96      0.97      0.97      1075\n",
      "RESTED/RELAXED       0.96      0.97      0.96      1175\n",
      "           SAD       0.99      1.00      1.00      1062\n",
      " TENSE/ANXIOUS       0.99      0.98      0.98      1098\n",
      "         TIRED       0.98      0.96      0.97      1104\n",
      "\n",
      "      accuracy                           0.97      9798\n",
      "     macro avg       0.97      0.97      0.97      9798\n",
      "  weighted avg       0.97      0.97      0.97      9798\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1015    0    0   35   23   50    3    9   14]\n",
      " [   0 1022    0    0    0    0    0    0    0]\n",
      " [   0    0 1039    0    0    0    0    0    0]\n",
      " [   7   19    0 1030    9    3    2    1    3]\n",
      " [   3    0    0   15 1048    0    0    5    4]\n",
      " [   2    0    0   33    1 1135    0    0    4]\n",
      " [   0    0    0    0    0    0 1062    0    0]\n",
      " [   6    0    0    7    9    0    3 1073    0]\n",
      " [  23    0    0   10    6    0    0    0 1065]]\n",
      "Emotion: ALERT\n",
      "True Positives (TP): 1015\n",
      "True Negatives (TN): 8608\n",
      "False Positives (FP): 41\n",
      "False Negatives (FN): 134\n",
      "------------------------------\n",
      "Emotion: ANGER\n",
      "True Positives (TP): 1022\n",
      "True Negatives (TN): 8757\n",
      "False Positives (FP): 19\n",
      "False Negatives (FN): 0\n",
      "------------------------------\n",
      "Emotion: FEAR\n",
      "True Positives (TP): 1039\n",
      "True Negatives (TN): 8759\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 0\n",
      "------------------------------\n",
      "Emotion: HAPPY\n",
      "True Positives (TP): 1030\n",
      "True Negatives (TN): 8624\n",
      "False Positives (FP): 100\n",
      "False Negatives (FN): 44\n",
      "------------------------------\n",
      "Emotion: NEUTRAL\n",
      "True Positives (TP): 1048\n",
      "True Negatives (TN): 8675\n",
      "False Positives (FP): 48\n",
      "False Negatives (FN): 27\n",
      "------------------------------\n",
      "Emotion: RESTED/RELAXED\n",
      "True Positives (TP): 1135\n",
      "True Negatives (TN): 8570\n",
      "False Positives (FP): 53\n",
      "False Negatives (FN): 40\n",
      "------------------------------\n",
      "Emotion: SAD\n",
      "True Positives (TP): 1062\n",
      "True Negatives (TN): 8728\n",
      "False Positives (FP): 8\n",
      "False Negatives (FN): 0\n",
      "------------------------------\n",
      "Emotion: TENSE/ANXIOUS\n",
      "True Positives (TP): 1073\n",
      "True Negatives (TN): 8685\n",
      "False Positives (FP): 15\n",
      "False Negatives (FN): 25\n",
      "------------------------------\n",
      "Emotion: TIRED\n",
      "True Positives (TP): 1065\n",
      "True Negatives (TN): 8669\n",
      "False Positives (FP): 25\n",
      "False Negatives (FN): 39\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler  # Using RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Raw_MAIN_DATASET_IMPUTATION_after_deleting_stai_badge_activity_step_goal.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "df = df.drop(['id', 'date'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Emotions', axis=1)\n",
    "y = df['Emotions']\n",
    "\n",
    "# Convert categorical target to numeric using label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Check the initial class distribution\n",
    "print(\"Class distribution before oversampling:\", Counter(y))\n",
    "\n",
    "# Oversampling to handle class imbalance using RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after oversampling\n",
    "print(\"Class distribution after oversampling:\", Counter(y))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Feature Selection\n",
    "selector = SelectKBest(f_classif, k=60)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_val = selector.transform(X_val)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  # Output layer (number of unique emotions)\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,  # Increased epochs\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Convert numeric predictions back to emotion labels\n",
    "y_test_pred_labels = le.inverse_transform(y_test_pred_classes)\n",
    "y_test_true_labels = le.inverse_transform(y_test)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "test_acc = accuracy_score(y_test_true_labels, y_test_pred_labels)\n",
    "print(f\"Test Accuracy with emotion labels: {test_acc * 100:.2f}%\")\n",
    "\n",
    "precision = precision_score(y_test_true_labels, y_test_pred_labels, average='weighted')  # Weighted precision\n",
    "f1 = f1_score(y_test_true_labels, y_test_pred_labels, average='weighted')  # Weighted F1 score\n",
    "\n",
    "print(f\"Weighted Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Weighted F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test_true_labels, y_test_pred_labels)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# Confusion matrix to calculate TP and TN for each emotion class\n",
    "conf_matrix = confusion_matrix(y_test_true_labels, y_test_pred_labels)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Calculate TP, TN, FP, FN for each class\n",
    "n_classes = len(le.classes_)\n",
    "for idx, emotion in enumerate(le.classes_):\n",
    "    # True Positives (TP): Diagonal elements\n",
    "    TP = conf_matrix[idx, idx]\n",
    "\n",
    "    # False Positives (FP): Sum of the current column except the diagonal element\n",
    "    FP = conf_matrix[:, idx].sum() - TP\n",
    "\n",
    "    # False Negatives (FN): Sum of the current row except the diagonal element\n",
    "    FN = conf_matrix[idx, :].sum() - TP\n",
    "\n",
    "    # True Negatives (TN): Total samples - (TP + FP + FN)\n",
    "    TN = conf_matrix.sum() - (TP + FP + FN)\n",
    "\n",
    "    print(f\"Emotion: {emotion}\")\n",
    "    print(f\"True Positives (TP): {TP}\")\n",
    "    print(f\"True Negatives (TN): {TN}\")\n",
    "    print(f\"False Positives (FP): {FP}\")\n",
    "    print(f\"False Negatives (FN): {FN}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
