{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 19:18:25.491243: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-24 19:18:25.570434: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 19:18:25.643910: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 19:18:25.665823: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 19:18:25.705821: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 19:18:29.051714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling: Counter({0: 5443, 3: 587, 5: 480, 4: 451, 8: 207, 7: 204, 6: 59, 1: 2, 2: 1})\n",
      "Class distribution after oversampling: Counter({0: 5443, 3: 5443, 7: 5443, 8: 5443, 4: 5443, 5: 5443, 6: 5443, 1: 5443, 2: 5443})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2024-09-24 19:18:33.360612: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - accuracy: 0.2681 - loss: 2.6107 - val_accuracy: 0.5304 - val_loss: 1.3980\n",
      "Epoch 2/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.4305 - loss: 1.8353 - val_accuracy: 0.5820 - val_loss: 1.2252\n",
      "Epoch 3/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.4633 - loss: 1.6448 - val_accuracy: 0.6185 - val_loss: 1.1267\n",
      "Epoch 4/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.4952 - loss: 1.5095 - val_accuracy: 0.6415 - val_loss: 1.0612\n",
      "Epoch 5/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.5084 - loss: 1.4209 - val_accuracy: 0.6611 - val_loss: 1.0057\n",
      "Epoch 6/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.5345 - loss: 1.3287 - val_accuracy: 0.6759 - val_loss: 0.9631\n",
      "Epoch 7/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.5537 - loss: 1.2689 - val_accuracy: 0.6826 - val_loss: 0.9239\n",
      "Epoch 8/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.5688 - loss: 1.2064 - val_accuracy: 0.6943 - val_loss: 0.8886\n",
      "Epoch 9/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.5853 - loss: 1.1707 - val_accuracy: 0.7099 - val_loss: 0.8534\n",
      "Epoch 10/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.5969 - loss: 1.1195 - val_accuracy: 0.7191 - val_loss: 0.8212\n",
      "Epoch 11/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6098 - loss: 1.0974 - val_accuracy: 0.7252 - val_loss: 0.7950\n",
      "Epoch 12/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.6185 - loss: 1.0574 - val_accuracy: 0.7360 - val_loss: 0.7690\n",
      "Epoch 13/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6322 - loss: 1.0252 - val_accuracy: 0.7490 - val_loss: 0.7451\n",
      "Epoch 14/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.6417 - loss: 0.9976 - val_accuracy: 0.7506 - val_loss: 0.7223\n",
      "Epoch 15/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.6557 - loss: 0.9625 - val_accuracy: 0.7617 - val_loss: 0.7023\n",
      "Epoch 16/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.6577 - loss: 0.9445 - val_accuracy: 0.7684 - val_loss: 0.6795\n",
      "Epoch 17/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.6615 - loss: 0.9329 - val_accuracy: 0.7742 - val_loss: 0.6589\n",
      "Epoch 18/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.6803 - loss: 0.8841 - val_accuracy: 0.7792 - val_loss: 0.6402\n",
      "Epoch 19/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.6812 - loss: 0.8840 - val_accuracy: 0.7901 - val_loss: 0.6216\n",
      "Epoch 20/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6933 - loss: 0.8577 - val_accuracy: 0.7979 - val_loss: 0.6054\n",
      "Epoch 21/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.6964 - loss: 0.8449 - val_accuracy: 0.7989 - val_loss: 0.5917\n",
      "Epoch 22/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.7024 - loss: 0.8260 - val_accuracy: 0.8059 - val_loss: 0.5740\n",
      "Epoch 23/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7069 - loss: 0.8085 - val_accuracy: 0.8116 - val_loss: 0.5603\n",
      "Epoch 24/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.7143 - loss: 0.7994 - val_accuracy: 0.8214 - val_loss: 0.5453\n",
      "Epoch 25/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.7197 - loss: 0.7740 - val_accuracy: 0.8238 - val_loss: 0.5308\n",
      "Epoch 26/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.7305 - loss: 0.7523 - val_accuracy: 0.8302 - val_loss: 0.5179\n",
      "Epoch 27/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.7299 - loss: 0.7607 - val_accuracy: 0.8315 - val_loss: 0.5068\n",
      "Epoch 28/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.7344 - loss: 0.7377 - val_accuracy: 0.8395 - val_loss: 0.4945\n",
      "Epoch 29/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.7364 - loss: 0.7264 - val_accuracy: 0.8428 - val_loss: 0.4834\n",
      "Epoch 30/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7487 - loss: 0.7087 - val_accuracy: 0.8450 - val_loss: 0.4735\n",
      "Epoch 31/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.7496 - loss: 0.7093 - val_accuracy: 0.8505 - val_loss: 0.4597\n",
      "Epoch 32/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.7548 - loss: 0.6902 - val_accuracy: 0.8512 - val_loss: 0.4525\n",
      "Epoch 33/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7563 - loss: 0.6871 - val_accuracy: 0.8583 - val_loss: 0.4429\n",
      "Epoch 34/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.7614 - loss: 0.6707 - val_accuracy: 0.8581 - val_loss: 0.4348\n",
      "Epoch 35/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.7676 - loss: 0.6554 - val_accuracy: 0.8636 - val_loss: 0.4248\n",
      "Epoch 36/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.7667 - loss: 0.6539 - val_accuracy: 0.8664 - val_loss: 0.4151\n",
      "Epoch 37/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.7682 - loss: 0.6436 - val_accuracy: 0.8709 - val_loss: 0.4105\n",
      "Epoch 38/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.7708 - loss: 0.6408 - val_accuracy: 0.8748 - val_loss: 0.4003\n",
      "Epoch 39/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.7768 - loss: 0.6300 - val_accuracy: 0.8751 - val_loss: 0.3934\n",
      "Epoch 40/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.7825 - loss: 0.6101 - val_accuracy: 0.8757 - val_loss: 0.3859\n",
      "Epoch 41/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.7812 - loss: 0.6176 - val_accuracy: 0.8787 - val_loss: 0.3792\n",
      "Epoch 42/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.7858 - loss: 0.5990 - val_accuracy: 0.8857 - val_loss: 0.3722\n",
      "Epoch 43/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.7877 - loss: 0.5940 - val_accuracy: 0.8865 - val_loss: 0.3661\n",
      "Epoch 44/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.7946 - loss: 0.5879 - val_accuracy: 0.8870 - val_loss: 0.3609\n",
      "Epoch 45/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7907 - loss: 0.5876 - val_accuracy: 0.8871 - val_loss: 0.3539\n",
      "Epoch 46/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7937 - loss: 0.5834 - val_accuracy: 0.8896 - val_loss: 0.3481\n",
      "Epoch 47/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.7941 - loss: 0.5732 - val_accuracy: 0.8913 - val_loss: 0.3436\n",
      "Epoch 48/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8045 - loss: 0.5510 - val_accuracy: 0.8945 - val_loss: 0.3377\n",
      "Epoch 49/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8035 - loss: 0.5518 - val_accuracy: 0.8959 - val_loss: 0.3314\n",
      "Epoch 50/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8048 - loss: 0.5450 - val_accuracy: 0.8955 - val_loss: 0.3269\n",
      "Epoch 51/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8017 - loss: 0.5508 - val_accuracy: 0.8986 - val_loss: 0.3224\n",
      "Epoch 52/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8062 - loss: 0.5484 - val_accuracy: 0.9004 - val_loss: 0.3187\n",
      "Epoch 53/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8119 - loss: 0.5349 - val_accuracy: 0.9023 - val_loss: 0.3119\n",
      "Epoch 54/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8075 - loss: 0.5425 - val_accuracy: 0.9027 - val_loss: 0.3098\n",
      "Epoch 55/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8143 - loss: 0.5224 - val_accuracy: 0.9025 - val_loss: 0.3046\n",
      "Epoch 56/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8199 - loss: 0.5113 - val_accuracy: 0.9057 - val_loss: 0.3009\n",
      "Epoch 57/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8190 - loss: 0.5084 - val_accuracy: 0.9061 - val_loss: 0.2956\n",
      "Epoch 58/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8213 - loss: 0.5102 - val_accuracy: 0.9097 - val_loss: 0.2925\n",
      "Epoch 59/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8181 - loss: 0.5162 - val_accuracy: 0.9087 - val_loss: 0.2874\n",
      "Epoch 60/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8272 - loss: 0.4959 - val_accuracy: 0.9101 - val_loss: 0.2858\n",
      "Epoch 61/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8236 - loss: 0.4901 - val_accuracy: 0.9124 - val_loss: 0.2789\n",
      "Epoch 62/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.8261 - loss: 0.4905 - val_accuracy: 0.9150 - val_loss: 0.2771\n",
      "Epoch 63/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8332 - loss: 0.4819 - val_accuracy: 0.9129 - val_loss: 0.2741\n",
      "Epoch 64/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8296 - loss: 0.4797 - val_accuracy: 0.9177 - val_loss: 0.2703\n",
      "Epoch 65/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8367 - loss: 0.4704 - val_accuracy: 0.9158 - val_loss: 0.2660\n",
      "Epoch 66/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8362 - loss: 0.4734 - val_accuracy: 0.9187 - val_loss: 0.2644\n",
      "Epoch 67/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8335 - loss: 0.4758 - val_accuracy: 0.9215 - val_loss: 0.2601\n",
      "Epoch 68/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8358 - loss: 0.4713 - val_accuracy: 0.9218 - val_loss: 0.2555\n",
      "Epoch 69/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8366 - loss: 0.4599 - val_accuracy: 0.9223 - val_loss: 0.2555\n",
      "Epoch 70/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8441 - loss: 0.4531 - val_accuracy: 0.9266 - val_loss: 0.2508\n",
      "Epoch 71/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8415 - loss: 0.4529 - val_accuracy: 0.9261 - val_loss: 0.2472\n",
      "Epoch 72/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8456 - loss: 0.4510 - val_accuracy: 0.9264 - val_loss: 0.2446\n",
      "Epoch 73/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8411 - loss: 0.4454 - val_accuracy: 0.9282 - val_loss: 0.2403\n",
      "Epoch 74/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8495 - loss: 0.4315 - val_accuracy: 0.9301 - val_loss: 0.2395\n",
      "Epoch 75/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8467 - loss: 0.4382 - val_accuracy: 0.9308 - val_loss: 0.2354\n",
      "Epoch 76/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8485 - loss: 0.4368 - val_accuracy: 0.9324 - val_loss: 0.2326\n",
      "Epoch 77/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8481 - loss: 0.4317 - val_accuracy: 0.9328 - val_loss: 0.2306\n",
      "Epoch 78/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8469 - loss: 0.4353 - val_accuracy: 0.9343 - val_loss: 0.2276\n",
      "Epoch 79/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8507 - loss: 0.4347 - val_accuracy: 0.9370 - val_loss: 0.2253\n",
      "Epoch 80/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8515 - loss: 0.4231 - val_accuracy: 0.9370 - val_loss: 0.2240\n",
      "Epoch 81/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8542 - loss: 0.4201 - val_accuracy: 0.9365 - val_loss: 0.2219\n",
      "Epoch 82/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8530 - loss: 0.4186 - val_accuracy: 0.9371 - val_loss: 0.2194\n",
      "Epoch 83/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8557 - loss: 0.4114 - val_accuracy: 0.9374 - val_loss: 0.2172\n",
      "Epoch 84/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8563 - loss: 0.4131 - val_accuracy: 0.9377 - val_loss: 0.2150\n",
      "Epoch 85/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.8561 - loss: 0.4062 - val_accuracy: 0.9397 - val_loss: 0.2131\n",
      "Epoch 86/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8581 - loss: 0.4093 - val_accuracy: 0.9395 - val_loss: 0.2101\n",
      "Epoch 87/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8582 - loss: 0.4039 - val_accuracy: 0.9391 - val_loss: 0.2079\n",
      "Epoch 88/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8617 - loss: 0.3902 - val_accuracy: 0.9408 - val_loss: 0.2066\n",
      "Epoch 89/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8613 - loss: 0.3931 - val_accuracy: 0.9381 - val_loss: 0.2058\n",
      "Epoch 90/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8655 - loss: 0.3936 - val_accuracy: 0.9421 - val_loss: 0.2035\n",
      "Epoch 91/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8658 - loss: 0.3852 - val_accuracy: 0.9413 - val_loss: 0.2006\n",
      "Epoch 92/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8633 - loss: 0.3940 - val_accuracy: 0.9423 - val_loss: 0.1990\n",
      "Epoch 93/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8603 - loss: 0.3985 - val_accuracy: 0.9425 - val_loss: 0.1985\n",
      "Epoch 94/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8667 - loss: 0.3838 - val_accuracy: 0.9382 - val_loss: 0.1978\n",
      "Epoch 95/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8688 - loss: 0.3795 - val_accuracy: 0.9412 - val_loss: 0.1949\n",
      "Epoch 96/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8671 - loss: 0.3808 - val_accuracy: 0.9409 - val_loss: 0.1916\n",
      "Epoch 97/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8698 - loss: 0.3743 - val_accuracy: 0.9450 - val_loss: 0.1898\n",
      "Epoch 98/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8701 - loss: 0.3714 - val_accuracy: 0.9446 - val_loss: 0.1888\n",
      "Epoch 99/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.8695 - loss: 0.3681 - val_accuracy: 0.9465 - val_loss: 0.1870\n",
      "Epoch 100/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8657 - loss: 0.3808 - val_accuracy: 0.9446 - val_loss: 0.1875\n",
      "Epoch 101/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8740 - loss: 0.3614 - val_accuracy: 0.9471 - val_loss: 0.1854\n",
      "Epoch 102/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8717 - loss: 0.3676 - val_accuracy: 0.9472 - val_loss: 0.1840\n",
      "Epoch 103/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8726 - loss: 0.3665 - val_accuracy: 0.9469 - val_loss: 0.1810\n",
      "Epoch 104/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8784 - loss: 0.3553 - val_accuracy: 0.9477 - val_loss: 0.1818\n",
      "Epoch 105/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8756 - loss: 0.3582 - val_accuracy: 0.9464 - val_loss: 0.1797\n",
      "Epoch 106/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8748 - loss: 0.3602 - val_accuracy: 0.9476 - val_loss: 0.1793\n",
      "Epoch 107/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8775 - loss: 0.3524 - val_accuracy: 0.9488 - val_loss: 0.1752\n",
      "Epoch 108/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8810 - loss: 0.3442 - val_accuracy: 0.9490 - val_loss: 0.1749\n",
      "Epoch 109/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.8717 - loss: 0.3621 - val_accuracy: 0.9492 - val_loss: 0.1736\n",
      "Epoch 110/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8775 - loss: 0.3536 - val_accuracy: 0.9508 - val_loss: 0.1725\n",
      "Epoch 111/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8772 - loss: 0.3530 - val_accuracy: 0.9505 - val_loss: 0.1730\n",
      "Epoch 112/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8785 - loss: 0.3491 - val_accuracy: 0.9483 - val_loss: 0.1711\n",
      "Epoch 113/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8784 - loss: 0.3505 - val_accuracy: 0.9504 - val_loss: 0.1690\n",
      "Epoch 114/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.8769 - loss: 0.3520 - val_accuracy: 0.9511 - val_loss: 0.1684\n",
      "Epoch 115/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8827 - loss: 0.3393 - val_accuracy: 0.9523 - val_loss: 0.1651\n",
      "Epoch 116/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.8748 - loss: 0.3543 - val_accuracy: 0.9514 - val_loss: 0.1660\n",
      "Epoch 117/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8825 - loss: 0.3362 - val_accuracy: 0.9502 - val_loss: 0.1666\n",
      "Epoch 118/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8803 - loss: 0.3439 - val_accuracy: 0.9523 - val_loss: 0.1631\n",
      "Epoch 119/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8880 - loss: 0.3298 - val_accuracy: 0.9525 - val_loss: 0.1624\n",
      "Epoch 120/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8845 - loss: 0.3343 - val_accuracy: 0.9514 - val_loss: 0.1620\n",
      "Epoch 121/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8811 - loss: 0.3392 - val_accuracy: 0.9547 - val_loss: 0.1612\n",
      "Epoch 122/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8860 - loss: 0.3343 - val_accuracy: 0.9542 - val_loss: 0.1587\n",
      "Epoch 123/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8861 - loss: 0.3299 - val_accuracy: 0.9530 - val_loss: 0.1589\n",
      "Epoch 124/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8862 - loss: 0.3284 - val_accuracy: 0.9555 - val_loss: 0.1558\n",
      "Epoch 125/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8845 - loss: 0.3305 - val_accuracy: 0.9548 - val_loss: 0.1565\n",
      "Epoch 126/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8878 - loss: 0.3272 - val_accuracy: 0.9561 - val_loss: 0.1566\n",
      "Epoch 127/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8870 - loss: 0.3202 - val_accuracy: 0.9546 - val_loss: 0.1575\n",
      "Epoch 128/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8901 - loss: 0.3226 - val_accuracy: 0.9560 - val_loss: 0.1531\n",
      "Epoch 129/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8882 - loss: 0.3230 - val_accuracy: 0.9553 - val_loss: 0.1545\n",
      "Epoch 130/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8888 - loss: 0.3180 - val_accuracy: 0.9565 - val_loss: 0.1525\n",
      "Epoch 131/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8874 - loss: 0.3197 - val_accuracy: 0.9557 - val_loss: 0.1514\n",
      "Epoch 132/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8917 - loss: 0.3119 - val_accuracy: 0.9553 - val_loss: 0.1514\n",
      "Epoch 133/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8918 - loss: 0.3144 - val_accuracy: 0.9584 - val_loss: 0.1485\n",
      "Epoch 134/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8917 - loss: 0.3143 - val_accuracy: 0.9582 - val_loss: 0.1481\n",
      "Epoch 135/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8898 - loss: 0.3134 - val_accuracy: 0.9571 - val_loss: 0.1487\n",
      "Epoch 136/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8901 - loss: 0.3135 - val_accuracy: 0.9565 - val_loss: 0.1459\n",
      "Epoch 137/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8928 - loss: 0.3111 - val_accuracy: 0.9589 - val_loss: 0.1439\n",
      "Epoch 138/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8944 - loss: 0.3138 - val_accuracy: 0.9579 - val_loss: 0.1445\n",
      "Epoch 139/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8925 - loss: 0.3117 - val_accuracy: 0.9582 - val_loss: 0.1445\n",
      "Epoch 140/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8938 - loss: 0.3092 - val_accuracy: 0.9580 - val_loss: 0.1445\n",
      "Epoch 141/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8909 - loss: 0.3097 - val_accuracy: 0.9601 - val_loss: 0.1429\n",
      "Epoch 142/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8927 - loss: 0.3083 - val_accuracy: 0.9598 - val_loss: 0.1406\n",
      "Epoch 143/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8957 - loss: 0.3066 - val_accuracy: 0.9612 - val_loss: 0.1410\n",
      "Epoch 144/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.8992 - loss: 0.2877 - val_accuracy: 0.9602 - val_loss: 0.1395\n",
      "Epoch 145/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8956 - loss: 0.3012 - val_accuracy: 0.9611 - val_loss: 0.1382\n",
      "Epoch 146/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8935 - loss: 0.3070 - val_accuracy: 0.9616 - val_loss: 0.1382\n",
      "Epoch 147/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8990 - loss: 0.2932 - val_accuracy: 0.9625 - val_loss: 0.1367\n",
      "Epoch 148/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8974 - loss: 0.2991 - val_accuracy: 0.9608 - val_loss: 0.1380\n",
      "Epoch 149/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8985 - loss: 0.2913 - val_accuracy: 0.9615 - val_loss: 0.1355\n",
      "Epoch 150/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8947 - loss: 0.2986 - val_accuracy: 0.9610 - val_loss: 0.1345\n",
      "Epoch 151/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8972 - loss: 0.3009 - val_accuracy: 0.9619 - val_loss: 0.1352\n",
      "Epoch 152/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9024 - loss: 0.2834 - val_accuracy: 0.9621 - val_loss: 0.1351\n",
      "Epoch 153/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8979 - loss: 0.2912 - val_accuracy: 0.9624 - val_loss: 0.1336\n",
      "Epoch 154/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.8979 - loss: 0.2912 - val_accuracy: 0.9615 - val_loss: 0.1315\n",
      "Epoch 155/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8995 - loss: 0.2812 - val_accuracy: 0.9615 - val_loss: 0.1336\n",
      "Epoch 156/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9018 - loss: 0.2939 - val_accuracy: 0.9645 - val_loss: 0.1299\n",
      "Epoch 157/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8979 - loss: 0.2883 - val_accuracy: 0.9624 - val_loss: 0.1295\n",
      "Epoch 158/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9020 - loss: 0.2802 - val_accuracy: 0.9619 - val_loss: 0.1298\n",
      "Epoch 159/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.9018 - loss: 0.2844 - val_accuracy: 0.9641 - val_loss: 0.1281\n",
      "Epoch 160/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9055 - loss: 0.2842 - val_accuracy: 0.9641 - val_loss: 0.1290\n",
      "Epoch 161/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9015 - loss: 0.2859 - val_accuracy: 0.9622 - val_loss: 0.1288\n",
      "Epoch 162/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9038 - loss: 0.2830 - val_accuracy: 0.9629 - val_loss: 0.1278\n",
      "Epoch 163/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9028 - loss: 0.2828 - val_accuracy: 0.9622 - val_loss: 0.1279\n",
      "Epoch 164/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9043 - loss: 0.2840 - val_accuracy: 0.9620 - val_loss: 0.1263\n",
      "Epoch 165/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9016 - loss: 0.2877 - val_accuracy: 0.9634 - val_loss: 0.1271\n",
      "Epoch 166/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8995 - loss: 0.2890 - val_accuracy: 0.9643 - val_loss: 0.1257\n",
      "Epoch 167/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9034 - loss: 0.2809 - val_accuracy: 0.9650 - val_loss: 0.1245\n",
      "Epoch 168/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9041 - loss: 0.2731 - val_accuracy: 0.9643 - val_loss: 0.1241\n",
      "Epoch 169/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9045 - loss: 0.2737 - val_accuracy: 0.9633 - val_loss: 0.1241\n",
      "Epoch 170/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9027 - loss: 0.2825 - val_accuracy: 0.9645 - val_loss: 0.1247\n",
      "Epoch 171/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9061 - loss: 0.2771 - val_accuracy: 0.9650 - val_loss: 0.1239\n",
      "Epoch 172/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9066 - loss: 0.2684 - val_accuracy: 0.9650 - val_loss: 0.1203\n",
      "Epoch 173/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9059 - loss: 0.2754 - val_accuracy: 0.9664 - val_loss: 0.1207\n",
      "Epoch 174/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9094 - loss: 0.2635 - val_accuracy: 0.9654 - val_loss: 0.1203\n",
      "Epoch 175/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9066 - loss: 0.2697 - val_accuracy: 0.9663 - val_loss: 0.1208\n",
      "Epoch 176/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9128 - loss: 0.2592 - val_accuracy: 0.9666 - val_loss: 0.1204\n",
      "Epoch 177/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9101 - loss: 0.2577 - val_accuracy: 0.9671 - val_loss: 0.1186\n",
      "Epoch 178/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.9050 - loss: 0.2700 - val_accuracy: 0.9672 - val_loss: 0.1188\n",
      "Epoch 179/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9047 - loss: 0.2704 - val_accuracy: 0.9658 - val_loss: 0.1192\n",
      "Epoch 180/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9093 - loss: 0.2642 - val_accuracy: 0.9672 - val_loss: 0.1181\n",
      "Epoch 181/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9080 - loss: 0.2690 - val_accuracy: 0.9664 - val_loss: 0.1193\n",
      "Epoch 182/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9082 - loss: 0.2661 - val_accuracy: 0.9673 - val_loss: 0.1176\n",
      "Epoch 183/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9085 - loss: 0.2630 - val_accuracy: 0.9668 - val_loss: 0.1173\n",
      "Epoch 184/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9049 - loss: 0.2713 - val_accuracy: 0.9667 - val_loss: 0.1158\n",
      "Epoch 185/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.9097 - loss: 0.2619 - val_accuracy: 0.9673 - val_loss: 0.1146\n",
      "Epoch 186/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.9124 - loss: 0.2579 - val_accuracy: 0.9668 - val_loss: 0.1135\n",
      "Epoch 187/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9127 - loss: 0.2552 - val_accuracy: 0.9678 - val_loss: 0.1134\n",
      "Epoch 188/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9063 - loss: 0.2672 - val_accuracy: 0.9670 - val_loss: 0.1128\n",
      "Epoch 189/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.9139 - loss: 0.2521 - val_accuracy: 0.9671 - val_loss: 0.1138\n",
      "Epoch 190/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9059 - loss: 0.2629 - val_accuracy: 0.9675 - val_loss: 0.1131\n",
      "Epoch 191/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9087 - loss: 0.2643 - val_accuracy: 0.9687 - val_loss: 0.1130\n",
      "Epoch 192/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9111 - loss: 0.2614 - val_accuracy: 0.9677 - val_loss: 0.1137\n",
      "Epoch 193/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9101 - loss: 0.2597 - val_accuracy: 0.9685 - val_loss: 0.1118\n",
      "Epoch 194/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9115 - loss: 0.2648 - val_accuracy: 0.9680 - val_loss: 0.1111\n",
      "Epoch 195/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9156 - loss: 0.2485 - val_accuracy: 0.9698 - val_loss: 0.1104\n",
      "Epoch 196/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9135 - loss: 0.2562 - val_accuracy: 0.9696 - val_loss: 0.1099\n",
      "Epoch 197/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9134 - loss: 0.2545 - val_accuracy: 0.9698 - val_loss: 0.1106\n",
      "Epoch 198/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9148 - loss: 0.2487 - val_accuracy: 0.9698 - val_loss: 0.1082\n",
      "Epoch 199/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9102 - loss: 0.2587 - val_accuracy: 0.9686 - val_loss: 0.1096\n",
      "Epoch 200/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9159 - loss: 0.2512 - val_accuracy: 0.9694 - val_loss: 0.1073\n",
      "Epoch 201/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9108 - loss: 0.2585 - val_accuracy: 0.9690 - val_loss: 0.1087\n",
      "Epoch 202/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9134 - loss: 0.2464 - val_accuracy: 0.9689 - val_loss: 0.1078\n",
      "Epoch 203/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9093 - loss: 0.2629 - val_accuracy: 0.9694 - val_loss: 0.1076\n",
      "Epoch 204/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9157 - loss: 0.2516 - val_accuracy: 0.9698 - val_loss: 0.1066\n",
      "Epoch 205/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9151 - loss: 0.2537 - val_accuracy: 0.9682 - val_loss: 0.1068\n",
      "Epoch 206/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9131 - loss: 0.2558 - val_accuracy: 0.9686 - val_loss: 0.1070\n",
      "Epoch 207/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9188 - loss: 0.2376 - val_accuracy: 0.9689 - val_loss: 0.1056\n",
      "Epoch 208/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9170 - loss: 0.2370 - val_accuracy: 0.9694 - val_loss: 0.1068\n",
      "Epoch 209/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9149 - loss: 0.2450 - val_accuracy: 0.9694 - val_loss: 0.1061\n",
      "Epoch 210/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9141 - loss: 0.2446 - val_accuracy: 0.9707 - val_loss: 0.1055\n",
      "Epoch 211/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9184 - loss: 0.2432 - val_accuracy: 0.9707 - val_loss: 0.1047\n",
      "Epoch 212/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - accuracy: 0.9151 - loss: 0.2476 - val_accuracy: 0.9682 - val_loss: 0.1051\n",
      "Epoch 213/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9145 - loss: 0.2517 - val_accuracy: 0.9686 - val_loss: 0.1047\n",
      "Epoch 214/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9180 - loss: 0.2396 - val_accuracy: 0.9704 - val_loss: 0.1034\n",
      "Epoch 215/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.9136 - loss: 0.2498 - val_accuracy: 0.9714 - val_loss: 0.1042\n",
      "Epoch 216/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9170 - loss: 0.2353 - val_accuracy: 0.9700 - val_loss: 0.1031\n",
      "Epoch 217/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9219 - loss: 0.2286 - val_accuracy: 0.9704 - val_loss: 0.1039\n",
      "Epoch 218/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9154 - loss: 0.2433 - val_accuracy: 0.9700 - val_loss: 0.1031\n",
      "Epoch 219/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9198 - loss: 0.2417 - val_accuracy: 0.9699 - val_loss: 0.1026\n",
      "Epoch 220/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9220 - loss: 0.2290 - val_accuracy: 0.9709 - val_loss: 0.1024\n",
      "Epoch 221/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9196 - loss: 0.2324 - val_accuracy: 0.9699 - val_loss: 0.1016\n",
      "Epoch 222/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9142 - loss: 0.2475 - val_accuracy: 0.9701 - val_loss: 0.1018\n",
      "Epoch 223/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9201 - loss: 0.2379 - val_accuracy: 0.9701 - val_loss: 0.1008\n",
      "Epoch 224/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9209 - loss: 0.2295 - val_accuracy: 0.9695 - val_loss: 0.1012\n",
      "Epoch 225/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9187 - loss: 0.2331 - val_accuracy: 0.9690 - val_loss: 0.1009\n",
      "Epoch 226/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.9178 - loss: 0.2386 - val_accuracy: 0.9693 - val_loss: 0.1005\n",
      "Epoch 227/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9186 - loss: 0.2367 - val_accuracy: 0.9695 - val_loss: 0.1015\n",
      "Epoch 228/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9205 - loss: 0.2341 - val_accuracy: 0.9705 - val_loss: 0.1011\n",
      "Epoch 229/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9201 - loss: 0.2365 - val_accuracy: 0.9704 - val_loss: 0.1002\n",
      "Epoch 230/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9208 - loss: 0.2301 - val_accuracy: 0.9701 - val_loss: 0.0998\n",
      "Epoch 231/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9198 - loss: 0.2336 - val_accuracy: 0.9701 - val_loss: 0.0993\n",
      "Epoch 232/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9204 - loss: 0.2308 - val_accuracy: 0.9713 - val_loss: 0.1003\n",
      "Epoch 233/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9219 - loss: 0.2290 - val_accuracy: 0.9722 - val_loss: 0.0994\n",
      "Epoch 234/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9226 - loss: 0.2292 - val_accuracy: 0.9713 - val_loss: 0.0980\n",
      "Epoch 235/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9229 - loss: 0.2314 - val_accuracy: 0.9707 - val_loss: 0.0984\n",
      "Epoch 236/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9216 - loss: 0.2258 - val_accuracy: 0.9719 - val_loss: 0.0995\n",
      "Epoch 237/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9262 - loss: 0.2229 - val_accuracy: 0.9726 - val_loss: 0.0980\n",
      "Epoch 238/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9223 - loss: 0.2227 - val_accuracy: 0.9701 - val_loss: 0.0985\n",
      "Epoch 239/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9212 - loss: 0.2281 - val_accuracy: 0.9724 - val_loss: 0.0986\n",
      "Epoch 240/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9209 - loss: 0.2288 - val_accuracy: 0.9708 - val_loss: 0.0968\n",
      "Epoch 241/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9203 - loss: 0.2371 - val_accuracy: 0.9741 - val_loss: 0.0948\n",
      "Epoch 242/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9228 - loss: 0.2253 - val_accuracy: 0.9738 - val_loss: 0.0945\n",
      "Epoch 243/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9177 - loss: 0.2333 - val_accuracy: 0.9741 - val_loss: 0.0945\n",
      "Epoch 244/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9239 - loss: 0.2268 - val_accuracy: 0.9732 - val_loss: 0.0964\n",
      "Epoch 245/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.9228 - loss: 0.2223 - val_accuracy: 0.9721 - val_loss: 0.0978\n",
      "Epoch 246/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9235 - loss: 0.2247 - val_accuracy: 0.9709 - val_loss: 0.0974\n",
      "Epoch 247/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9218 - loss: 0.2336 - val_accuracy: 0.9726 - val_loss: 0.0960\n",
      "Epoch 248/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9225 - loss: 0.2284 - val_accuracy: 0.9708 - val_loss: 0.0956\n",
      "Epoch 249/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9236 - loss: 0.2243 - val_accuracy: 0.9713 - val_loss: 0.0969\n",
      "Epoch 250/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9231 - loss: 0.2187 - val_accuracy: 0.9723 - val_loss: 0.0955\n",
      "Epoch 251/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9255 - loss: 0.2203 - val_accuracy: 0.9727 - val_loss: 0.0955\n",
      "Epoch 252/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9243 - loss: 0.2210 - val_accuracy: 0.9717 - val_loss: 0.0946\n",
      "Epoch 253/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9227 - loss: 0.2275 - val_accuracy: 0.9737 - val_loss: 0.0949\n",
      "Epoch 254/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9235 - loss: 0.2238 - val_accuracy: 0.9745 - val_loss: 0.0946\n",
      "Epoch 255/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9230 - loss: 0.2299 - val_accuracy: 0.9735 - val_loss: 0.0944\n",
      "Epoch 256/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9228 - loss: 0.2281 - val_accuracy: 0.9730 - val_loss: 0.0948\n",
      "Epoch 257/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9256 - loss: 0.2169 - val_accuracy: 0.9726 - val_loss: 0.0935\n",
      "Epoch 258/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9222 - loss: 0.2237 - val_accuracy: 0.9730 - val_loss: 0.0930\n",
      "Epoch 259/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9267 - loss: 0.2201 - val_accuracy: 0.9717 - val_loss: 0.0933\n",
      "Epoch 260/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.9257 - loss: 0.2206 - val_accuracy: 0.9719 - val_loss: 0.0928\n",
      "Epoch 261/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9223 - loss: 0.2243 - val_accuracy: 0.9735 - val_loss: 0.0942\n",
      "Epoch 262/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9282 - loss: 0.2100 - val_accuracy: 0.9728 - val_loss: 0.0944\n",
      "Epoch 263/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9256 - loss: 0.2203 - val_accuracy: 0.9722 - val_loss: 0.0936\n",
      "Epoch 264/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9261 - loss: 0.2166 - val_accuracy: 0.9745 - val_loss: 0.0925\n",
      "Epoch 265/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9300 - loss: 0.2110 - val_accuracy: 0.9732 - val_loss: 0.0925\n",
      "Epoch 266/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9248 - loss: 0.2197 - val_accuracy: 0.9718 - val_loss: 0.0919\n",
      "Epoch 267/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9231 - loss: 0.2233 - val_accuracy: 0.9731 - val_loss: 0.0916\n",
      "Epoch 268/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9257 - loss: 0.2161 - val_accuracy: 0.9717 - val_loss: 0.0936\n",
      "Epoch 269/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9258 - loss: 0.2190 - val_accuracy: 0.9733 - val_loss: 0.0932\n",
      "Epoch 270/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9262 - loss: 0.2127 - val_accuracy: 0.9721 - val_loss: 0.0930\n",
      "Epoch 271/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9313 - loss: 0.2074 - val_accuracy: 0.9733 - val_loss: 0.0918\n",
      "Epoch 272/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9260 - loss: 0.2091 - val_accuracy: 0.9741 - val_loss: 0.0896\n",
      "Epoch 273/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9240 - loss: 0.2139 - val_accuracy: 0.9715 - val_loss: 0.0926\n",
      "Epoch 274/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9252 - loss: 0.2158 - val_accuracy: 0.9735 - val_loss: 0.0912\n",
      "Epoch 275/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9268 - loss: 0.2109 - val_accuracy: 0.9722 - val_loss: 0.0908\n",
      "Epoch 276/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9288 - loss: 0.2092 - val_accuracy: 0.9740 - val_loss: 0.0909\n",
      "Epoch 277/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9268 - loss: 0.2099 - val_accuracy: 0.9742 - val_loss: 0.0905\n",
      "Epoch 278/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9269 - loss: 0.2097 - val_accuracy: 0.9735 - val_loss: 0.0897\n",
      "Epoch 279/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9278 - loss: 0.2157 - val_accuracy: 0.9741 - val_loss: 0.0909\n",
      "Epoch 280/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9269 - loss: 0.2111 - val_accuracy: 0.9736 - val_loss: 0.0910\n",
      "Epoch 281/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9274 - loss: 0.2127 - val_accuracy: 0.9735 - val_loss: 0.0913\n",
      "Epoch 282/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9266 - loss: 0.2145 - val_accuracy: 0.9736 - val_loss: 0.0894\n",
      "Epoch 283/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9250 - loss: 0.2167 - val_accuracy: 0.9730 - val_loss: 0.0904\n",
      "Epoch 284/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9251 - loss: 0.2209 - val_accuracy: 0.9754 - val_loss: 0.0892\n",
      "Epoch 285/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9261 - loss: 0.2135 - val_accuracy: 0.9747 - val_loss: 0.0891\n",
      "Epoch 286/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9256 - loss: 0.2166 - val_accuracy: 0.9742 - val_loss: 0.0898\n",
      "Epoch 287/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9279 - loss: 0.2082 - val_accuracy: 0.9756 - val_loss: 0.0890\n",
      "Epoch 288/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9301 - loss: 0.2032 - val_accuracy: 0.9751 - val_loss: 0.0895\n",
      "Epoch 289/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9290 - loss: 0.2059 - val_accuracy: 0.9749 - val_loss: 0.0889\n",
      "Epoch 290/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9334 - loss: 0.2014 - val_accuracy: 0.9737 - val_loss: 0.0900\n",
      "Epoch 291/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9320 - loss: 0.2022 - val_accuracy: 0.9754 - val_loss: 0.0880\n",
      "Epoch 292/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.9289 - loss: 0.2073 - val_accuracy: 0.9751 - val_loss: 0.0879\n",
      "Epoch 293/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9313 - loss: 0.2012 - val_accuracy: 0.9752 - val_loss: 0.0889\n",
      "Epoch 294/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9321 - loss: 0.2058 - val_accuracy: 0.9749 - val_loss: 0.0895\n",
      "Epoch 295/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9302 - loss: 0.2102 - val_accuracy: 0.9749 - val_loss: 0.0871\n",
      "Epoch 296/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9282 - loss: 0.2100 - val_accuracy: 0.9740 - val_loss: 0.0874\n",
      "Epoch 297/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9262 - loss: 0.2101 - val_accuracy: 0.9750 - val_loss: 0.0879\n",
      "Epoch 298/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9303 - loss: 0.2078 - val_accuracy: 0.9747 - val_loss: 0.0867\n",
      "Epoch 299/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9299 - loss: 0.2026 - val_accuracy: 0.9758 - val_loss: 0.0878\n",
      "Epoch 300/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9261 - loss: 0.2101 - val_accuracy: 0.9751 - val_loss: 0.0880\n",
      "Epoch 301/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9331 - loss: 0.1990 - val_accuracy: 0.9747 - val_loss: 0.0871\n",
      "Epoch 302/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9311 - loss: 0.2056 - val_accuracy: 0.9741 - val_loss: 0.0872\n",
      "Epoch 303/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9302 - loss: 0.2009 - val_accuracy: 0.9738 - val_loss: 0.0877\n",
      "Epoch 304/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9295 - loss: 0.1999 - val_accuracy: 0.9742 - val_loss: 0.0871\n",
      "Epoch 305/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9276 - loss: 0.2070 - val_accuracy: 0.9760 - val_loss: 0.0872\n",
      "Epoch 306/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9325 - loss: 0.1996 - val_accuracy: 0.9749 - val_loss: 0.0873\n",
      "Epoch 307/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9282 - loss: 0.2106 - val_accuracy: 0.9751 - val_loss: 0.0869\n",
      "Epoch 308/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9299 - loss: 0.2019 - val_accuracy: 0.9759 - val_loss: 0.0856\n",
      "Epoch 309/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9314 - loss: 0.2001 - val_accuracy: 0.9737 - val_loss: 0.0854\n",
      "Epoch 310/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9286 - loss: 0.2077 - val_accuracy: 0.9736 - val_loss: 0.0859\n",
      "Epoch 311/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 26ms/step - accuracy: 0.9282 - loss: 0.2067 - val_accuracy: 0.9752 - val_loss: 0.0856\n",
      "Epoch 312/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9351 - loss: 0.1885 - val_accuracy: 0.9759 - val_loss: 0.0859\n",
      "Epoch 313/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9317 - loss: 0.2015 - val_accuracy: 0.9754 - val_loss: 0.0858\n",
      "Epoch 314/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9304 - loss: 0.2031 - val_accuracy: 0.9755 - val_loss: 0.0856\n",
      "Epoch 315/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9331 - loss: 0.1933 - val_accuracy: 0.9761 - val_loss: 0.0849\n",
      "Epoch 316/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - accuracy: 0.9326 - loss: 0.1987 - val_accuracy: 0.9756 - val_loss: 0.0854\n",
      "Epoch 317/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9317 - loss: 0.2013 - val_accuracy: 0.9749 - val_loss: 0.0858\n",
      "Epoch 318/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9349 - loss: 0.1911 - val_accuracy: 0.9747 - val_loss: 0.0854\n",
      "Epoch 319/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9292 - loss: 0.2069 - val_accuracy: 0.9756 - val_loss: 0.0849\n",
      "Epoch 320/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9305 - loss: 0.2003 - val_accuracy: 0.9750 - val_loss: 0.0853\n",
      "Epoch 321/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9338 - loss: 0.1949 - val_accuracy: 0.9756 - val_loss: 0.0847\n",
      "Epoch 322/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 26ms/step - accuracy: 0.9303 - loss: 0.2052 - val_accuracy: 0.9751 - val_loss: 0.0849\n",
      "Epoch 323/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 27ms/step - accuracy: 0.9305 - loss: 0.2046 - val_accuracy: 0.9740 - val_loss: 0.0853\n",
      "Epoch 324/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9303 - loss: 0.2001 - val_accuracy: 0.9755 - val_loss: 0.0854\n",
      "Epoch 325/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 27ms/step - accuracy: 0.9333 - loss: 0.1930 - val_accuracy: 0.9756 - val_loss: 0.0842\n",
      "Epoch 326/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9315 - loss: 0.1999 - val_accuracy: 0.9760 - val_loss: 0.0832\n",
      "Epoch 327/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9302 - loss: 0.2059 - val_accuracy: 0.9756 - val_loss: 0.0847\n",
      "Epoch 328/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9297 - loss: 0.1993 - val_accuracy: 0.9755 - val_loss: 0.0841\n",
      "Epoch 329/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9314 - loss: 0.2011 - val_accuracy: 0.9749 - val_loss: 0.0856\n",
      "Epoch 330/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9318 - loss: 0.2032 - val_accuracy: 0.9760 - val_loss: 0.0836\n",
      "Epoch 331/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9337 - loss: 0.1944 - val_accuracy: 0.9758 - val_loss: 0.0836\n",
      "Epoch 332/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 26ms/step - accuracy: 0.9325 - loss: 0.1957 - val_accuracy: 0.9755 - val_loss: 0.0840\n",
      "Epoch 333/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9323 - loss: 0.1961 - val_accuracy: 0.9756 - val_loss: 0.0842\n",
      "Epoch 334/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9343 - loss: 0.1917 - val_accuracy: 0.9751 - val_loss: 0.0853\n",
      "Epoch 335/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9364 - loss: 0.1901 - val_accuracy: 0.9758 - val_loss: 0.0847\n",
      "Epoch 336/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9331 - loss: 0.1980 - val_accuracy: 0.9765 - val_loss: 0.0837\n",
      "Epoch 337/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9304 - loss: 0.2043 - val_accuracy: 0.9756 - val_loss: 0.0836\n",
      "Epoch 338/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9322 - loss: 0.2000 - val_accuracy: 0.9756 - val_loss: 0.0836\n",
      "Epoch 339/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9354 - loss: 0.1869 - val_accuracy: 0.9759 - val_loss: 0.0837\n",
      "Epoch 340/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9322 - loss: 0.1939 - val_accuracy: 0.9764 - val_loss: 0.0833\n",
      "Epoch 341/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9334 - loss: 0.1921 - val_accuracy: 0.9758 - val_loss: 0.0841\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.9798 - loss: 0.0645\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9769 - loss: 0.0801\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9718 - loss: 0.0999\n",
      "Training Accuracy: 98.00%\n",
      "Validation Accuracy: 97.60%\n",
      "Test Accuracy: 97.00%\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
      "Test Accuracy with emotion labels: 97.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler  # Using RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Raw_MAIN_DATASET_IMPUTATION_after_deleting_stai_badge_activity_step_goal.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "df = df.drop(['id', 'date'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Emotions', axis=1)\n",
    "y = df['Emotions']\n",
    "\n",
    "# Convert categorical target to numeric using label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Check the initial class distribution\n",
    "print(\"Class distribution before oversampling:\", Counter(y))\n",
    "\n",
    "# Oversampling to handle class imbalance using RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after oversampling\n",
    "print(\"Class distribution after oversampling:\", Counter(y))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Feature Selection\n",
    "selector = SelectKBest(f_classif, k=60)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_val = selector.transform(X_val)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  # Output layer (number of unique emotions)\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,  # Increased epochs\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Convert numeric predictions back to emotion labels\n",
    "y_test_pred_labels = le.inverse_transform(y_test_pred_classes)\n",
    "y_test_true_labels = le.inverse_transform(y_test)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "test_acc = accuracy_score(y_test_true_labels, y_test_pred_labels)\n",
    "print(f\"Test Accuracy with emotion labels: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:41:12.492720: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-04 10:41:12.573866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-04 10:41:12.700507: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-04 10:41:12.724436: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-04 10:41:12.786765: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 10:41:15.669825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling: Counter({0: 5443, 3: 587, 5: 480, 4: 451, 8: 207, 7: 204, 6: 59, 1: 2, 2: 1})\n",
      "Class distribution after oversampling: Counter({0: 5443, 3: 5443, 7: 5443, 8: 5443, 4: 5443, 5: 5443, 6: 5443, 1: 5443, 2: 5443})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2024-10-04 10:41:19.231032: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 32ms/step - accuracy: 0.2734 - loss: 2.5893 - val_accuracy: 0.5131 - val_loss: 1.3697\n",
      "Epoch 2/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.4249 - loss: 1.8404 - val_accuracy: 0.5773 - val_loss: 1.2007\n",
      "Epoch 3/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 32ms/step - accuracy: 0.4648 - loss: 1.6500 - val_accuracy: 0.6183 - val_loss: 1.1102\n",
      "Epoch 4/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.4975 - loss: 1.4844 - val_accuracy: 0.6401 - val_loss: 1.0499\n",
      "Epoch 5/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.5126 - loss: 1.4009 - val_accuracy: 0.6545 - val_loss: 1.0005\n",
      "Epoch 6/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 32ms/step - accuracy: 0.5331 - loss: 1.3305 - val_accuracy: 0.6724 - val_loss: 0.9584\n",
      "Epoch 7/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.5512 - loss: 1.2735 - val_accuracy: 0.6869 - val_loss: 0.9191\n",
      "Epoch 8/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.5666 - loss: 1.2239 - val_accuracy: 0.6961 - val_loss: 0.8882\n",
      "Epoch 9/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.5769 - loss: 1.1789 - val_accuracy: 0.7085 - val_loss: 0.8520\n",
      "Epoch 10/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - accuracy: 0.5921 - loss: 1.1221 - val_accuracy: 0.7166 - val_loss: 0.8222\n",
      "Epoch 11/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.6079 - loss: 1.0920 - val_accuracy: 0.7285 - val_loss: 0.8001\n",
      "Epoch 12/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.6124 - loss: 1.0572 - val_accuracy: 0.7336 - val_loss: 0.7743\n",
      "Epoch 13/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.6293 - loss: 1.0233 - val_accuracy: 0.7433 - val_loss: 0.7480\n",
      "Epoch 14/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.6334 - loss: 1.0086 - val_accuracy: 0.7524 - val_loss: 0.7260\n",
      "Epoch 15/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.6481 - loss: 0.9752 - val_accuracy: 0.7666 - val_loss: 0.7056\n",
      "Epoch 16/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.6568 - loss: 0.9461 - val_accuracy: 0.7719 - val_loss: 0.6843\n",
      "Epoch 17/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.6659 - loss: 0.9258 - val_accuracy: 0.7784 - val_loss: 0.6642\n",
      "Epoch 18/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.6724 - loss: 0.9051 - val_accuracy: 0.7869 - val_loss: 0.6455\n",
      "Epoch 19/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.6771 - loss: 0.8866 - val_accuracy: 0.7965 - val_loss: 0.6256\n",
      "Epoch 20/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.6829 - loss: 0.8741 - val_accuracy: 0.8051 - val_loss: 0.6108\n",
      "Epoch 21/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 28ms/step - accuracy: 0.6975 - loss: 0.8433 - val_accuracy: 0.8085 - val_loss: 0.5921\n",
      "Epoch 22/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.7020 - loss: 0.8325 - val_accuracy: 0.8121 - val_loss: 0.5789\n",
      "Epoch 23/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.7039 - loss: 0.8198 - val_accuracy: 0.8211 - val_loss: 0.5615\n",
      "Epoch 24/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.7071 - loss: 0.8111 - val_accuracy: 0.8214 - val_loss: 0.5493\n",
      "Epoch 25/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.7219 - loss: 0.7796 - val_accuracy: 0.8224 - val_loss: 0.5348\n",
      "Epoch 26/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.7184 - loss: 0.7793 - val_accuracy: 0.8261 - val_loss: 0.5241\n",
      "Epoch 27/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.7239 - loss: 0.7720 - val_accuracy: 0.8327 - val_loss: 0.5089\n",
      "Epoch 28/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.7305 - loss: 0.7424 - val_accuracy: 0.8415 - val_loss: 0.4989\n",
      "Epoch 29/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 27ms/step - accuracy: 0.7359 - loss: 0.7385 - val_accuracy: 0.8464 - val_loss: 0.4886\n",
      "Epoch 30/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7394 - loss: 0.7318 - val_accuracy: 0.8474 - val_loss: 0.4791\n",
      "Epoch 31/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.7477 - loss: 0.7081 - val_accuracy: 0.8510 - val_loss: 0.4674\n",
      "Epoch 32/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7451 - loss: 0.7030 - val_accuracy: 0.8553 - val_loss: 0.4545\n",
      "Epoch 33/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.7544 - loss: 0.6839 - val_accuracy: 0.8591 - val_loss: 0.4445\n",
      "Epoch 34/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.7631 - loss: 0.6725 - val_accuracy: 0.8665 - val_loss: 0.4372\n",
      "Epoch 35/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.7574 - loss: 0.6735 - val_accuracy: 0.8654 - val_loss: 0.4291\n",
      "Epoch 36/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.7668 - loss: 0.6507 - val_accuracy: 0.8678 - val_loss: 0.4204\n",
      "Epoch 37/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.7710 - loss: 0.6397 - val_accuracy: 0.8728 - val_loss: 0.4115\n",
      "Epoch 38/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.7738 - loss: 0.6390 - val_accuracy: 0.8754 - val_loss: 0.4034\n",
      "Epoch 39/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.7746 - loss: 0.6331 - val_accuracy: 0.8779 - val_loss: 0.3944\n",
      "Epoch 40/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.7755 - loss: 0.6336 - val_accuracy: 0.8822 - val_loss: 0.3877\n",
      "Epoch 41/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.7805 - loss: 0.6152 - val_accuracy: 0.8853 - val_loss: 0.3776\n",
      "Epoch 42/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.7837 - loss: 0.6048 - val_accuracy: 0.8854 - val_loss: 0.3710\n",
      "Epoch 43/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - accuracy: 0.7865 - loss: 0.5893 - val_accuracy: 0.8884 - val_loss: 0.3676\n",
      "Epoch 44/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.7905 - loss: 0.5941 - val_accuracy: 0.8927 - val_loss: 0.3598\n",
      "Epoch 45/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.7894 - loss: 0.5862 - val_accuracy: 0.8932 - val_loss: 0.3523\n",
      "Epoch 46/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 37ms/step - accuracy: 0.7956 - loss: 0.5762 - val_accuracy: 0.8942 - val_loss: 0.3443\n",
      "Epoch 47/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.7947 - loss: 0.5810 - val_accuracy: 0.8919 - val_loss: 0.3429\n",
      "Epoch 48/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.7944 - loss: 0.5683 - val_accuracy: 0.8995 - val_loss: 0.3364\n",
      "Epoch 49/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.7974 - loss: 0.5617 - val_accuracy: 0.9005 - val_loss: 0.3301\n",
      "Epoch 50/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8043 - loss: 0.5563 - val_accuracy: 0.8993 - val_loss: 0.3261\n",
      "Epoch 51/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8053 - loss: 0.5469 - val_accuracy: 0.9039 - val_loss: 0.3226\n",
      "Epoch 52/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8067 - loss: 0.5476 - val_accuracy: 0.9042 - val_loss: 0.3160\n",
      "Epoch 53/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8114 - loss: 0.5357 - val_accuracy: 0.9029 - val_loss: 0.3140\n",
      "Epoch 54/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8138 - loss: 0.5364 - val_accuracy: 0.9033 - val_loss: 0.3082\n",
      "Epoch 55/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8087 - loss: 0.5371 - val_accuracy: 0.9066 - val_loss: 0.3033\n",
      "Epoch 56/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8115 - loss: 0.5287 - val_accuracy: 0.9095 - val_loss: 0.2981\n",
      "Epoch 57/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8122 - loss: 0.5217 - val_accuracy: 0.9104 - val_loss: 0.2931\n",
      "Epoch 58/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8193 - loss: 0.5149 - val_accuracy: 0.9098 - val_loss: 0.2900\n",
      "Epoch 59/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8203 - loss: 0.5087 - val_accuracy: 0.9163 - val_loss: 0.2853\n",
      "Epoch 60/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8176 - loss: 0.5152 - val_accuracy: 0.9171 - val_loss: 0.2813\n",
      "Epoch 61/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8233 - loss: 0.4988 - val_accuracy: 0.9168 - val_loss: 0.2802\n",
      "Epoch 62/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8257 - loss: 0.4941 - val_accuracy: 0.9185 - val_loss: 0.2727\n",
      "Epoch 63/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8226 - loss: 0.4987 - val_accuracy: 0.9182 - val_loss: 0.2706\n",
      "Epoch 64/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8323 - loss: 0.4828 - val_accuracy: 0.9177 - val_loss: 0.2683\n",
      "Epoch 65/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8305 - loss: 0.4787 - val_accuracy: 0.9220 - val_loss: 0.2649\n",
      "Epoch 66/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 36ms/step - accuracy: 0.8297 - loss: 0.4772 - val_accuracy: 0.9238 - val_loss: 0.2608\n",
      "Epoch 67/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8327 - loss: 0.4739 - val_accuracy: 0.9232 - val_loss: 0.2593\n",
      "Epoch 68/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8338 - loss: 0.4742 - val_accuracy: 0.9206 - val_loss: 0.2569\n",
      "Epoch 69/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8334 - loss: 0.4648 - val_accuracy: 0.9249 - val_loss: 0.2525\n",
      "Epoch 70/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8425 - loss: 0.4523 - val_accuracy: 0.9277 - val_loss: 0.2472\n",
      "Epoch 71/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8393 - loss: 0.4551 - val_accuracy: 0.9291 - val_loss: 0.2461\n",
      "Epoch 72/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8374 - loss: 0.4543 - val_accuracy: 0.9306 - val_loss: 0.2428\n",
      "Epoch 73/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8419 - loss: 0.4530 - val_accuracy: 0.9321 - val_loss: 0.2394\n",
      "Epoch 74/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8445 - loss: 0.4381 - val_accuracy: 0.9303 - val_loss: 0.2361\n",
      "Epoch 75/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8423 - loss: 0.4413 - val_accuracy: 0.9339 - val_loss: 0.2343\n",
      "Epoch 76/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8449 - loss: 0.4399 - val_accuracy: 0.9314 - val_loss: 0.2324\n",
      "Epoch 77/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8443 - loss: 0.4398 - val_accuracy: 0.9339 - val_loss: 0.2294\n",
      "Epoch 78/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8467 - loss: 0.4300 - val_accuracy: 0.9374 - val_loss: 0.2259\n",
      "Epoch 79/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8479 - loss: 0.4301 - val_accuracy: 0.9363 - val_loss: 0.2238\n",
      "Epoch 80/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8488 - loss: 0.4207 - val_accuracy: 0.9390 - val_loss: 0.2207\n",
      "Epoch 81/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8492 - loss: 0.4296 - val_accuracy: 0.9397 - val_loss: 0.2215\n",
      "Epoch 82/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8504 - loss: 0.4236 - val_accuracy: 0.9409 - val_loss: 0.2177\n",
      "Epoch 83/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8530 - loss: 0.4217 - val_accuracy: 0.9394 - val_loss: 0.2157\n",
      "Epoch 84/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.8500 - loss: 0.4220 - val_accuracy: 0.9397 - val_loss: 0.2149\n",
      "Epoch 85/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8553 - loss: 0.4227 - val_accuracy: 0.9425 - val_loss: 0.2111\n",
      "Epoch 86/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.8558 - loss: 0.4166 - val_accuracy: 0.9394 - val_loss: 0.2091\n",
      "Epoch 87/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8572 - loss: 0.4040 - val_accuracy: 0.9432 - val_loss: 0.2066\n",
      "Epoch 88/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8598 - loss: 0.4016 - val_accuracy: 0.9428 - val_loss: 0.2049\n",
      "Epoch 89/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8575 - loss: 0.4066 - val_accuracy: 0.9432 - val_loss: 0.2032\n",
      "Epoch 90/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8559 - loss: 0.4023 - val_accuracy: 0.9436 - val_loss: 0.2012\n",
      "Epoch 91/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.8640 - loss: 0.3915 - val_accuracy: 0.9432 - val_loss: 0.2007\n",
      "Epoch 92/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - accuracy: 0.8675 - loss: 0.3847 - val_accuracy: 0.9427 - val_loss: 0.1966\n",
      "Epoch 93/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8654 - loss: 0.3782 - val_accuracy: 0.9462 - val_loss: 0.1943\n",
      "Epoch 94/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8646 - loss: 0.3873 - val_accuracy: 0.9451 - val_loss: 0.1927\n",
      "Epoch 95/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8657 - loss: 0.3799 - val_accuracy: 0.9473 - val_loss: 0.1916\n",
      "Epoch 96/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8686 - loss: 0.3796 - val_accuracy: 0.9465 - val_loss: 0.1894\n",
      "Epoch 97/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8642 - loss: 0.3827 - val_accuracy: 0.9497 - val_loss: 0.1879\n",
      "Epoch 98/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 35ms/step - accuracy: 0.8658 - loss: 0.3846 - val_accuracy: 0.9472 - val_loss: 0.1869\n",
      "Epoch 99/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8686 - loss: 0.3787 - val_accuracy: 0.9482 - val_loss: 0.1853\n",
      "Epoch 100/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8703 - loss: 0.3774 - val_accuracy: 0.9500 - val_loss: 0.1825\n",
      "Epoch 101/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8721 - loss: 0.3651 - val_accuracy: 0.9483 - val_loss: 0.1831\n",
      "Epoch 102/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8699 - loss: 0.3735 - val_accuracy: 0.9496 - val_loss: 0.1821\n",
      "Epoch 103/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8696 - loss: 0.3714 - val_accuracy: 0.9471 - val_loss: 0.1806\n",
      "Epoch 104/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8714 - loss: 0.3632 - val_accuracy: 0.9490 - val_loss: 0.1781\n",
      "Epoch 105/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8739 - loss: 0.3624 - val_accuracy: 0.9492 - val_loss: 0.1770\n",
      "Epoch 106/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8742 - loss: 0.3599 - val_accuracy: 0.9501 - val_loss: 0.1746\n",
      "Epoch 107/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8777 - loss: 0.3515 - val_accuracy: 0.9505 - val_loss: 0.1716\n",
      "Epoch 108/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8733 - loss: 0.3623 - val_accuracy: 0.9499 - val_loss: 0.1735\n",
      "Epoch 109/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8724 - loss: 0.3639 - val_accuracy: 0.9510 - val_loss: 0.1741\n",
      "Epoch 110/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8739 - loss: 0.3579 - val_accuracy: 0.9509 - val_loss: 0.1693\n",
      "Epoch 111/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 36ms/step - accuracy: 0.8752 - loss: 0.3520 - val_accuracy: 0.9523 - val_loss: 0.1688\n",
      "Epoch 112/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8805 - loss: 0.3448 - val_accuracy: 0.9532 - val_loss: 0.1678\n",
      "Epoch 113/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8773 - loss: 0.3535 - val_accuracy: 0.9527 - val_loss: 0.1678\n",
      "Epoch 114/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8799 - loss: 0.3485 - val_accuracy: 0.9548 - val_loss: 0.1648\n",
      "Epoch 115/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8838 - loss: 0.3469 - val_accuracy: 0.9529 - val_loss: 0.1647\n",
      "Epoch 116/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8791 - loss: 0.3531 - val_accuracy: 0.9509 - val_loss: 0.1657\n",
      "Epoch 117/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8785 - loss: 0.3485 - val_accuracy: 0.9520 - val_loss: 0.1634\n",
      "Epoch 118/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8803 - loss: 0.3418 - val_accuracy: 0.9543 - val_loss: 0.1617\n",
      "Epoch 119/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8801 - loss: 0.3413 - val_accuracy: 0.9534 - val_loss: 0.1608\n",
      "Epoch 120/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - accuracy: 0.8836 - loss: 0.3300 - val_accuracy: 0.9556 - val_loss: 0.1596\n",
      "Epoch 121/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8816 - loss: 0.3392 - val_accuracy: 0.9547 - val_loss: 0.1586\n",
      "Epoch 122/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8804 - loss: 0.3445 - val_accuracy: 0.9541 - val_loss: 0.1573\n",
      "Epoch 123/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8835 - loss: 0.3352 - val_accuracy: 0.9555 - val_loss: 0.1564\n",
      "Epoch 124/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.8847 - loss: 0.3352 - val_accuracy: 0.9562 - val_loss: 0.1553\n",
      "Epoch 125/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8871 - loss: 0.3258 - val_accuracy: 0.9548 - val_loss: 0.1539\n",
      "Epoch 126/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8833 - loss: 0.3338 - val_accuracy: 0.9551 - val_loss: 0.1534\n",
      "Epoch 127/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8870 - loss: 0.3330 - val_accuracy: 0.9562 - val_loss: 0.1531\n",
      "Epoch 128/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - accuracy: 0.8877 - loss: 0.3281 - val_accuracy: 0.9573 - val_loss: 0.1528\n",
      "Epoch 129/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8861 - loss: 0.3289 - val_accuracy: 0.9573 - val_loss: 0.1526\n",
      "Epoch 130/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8901 - loss: 0.3221 - val_accuracy: 0.9567 - val_loss: 0.1491\n",
      "Epoch 131/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8874 - loss: 0.3222 - val_accuracy: 0.9593 - val_loss: 0.1491\n",
      "Epoch 132/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8909 - loss: 0.3202 - val_accuracy: 0.9589 - val_loss: 0.1507\n",
      "Epoch 133/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8893 - loss: 0.3225 - val_accuracy: 0.9579 - val_loss: 0.1480\n",
      "Epoch 134/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8902 - loss: 0.3171 - val_accuracy: 0.9596 - val_loss: 0.1464\n",
      "Epoch 135/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8902 - loss: 0.3172 - val_accuracy: 0.9582 - val_loss: 0.1444\n",
      "Epoch 136/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8933 - loss: 0.3124 - val_accuracy: 0.9590 - val_loss: 0.1435\n",
      "Epoch 137/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8899 - loss: 0.3209 - val_accuracy: 0.9596 - val_loss: 0.1439\n",
      "Epoch 138/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 33ms/step - accuracy: 0.8932 - loss: 0.3184 - val_accuracy: 0.9593 - val_loss: 0.1429\n",
      "Epoch 139/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8944 - loss: 0.3142 - val_accuracy: 0.9583 - val_loss: 0.1422\n",
      "Epoch 140/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8895 - loss: 0.3163 - val_accuracy: 0.9612 - val_loss: 0.1414\n",
      "Epoch 141/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8954 - loss: 0.3110 - val_accuracy: 0.9619 - val_loss: 0.1415\n",
      "Epoch 142/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8946 - loss: 0.3037 - val_accuracy: 0.9619 - val_loss: 0.1404\n",
      "Epoch 143/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8959 - loss: 0.3045 - val_accuracy: 0.9611 - val_loss: 0.1373\n",
      "Epoch 144/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8950 - loss: 0.3060 - val_accuracy: 0.9627 - val_loss: 0.1380\n",
      "Epoch 145/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8942 - loss: 0.3134 - val_accuracy: 0.9592 - val_loss: 0.1370\n",
      "Epoch 146/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8990 - loss: 0.2956 - val_accuracy: 0.9604 - val_loss: 0.1384\n",
      "Epoch 147/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8953 - loss: 0.3018 - val_accuracy: 0.9613 - val_loss: 0.1358\n",
      "Epoch 148/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8970 - loss: 0.2987 - val_accuracy: 0.9612 - val_loss: 0.1357\n",
      "Epoch 149/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.8950 - loss: 0.3039 - val_accuracy: 0.9631 - val_loss: 0.1370\n",
      "Epoch 150/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8934 - loss: 0.3073 - val_accuracy: 0.9626 - val_loss: 0.1357\n",
      "Epoch 151/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8962 - loss: 0.3000 - val_accuracy: 0.9627 - val_loss: 0.1348\n",
      "Epoch 152/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8970 - loss: 0.2988 - val_accuracy: 0.9635 - val_loss: 0.1343\n",
      "Epoch 153/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9010 - loss: 0.2936 - val_accuracy: 0.9624 - val_loss: 0.1319\n",
      "Epoch 154/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9008 - loss: 0.2878 - val_accuracy: 0.9636 - val_loss: 0.1308\n",
      "Epoch 155/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8998 - loss: 0.2915 - val_accuracy: 0.9643 - val_loss: 0.1313\n",
      "Epoch 156/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9021 - loss: 0.2852 - val_accuracy: 0.9635 - val_loss: 0.1314\n",
      "Epoch 157/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9007 - loss: 0.2843 - val_accuracy: 0.9644 - val_loss: 0.1304\n",
      "Epoch 158/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9034 - loss: 0.2798 - val_accuracy: 0.9634 - val_loss: 0.1291\n",
      "Epoch 159/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8994 - loss: 0.2927 - val_accuracy: 0.9624 - val_loss: 0.1296\n",
      "Epoch 160/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9004 - loss: 0.2893 - val_accuracy: 0.9634 - val_loss: 0.1263\n",
      "Epoch 161/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9016 - loss: 0.2820 - val_accuracy: 0.9649 - val_loss: 0.1271\n",
      "Epoch 162/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9058 - loss: 0.2760 - val_accuracy: 0.9653 - val_loss: 0.1275\n",
      "Epoch 163/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9029 - loss: 0.2833 - val_accuracy: 0.9661 - val_loss: 0.1263\n",
      "Epoch 164/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9042 - loss: 0.2802 - val_accuracy: 0.9641 - val_loss: 0.1252\n",
      "Epoch 165/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8982 - loss: 0.2952 - val_accuracy: 0.9658 - val_loss: 0.1237\n",
      "Epoch 166/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9049 - loss: 0.2806 - val_accuracy: 0.9662 - val_loss: 0.1233\n",
      "Epoch 167/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9022 - loss: 0.2851 - val_accuracy: 0.9647 - val_loss: 0.1246\n",
      "Epoch 168/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9032 - loss: 0.2820 - val_accuracy: 0.9661 - val_loss: 0.1241\n",
      "Epoch 169/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9056 - loss: 0.2762 - val_accuracy: 0.9647 - val_loss: 0.1247\n",
      "Epoch 170/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9009 - loss: 0.2801 - val_accuracy: 0.9644 - val_loss: 0.1233\n",
      "Epoch 171/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9066 - loss: 0.2741 - val_accuracy: 0.9661 - val_loss: 0.1207\n",
      "Epoch 172/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9012 - loss: 0.2816 - val_accuracy: 0.9662 - val_loss: 0.1215\n",
      "Epoch 173/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.9046 - loss: 0.2774 - val_accuracy: 0.9658 - val_loss: 0.1218\n",
      "Epoch 174/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9077 - loss: 0.2670 - val_accuracy: 0.9659 - val_loss: 0.1228\n",
      "Epoch 175/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9027 - loss: 0.2777 - val_accuracy: 0.9657 - val_loss: 0.1219\n",
      "Epoch 176/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9032 - loss: 0.2839 - val_accuracy: 0.9648 - val_loss: 0.1217\n",
      "Epoch 177/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9052 - loss: 0.2705 - val_accuracy: 0.9675 - val_loss: 0.1203\n",
      "Epoch 178/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9062 - loss: 0.2668 - val_accuracy: 0.9664 - val_loss: 0.1192\n",
      "Epoch 179/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.9055 - loss: 0.2734 - val_accuracy: 0.9668 - val_loss: 0.1187\n",
      "Epoch 180/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9049 - loss: 0.2753 - val_accuracy: 0.9652 - val_loss: 0.1200\n",
      "Epoch 181/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9065 - loss: 0.2737 - val_accuracy: 0.9662 - val_loss: 0.1185\n",
      "Epoch 182/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9067 - loss: 0.2685 - val_accuracy: 0.9662 - val_loss: 0.1183\n",
      "Epoch 183/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9058 - loss: 0.2734 - val_accuracy: 0.9667 - val_loss: 0.1178\n",
      "Epoch 184/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9096 - loss: 0.2681 - val_accuracy: 0.9676 - val_loss: 0.1150\n",
      "Epoch 185/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9140 - loss: 0.2560 - val_accuracy: 0.9666 - val_loss: 0.1160\n",
      "Epoch 186/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9094 - loss: 0.2629 - val_accuracy: 0.9677 - val_loss: 0.1156\n",
      "Epoch 187/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 34ms/step - accuracy: 0.9096 - loss: 0.2682 - val_accuracy: 0.9677 - val_loss: 0.1148\n",
      "Epoch 188/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.9066 - loss: 0.2684 - val_accuracy: 0.9670 - val_loss: 0.1141\n",
      "Epoch 189/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9086 - loss: 0.2681 - val_accuracy: 0.9678 - val_loss: 0.1132\n",
      "Epoch 190/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9079 - loss: 0.2672 - val_accuracy: 0.9671 - val_loss: 0.1145\n",
      "Epoch 191/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9099 - loss: 0.2634 - val_accuracy: 0.9686 - val_loss: 0.1134\n",
      "Epoch 192/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9082 - loss: 0.2621 - val_accuracy: 0.9684 - val_loss: 0.1142\n",
      "Epoch 193/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9102 - loss: 0.2572 - val_accuracy: 0.9687 - val_loss: 0.1114\n",
      "Epoch 194/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9166 - loss: 0.2512 - val_accuracy: 0.9684 - val_loss: 0.1118\n",
      "Epoch 195/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.9090 - loss: 0.2573 - val_accuracy: 0.9686 - val_loss: 0.1113\n",
      "Epoch 196/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9083 - loss: 0.2598 - val_accuracy: 0.9677 - val_loss: 0.1108\n",
      "Epoch 197/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9151 - loss: 0.2511 - val_accuracy: 0.9677 - val_loss: 0.1117\n",
      "Epoch 198/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9125 - loss: 0.2547 - val_accuracy: 0.9698 - val_loss: 0.1129\n",
      "Epoch 199/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9145 - loss: 0.2486 - val_accuracy: 0.9690 - val_loss: 0.1093\n",
      "Epoch 200/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9114 - loss: 0.2528 - val_accuracy: 0.9678 - val_loss: 0.1108\n",
      "Epoch 201/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9112 - loss: 0.2593 - val_accuracy: 0.9695 - val_loss: 0.1090\n",
      "Epoch 202/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.9138 - loss: 0.2531 - val_accuracy: 0.9699 - val_loss: 0.1092\n",
      "Epoch 203/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9148 - loss: 0.2537 - val_accuracy: 0.9693 - val_loss: 0.1094\n",
      "Epoch 204/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9144 - loss: 0.2552 - val_accuracy: 0.9701 - val_loss: 0.1086\n",
      "Epoch 205/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9112 - loss: 0.2503 - val_accuracy: 0.9686 - val_loss: 0.1095\n",
      "Epoch 206/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9141 - loss: 0.2506 - val_accuracy: 0.9682 - val_loss: 0.1087\n",
      "Epoch 207/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9154 - loss: 0.2420 - val_accuracy: 0.9707 - val_loss: 0.1073\n",
      "Epoch 208/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9138 - loss: 0.2482 - val_accuracy: 0.9681 - val_loss: 0.1088\n",
      "Epoch 209/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9169 - loss: 0.2517 - val_accuracy: 0.9691 - val_loss: 0.1080\n",
      "Epoch 210/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9164 - loss: 0.2425 - val_accuracy: 0.9701 - val_loss: 0.1070\n",
      "Epoch 211/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.9141 - loss: 0.2471 - val_accuracy: 0.9699 - val_loss: 0.1061\n",
      "Epoch 212/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9146 - loss: 0.2484 - val_accuracy: 0.9703 - val_loss: 0.1059\n",
      "Epoch 213/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - accuracy: 0.9165 - loss: 0.2430 - val_accuracy: 0.9701 - val_loss: 0.1054\n",
      "Epoch 214/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - accuracy: 0.9192 - loss: 0.2409 - val_accuracy: 0.9699 - val_loss: 0.1054\n",
      "Epoch 215/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9176 - loss: 0.2464 - val_accuracy: 0.9701 - val_loss: 0.1049\n",
      "Epoch 216/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9193 - loss: 0.2400 - val_accuracy: 0.9696 - val_loss: 0.1053\n",
      "Epoch 217/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9160 - loss: 0.2419 - val_accuracy: 0.9693 - val_loss: 0.1047\n",
      "Epoch 218/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9181 - loss: 0.2411 - val_accuracy: 0.9694 - val_loss: 0.1053\n",
      "Epoch 219/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9182 - loss: 0.2356 - val_accuracy: 0.9703 - val_loss: 0.1044\n",
      "Epoch 220/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9171 - loss: 0.2398 - val_accuracy: 0.9694 - val_loss: 0.1041\n",
      "Epoch 221/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9160 - loss: 0.2496 - val_accuracy: 0.9705 - val_loss: 0.1031\n",
      "Epoch 222/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9153 - loss: 0.2454 - val_accuracy: 0.9696 - val_loss: 0.1032\n",
      "Epoch 223/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - accuracy: 0.9177 - loss: 0.2419 - val_accuracy: 0.9700 - val_loss: 0.1034\n",
      "Epoch 224/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9196 - loss: 0.2368 - val_accuracy: 0.9710 - val_loss: 0.1025\n",
      "Epoch 225/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9203 - loss: 0.2308 - val_accuracy: 0.9713 - val_loss: 0.1017\n",
      "Epoch 226/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9198 - loss: 0.2345 - val_accuracy: 0.9704 - val_loss: 0.1019\n",
      "Epoch 227/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9191 - loss: 0.2407 - val_accuracy: 0.9696 - val_loss: 0.1028\n",
      "Epoch 228/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.9167 - loss: 0.2431 - val_accuracy: 0.9705 - val_loss: 0.1014\n",
      "Epoch 229/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9160 - loss: 0.2419 - val_accuracy: 0.9713 - val_loss: 0.1015\n",
      "Epoch 230/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9173 - loss: 0.2372 - val_accuracy: 0.9710 - val_loss: 0.1004\n",
      "Epoch 231/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9216 - loss: 0.2310 - val_accuracy: 0.9704 - val_loss: 0.1014\n",
      "Epoch 232/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9185 - loss: 0.2372 - val_accuracy: 0.9721 - val_loss: 0.0993\n",
      "Epoch 233/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9179 - loss: 0.2382 - val_accuracy: 0.9714 - val_loss: 0.0997\n",
      "Epoch 234/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9217 - loss: 0.2328 - val_accuracy: 0.9708 - val_loss: 0.1013\n",
      "Epoch 235/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9211 - loss: 0.2305 - val_accuracy: 0.9708 - val_loss: 0.1001\n",
      "Epoch 236/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9203 - loss: 0.2326 - val_accuracy: 0.9722 - val_loss: 0.1003\n",
      "Epoch 237/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9216 - loss: 0.2265 - val_accuracy: 0.9709 - val_loss: 0.1000\n",
      "Epoch 238/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9245 - loss: 0.2263 - val_accuracy: 0.9721 - val_loss: 0.1003\n",
      "Epoch 239/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9221 - loss: 0.2278 - val_accuracy: 0.9730 - val_loss: 0.0989\n",
      "Epoch 240/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9208 - loss: 0.2345 - val_accuracy: 0.9719 - val_loss: 0.0998\n",
      "Epoch 241/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9227 - loss: 0.2265 - val_accuracy: 0.9721 - val_loss: 0.0997\n",
      "Epoch 242/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9181 - loss: 0.2314 - val_accuracy: 0.9718 - val_loss: 0.0989\n",
      "Epoch 243/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9225 - loss: 0.2350 - val_accuracy: 0.9719 - val_loss: 0.0995\n",
      "Epoch 244/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9224 - loss: 0.2277 - val_accuracy: 0.9715 - val_loss: 0.0992\n",
      "Epoch 245/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9232 - loss: 0.2276 - val_accuracy: 0.9717 - val_loss: 0.0982\n",
      "Epoch 246/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9242 - loss: 0.2220 - val_accuracy: 0.9727 - val_loss: 0.0963\n",
      "Epoch 247/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9222 - loss: 0.2212 - val_accuracy: 0.9723 - val_loss: 0.0970\n",
      "Epoch 248/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9227 - loss: 0.2280 - val_accuracy: 0.9715 - val_loss: 0.0977\n",
      "Epoch 249/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9209 - loss: 0.2334 - val_accuracy: 0.9721 - val_loss: 0.0967\n",
      "Epoch 250/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 31ms/step - accuracy: 0.9241 - loss: 0.2243 - val_accuracy: 0.9721 - val_loss: 0.0975\n",
      "Epoch 251/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9196 - loss: 0.2323 - val_accuracy: 0.9719 - val_loss: 0.0973\n",
      "Epoch 252/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9228 - loss: 0.2269 - val_accuracy: 0.9726 - val_loss: 0.0971\n",
      "Epoch 253/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9200 - loss: 0.2303 - val_accuracy: 0.9722 - val_loss: 0.0966\n",
      "Epoch 254/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - accuracy: 0.9232 - loss: 0.2234 - val_accuracy: 0.9731 - val_loss: 0.0959\n",
      "Epoch 255/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9224 - loss: 0.2244 - val_accuracy: 0.9721 - val_loss: 0.0961\n",
      "Epoch 256/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9237 - loss: 0.2215 - val_accuracy: 0.9717 - val_loss: 0.0973\n",
      "Epoch 257/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9241 - loss: 0.2299 - val_accuracy: 0.9713 - val_loss: 0.0956\n",
      "Epoch 258/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9248 - loss: 0.2193 - val_accuracy: 0.9730 - val_loss: 0.0952\n",
      "Epoch 259/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.9250 - loss: 0.2189 - val_accuracy: 0.9721 - val_loss: 0.0959\n",
      "Epoch 260/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9246 - loss: 0.2201 - val_accuracy: 0.9737 - val_loss: 0.0964\n",
      "Epoch 261/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9257 - loss: 0.2214 - val_accuracy: 0.9718 - val_loss: 0.0953\n",
      "Epoch 262/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9251 - loss: 0.2166 - val_accuracy: 0.9726 - val_loss: 0.0954\n",
      "Epoch 263/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9254 - loss: 0.2148 - val_accuracy: 0.9724 - val_loss: 0.0947\n",
      "Epoch 264/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9253 - loss: 0.2138 - val_accuracy: 0.9726 - val_loss: 0.0950\n",
      "Epoch 265/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9276 - loss: 0.2154 - val_accuracy: 0.9728 - val_loss: 0.0953\n",
      "Epoch 266/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9244 - loss: 0.2205 - val_accuracy: 0.9719 - val_loss: 0.0945\n",
      "Epoch 267/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9247 - loss: 0.2189 - val_accuracy: 0.9728 - val_loss: 0.0944\n",
      "Epoch 268/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9280 - loss: 0.2149 - val_accuracy: 0.9737 - val_loss: 0.0944\n",
      "Epoch 269/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9235 - loss: 0.2249 - val_accuracy: 0.9731 - val_loss: 0.0932\n",
      "Epoch 270/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9270 - loss: 0.2161 - val_accuracy: 0.9730 - val_loss: 0.0940\n",
      "Epoch 271/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9271 - loss: 0.2219 - val_accuracy: 0.9724 - val_loss: 0.0943\n",
      "Epoch 272/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9229 - loss: 0.2249 - val_accuracy: 0.9735 - val_loss: 0.0931\n",
      "Epoch 273/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - accuracy: 0.9238 - loss: 0.2223 - val_accuracy: 0.9722 - val_loss: 0.0937\n",
      "Epoch 274/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9271 - loss: 0.2218 - val_accuracy: 0.9732 - val_loss: 0.0933\n",
      "Epoch 275/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9272 - loss: 0.2148 - val_accuracy: 0.9724 - val_loss: 0.0939\n",
      "Epoch 276/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9258 - loss: 0.2158 - val_accuracy: 0.9735 - val_loss: 0.0925\n",
      "Epoch 277/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9208 - loss: 0.2206 - val_accuracy: 0.9713 - val_loss: 0.0937\n",
      "Epoch 278/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9256 - loss: 0.2134 - val_accuracy: 0.9717 - val_loss: 0.0928\n",
      "Epoch 279/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9238 - loss: 0.2204 - val_accuracy: 0.9735 - val_loss: 0.0925\n",
      "Epoch 280/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - accuracy: 0.9265 - loss: 0.2157 - val_accuracy: 0.9728 - val_loss: 0.0923\n",
      "Epoch 281/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9270 - loss: 0.2187 - val_accuracy: 0.9721 - val_loss: 0.0941\n",
      "Epoch 282/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9255 - loss: 0.2178 - val_accuracy: 0.9751 - val_loss: 0.0923\n",
      "Epoch 283/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - accuracy: 0.9258 - loss: 0.2144 - val_accuracy: 0.9746 - val_loss: 0.0924\n",
      "Epoch 284/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9254 - loss: 0.2159 - val_accuracy: 0.9731 - val_loss: 0.0931\n",
      "Epoch 285/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9284 - loss: 0.2111 - val_accuracy: 0.9737 - val_loss: 0.0907\n",
      "Epoch 286/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9292 - loss: 0.2103 - val_accuracy: 0.9728 - val_loss: 0.0913\n",
      "Epoch 287/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9292 - loss: 0.2104 - val_accuracy: 0.9737 - val_loss: 0.0901\n",
      "Epoch 288/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9258 - loss: 0.2157 - val_accuracy: 0.9730 - val_loss: 0.0911\n",
      "Epoch 289/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9299 - loss: 0.2110 - val_accuracy: 0.9738 - val_loss: 0.0909\n",
      "Epoch 290/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.9287 - loss: 0.2066 - val_accuracy: 0.9728 - val_loss: 0.0913\n",
      "Epoch 291/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9315 - loss: 0.2069 - val_accuracy: 0.9728 - val_loss: 0.0898\n",
      "Epoch 292/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9320 - loss: 0.2021 - val_accuracy: 0.9736 - val_loss: 0.0915\n",
      "Epoch 293/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9311 - loss: 0.2069 - val_accuracy: 0.9750 - val_loss: 0.0897\n",
      "Epoch 294/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9265 - loss: 0.2061 - val_accuracy: 0.9737 - val_loss: 0.0896\n",
      "Epoch 295/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9295 - loss: 0.2115 - val_accuracy: 0.9741 - val_loss: 0.0886\n",
      "Epoch 296/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9247 - loss: 0.2165 - val_accuracy: 0.9726 - val_loss: 0.0901\n",
      "Epoch 297/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9317 - loss: 0.1970 - val_accuracy: 0.9747 - val_loss: 0.0896\n",
      "Epoch 298/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9283 - loss: 0.2087 - val_accuracy: 0.9732 - val_loss: 0.0901\n",
      "Epoch 299/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9297 - loss: 0.2076 - val_accuracy: 0.9746 - val_loss: 0.0890\n",
      "Epoch 300/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9286 - loss: 0.2105 - val_accuracy: 0.9751 - val_loss: 0.0888\n",
      "Epoch 301/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 33ms/step - accuracy: 0.9334 - loss: 0.1947 - val_accuracy: 0.9749 - val_loss: 0.0885\n",
      "Epoch 302/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9255 - loss: 0.2106 - val_accuracy: 0.9740 - val_loss: 0.0884\n",
      "Epoch 303/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9263 - loss: 0.2137 - val_accuracy: 0.9741 - val_loss: 0.0893\n",
      "Epoch 304/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9307 - loss: 0.2063 - val_accuracy: 0.9726 - val_loss: 0.0901\n",
      "Epoch 305/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9308 - loss: 0.2052 - val_accuracy: 0.9735 - val_loss: 0.0890\n",
      "Epoch 306/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9269 - loss: 0.2148 - val_accuracy: 0.9737 - val_loss: 0.0882\n",
      "Epoch 307/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9286 - loss: 0.2051 - val_accuracy: 0.9741 - val_loss: 0.0889\n",
      "Epoch 308/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9320 - loss: 0.2004 - val_accuracy: 0.9751 - val_loss: 0.0877\n",
      "Epoch 309/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9317 - loss: 0.1950 - val_accuracy: 0.9733 - val_loss: 0.0899\n",
      "Epoch 310/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9306 - loss: 0.2004 - val_accuracy: 0.9756 - val_loss: 0.0878\n",
      "Epoch 311/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9311 - loss: 0.2032 - val_accuracy: 0.9751 - val_loss: 0.0887\n",
      "Epoch 312/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9319 - loss: 0.2027 - val_accuracy: 0.9755 - val_loss: 0.0878\n",
      "Epoch 313/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9329 - loss: 0.2004 - val_accuracy: 0.9746 - val_loss: 0.0873\n",
      "Epoch 314/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9335 - loss: 0.1979 - val_accuracy: 0.9745 - val_loss: 0.0883\n",
      "Epoch 315/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9323 - loss: 0.2014 - val_accuracy: 0.9754 - val_loss: 0.0887\n",
      "Epoch 316/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.9311 - loss: 0.2056 - val_accuracy: 0.9746 - val_loss: 0.0864\n",
      "Epoch 317/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9303 - loss: 0.2022 - val_accuracy: 0.9737 - val_loss: 0.0875\n",
      "Epoch 318/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - accuracy: 0.9299 - loss: 0.2029 - val_accuracy: 0.9755 - val_loss: 0.0881\n",
      "Epoch 319/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9322 - loss: 0.2034 - val_accuracy: 0.9741 - val_loss: 0.0872\n",
      "Epoch 320/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9300 - loss: 0.2057 - val_accuracy: 0.9738 - val_loss: 0.0880\n",
      "Epoch 321/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9327 - loss: 0.1989 - val_accuracy: 0.9747 - val_loss: 0.0868\n",
      "Epoch 322/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9286 - loss: 0.2076 - val_accuracy: 0.9749 - val_loss: 0.0868\n",
      "Epoch 323/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9314 - loss: 0.1977 - val_accuracy: 0.9745 - val_loss: 0.0861\n",
      "Epoch 324/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9303 - loss: 0.2031 - val_accuracy: 0.9746 - val_loss: 0.0882\n",
      "Epoch 325/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9279 - loss: 0.2059 - val_accuracy: 0.9752 - val_loss: 0.0866\n",
      "Epoch 326/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9332 - loss: 0.1984 - val_accuracy: 0.9756 - val_loss: 0.0858\n",
      "Epoch 327/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9290 - loss: 0.2026 - val_accuracy: 0.9751 - val_loss: 0.0869\n",
      "Epoch 328/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9301 - loss: 0.1980 - val_accuracy: 0.9751 - val_loss: 0.0871\n",
      "Epoch 329/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9319 - loss: 0.1994 - val_accuracy: 0.9750 - val_loss: 0.0869\n",
      "Epoch 330/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9316 - loss: 0.1997 - val_accuracy: 0.9751 - val_loss: 0.0859\n",
      "Epoch 331/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.9316 - loss: 0.2027 - val_accuracy: 0.9746 - val_loss: 0.0860\n",
      "Epoch 332/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9346 - loss: 0.1954 - val_accuracy: 0.9751 - val_loss: 0.0860\n",
      "Epoch 333/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9328 - loss: 0.1995 - val_accuracy: 0.9742 - val_loss: 0.0863\n",
      "Epoch 334/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9336 - loss: 0.1978 - val_accuracy: 0.9752 - val_loss: 0.0860\n",
      "Epoch 335/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9337 - loss: 0.2001 - val_accuracy: 0.9758 - val_loss: 0.0857\n",
      "Epoch 336/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9329 - loss: 0.1943 - val_accuracy: 0.9755 - val_loss: 0.0851\n",
      "Epoch 337/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9348 - loss: 0.1958 - val_accuracy: 0.9747 - val_loss: 0.0866\n",
      "Epoch 338/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9330 - loss: 0.2044 - val_accuracy: 0.9761 - val_loss: 0.0857\n",
      "Epoch 339/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9324 - loss: 0.1988 - val_accuracy: 0.9772 - val_loss: 0.0848\n",
      "Epoch 340/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.9340 - loss: 0.1931 - val_accuracy: 0.9760 - val_loss: 0.0847\n",
      "Epoch 341/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9323 - loss: 0.2001 - val_accuracy: 0.9758 - val_loss: 0.0849\n",
      "Epoch 342/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9308 - loss: 0.2021 - val_accuracy: 0.9767 - val_loss: 0.0840\n",
      "Epoch 343/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9328 - loss: 0.1989 - val_accuracy: 0.9759 - val_loss: 0.0853\n",
      "Epoch 344/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.9330 - loss: 0.1917 - val_accuracy: 0.9756 - val_loss: 0.0843\n",
      "Epoch 345/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9341 - loss: 0.1937 - val_accuracy: 0.9760 - val_loss: 0.0839\n",
      "Epoch 346/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.9329 - loss: 0.1918 - val_accuracy: 0.9763 - val_loss: 0.0835\n",
      "Epoch 347/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9332 - loss: 0.1967 - val_accuracy: 0.9763 - val_loss: 0.0844\n",
      "Epoch 348/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.9349 - loss: 0.1954 - val_accuracy: 0.9774 - val_loss: 0.0846\n",
      "Epoch 349/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9371 - loss: 0.1859 - val_accuracy: 0.9765 - val_loss: 0.0833\n",
      "Epoch 350/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9360 - loss: 0.1937 - val_accuracy: 0.9745 - val_loss: 0.0846\n",
      "Epoch 351/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9300 - loss: 0.1968 - val_accuracy: 0.9749 - val_loss: 0.0834\n",
      "Epoch 352/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9324 - loss: 0.1961 - val_accuracy: 0.9760 - val_loss: 0.0834\n",
      "Epoch 353/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9319 - loss: 0.1960 - val_accuracy: 0.9750 - val_loss: 0.0836\n",
      "Epoch 354/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9336 - loss: 0.1932 - val_accuracy: 0.9756 - val_loss: 0.0840\n",
      "Epoch 355/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9331 - loss: 0.1941 - val_accuracy: 0.9754 - val_loss: 0.0849\n",
      "Epoch 356/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.9319 - loss: 0.2015 - val_accuracy: 0.9764 - val_loss: 0.0836\n",
      "Epoch 357/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9379 - loss: 0.1851 - val_accuracy: 0.9761 - val_loss: 0.0837\n",
      "Epoch 358/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9375 - loss: 0.1861 - val_accuracy: 0.9768 - val_loss: 0.0834\n",
      "Epoch 359/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9345 - loss: 0.1978 - val_accuracy: 0.9752 - val_loss: 0.0831\n",
      "Epoch 360/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9359 - loss: 0.1899 - val_accuracy: 0.9750 - val_loss: 0.0827\n",
      "Epoch 361/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9333 - loss: 0.1920 - val_accuracy: 0.9763 - val_loss: 0.0843\n",
      "Epoch 362/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9342 - loss: 0.1928 - val_accuracy: 0.9754 - val_loss: 0.0850\n",
      "Epoch 363/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 35ms/step - accuracy: 0.9355 - loss: 0.1913 - val_accuracy: 0.9741 - val_loss: 0.0843\n",
      "Epoch 364/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9335 - loss: 0.1901 - val_accuracy: 0.9755 - val_loss: 0.0839\n",
      "Epoch 365/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9389 - loss: 0.1848 - val_accuracy: 0.9765 - val_loss: 0.0831\n",
      "Epoch 366/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9370 - loss: 0.1849 - val_accuracy: 0.9769 - val_loss: 0.0818\n",
      "Epoch 367/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9364 - loss: 0.1863 - val_accuracy: 0.9767 - val_loss: 0.0833\n",
      "Epoch 368/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9335 - loss: 0.1905 - val_accuracy: 0.9763 - val_loss: 0.0826\n",
      "Epoch 369/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9366 - loss: 0.1848 - val_accuracy: 0.9770 - val_loss: 0.0823\n",
      "Epoch 370/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9338 - loss: 0.1910 - val_accuracy: 0.9751 - val_loss: 0.0824\n",
      "Epoch 371/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9351 - loss: 0.1885 - val_accuracy: 0.9764 - val_loss: 0.0820\n",
      "Epoch 372/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9330 - loss: 0.1930 - val_accuracy: 0.9760 - val_loss: 0.0826\n",
      "Epoch 373/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9356 - loss: 0.1843 - val_accuracy: 0.9760 - val_loss: 0.0826\n",
      "Epoch 374/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9335 - loss: 0.1916 - val_accuracy: 0.9763 - val_loss: 0.0823\n",
      "Epoch 375/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9329 - loss: 0.1917 - val_accuracy: 0.9755 - val_loss: 0.0831\n",
      "Epoch 376/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9369 - loss: 0.1826 - val_accuracy: 0.9764 - val_loss: 0.0823\n",
      "Epoch 377/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9346 - loss: 0.1902 - val_accuracy: 0.9763 - val_loss: 0.0818\n",
      "Epoch 378/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9342 - loss: 0.1886 - val_accuracy: 0.9764 - val_loss: 0.0819\n",
      "Epoch 379/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9375 - loss: 0.1851 - val_accuracy: 0.9767 - val_loss: 0.0821\n",
      "Epoch 380/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9396 - loss: 0.1737 - val_accuracy: 0.9760 - val_loss: 0.0827\n",
      "Epoch 381/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9374 - loss: 0.1831 - val_accuracy: 0.9768 - val_loss: 0.0812\n",
      "Epoch 382/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9377 - loss: 0.1790 - val_accuracy: 0.9765 - val_loss: 0.0821\n",
      "Epoch 383/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9356 - loss: 0.1864 - val_accuracy: 0.9761 - val_loss: 0.0816\n",
      "Epoch 384/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9387 - loss: 0.1759 - val_accuracy: 0.9764 - val_loss: 0.0814\n",
      "Epoch 385/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9356 - loss: 0.1897 - val_accuracy: 0.9765 - val_loss: 0.0810\n",
      "Epoch 386/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9404 - loss: 0.1788 - val_accuracy: 0.9754 - val_loss: 0.0820\n",
      "Epoch 387/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9346 - loss: 0.1928 - val_accuracy: 0.9761 - val_loss: 0.0812\n",
      "Epoch 388/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9405 - loss: 0.1768 - val_accuracy: 0.9765 - val_loss: 0.0815\n",
      "Epoch 389/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9397 - loss: 0.1804 - val_accuracy: 0.9763 - val_loss: 0.0815\n",
      "Epoch 390/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9386 - loss: 0.1811 - val_accuracy: 0.9765 - val_loss: 0.0811\n",
      "Epoch 391/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9386 - loss: 0.1787 - val_accuracy: 0.9770 - val_loss: 0.0806\n",
      "Epoch 392/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9383 - loss: 0.1800 - val_accuracy: 0.9764 - val_loss: 0.0826\n",
      "Epoch 393/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.9366 - loss: 0.1833 - val_accuracy: 0.9768 - val_loss: 0.0823\n",
      "Epoch 394/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9332 - loss: 0.1915 - val_accuracy: 0.9758 - val_loss: 0.0818\n",
      "Epoch 395/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9379 - loss: 0.1809 - val_accuracy: 0.9756 - val_loss: 0.0833\n",
      "Epoch 396/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9408 - loss: 0.1778 - val_accuracy: 0.9763 - val_loss: 0.0813\n",
      "Epoch 397/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9379 - loss: 0.1805 - val_accuracy: 0.9756 - val_loss: 0.0811\n",
      "Epoch 398/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 31ms/step - accuracy: 0.9385 - loss: 0.1833 - val_accuracy: 0.9759 - val_loss: 0.0816\n",
      "Epoch 399/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 23ms/step - accuracy: 0.9382 - loss: 0.1786 - val_accuracy: 0.9758 - val_loss: 0.0826\n",
      "Epoch 400/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9369 - loss: 0.1845 - val_accuracy: 0.9764 - val_loss: 0.0806\n",
      "Epoch 401/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9402 - loss: 0.1818 - val_accuracy: 0.9763 - val_loss: 0.0809\n",
      "Epoch 402/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9391 - loss: 0.1776 - val_accuracy: 0.9767 - val_loss: 0.0801\n",
      "Epoch 403/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.9332 - loss: 0.1871 - val_accuracy: 0.9763 - val_loss: 0.0815\n",
      "Epoch 404/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.9397 - loss: 0.1826 - val_accuracy: 0.9752 - val_loss: 0.0814\n",
      "Epoch 405/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.9425 - loss: 0.1686 - val_accuracy: 0.9754 - val_loss: 0.0823\n",
      "Epoch 406/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 32ms/step - accuracy: 0.9374 - loss: 0.1808 - val_accuracy: 0.9741 - val_loss: 0.0826\n",
      "Epoch 407/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.9382 - loss: 0.1790 - val_accuracy: 0.9763 - val_loss: 0.0814\n",
      "Epoch 408/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.9395 - loss: 0.1817 - val_accuracy: 0.9761 - val_loss: 0.0805\n",
      "Epoch 409/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.9361 - loss: 0.1855 - val_accuracy: 0.9761 - val_loss: 0.0812\n",
      "Epoch 410/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.9387 - loss: 0.1808 - val_accuracy: 0.9754 - val_loss: 0.0806\n",
      "Epoch 411/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9350 - loss: 0.1896 - val_accuracy: 0.9763 - val_loss: 0.0806\n",
      "Epoch 412/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9379 - loss: 0.1830 - val_accuracy: 0.9761 - val_loss: 0.0801\n",
      "Epoch 413/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9398 - loss: 0.1775 - val_accuracy: 0.9761 - val_loss: 0.0804\n",
      "Epoch 414/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9372 - loss: 0.1816 - val_accuracy: 0.9763 - val_loss: 0.0802\n",
      "Epoch 415/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9369 - loss: 0.1853 - val_accuracy: 0.9765 - val_loss: 0.0807\n",
      "Epoch 416/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9373 - loss: 0.1819 - val_accuracy: 0.9759 - val_loss: 0.0804\n",
      "Epoch 417/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9415 - loss: 0.1739 - val_accuracy: 0.9756 - val_loss: 0.0797\n",
      "Epoch 418/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9401 - loss: 0.1750 - val_accuracy: 0.9759 - val_loss: 0.0795\n",
      "Epoch 419/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9364 - loss: 0.1886 - val_accuracy: 0.9764 - val_loss: 0.0805\n",
      "Epoch 420/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9409 - loss: 0.1739 - val_accuracy: 0.9767 - val_loss: 0.0799\n",
      "Epoch 421/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9384 - loss: 0.1810 - val_accuracy: 0.9759 - val_loss: 0.0822\n",
      "Epoch 422/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.9378 - loss: 0.1789 - val_accuracy: 0.9769 - val_loss: 0.0800\n",
      "Epoch 423/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9371 - loss: 0.1837 - val_accuracy: 0.9765 - val_loss: 0.0793\n",
      "Epoch 424/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - accuracy: 0.9408 - loss: 0.1723 - val_accuracy: 0.9764 - val_loss: 0.0797\n",
      "Epoch 425/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9400 - loss: 0.1755 - val_accuracy: 0.9767 - val_loss: 0.0794\n",
      "Epoch 426/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9401 - loss: 0.1761 - val_accuracy: 0.9759 - val_loss: 0.0794\n",
      "Epoch 427/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9348 - loss: 0.1858 - val_accuracy: 0.9764 - val_loss: 0.0799\n",
      "Epoch 428/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9392 - loss: 0.1760 - val_accuracy: 0.9767 - val_loss: 0.0783\n",
      "Epoch 429/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9370 - loss: 0.1839 - val_accuracy: 0.9770 - val_loss: 0.0783\n",
      "Epoch 430/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9392 - loss: 0.1801 - val_accuracy: 0.9770 - val_loss: 0.0789\n",
      "Epoch 431/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9427 - loss: 0.1714 - val_accuracy: 0.9765 - val_loss: 0.0784\n",
      "Epoch 432/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9406 - loss: 0.1728 - val_accuracy: 0.9772 - val_loss: 0.0792\n",
      "Epoch 433/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9382 - loss: 0.1861 - val_accuracy: 0.9768 - val_loss: 0.0788\n",
      "Epoch 434/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - accuracy: 0.9389 - loss: 0.1790 - val_accuracy: 0.9768 - val_loss: 0.0786\n",
      "Epoch 435/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9392 - loss: 0.1719 - val_accuracy: 0.9765 - val_loss: 0.0793\n",
      "Epoch 436/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.9400 - loss: 0.1752 - val_accuracy: 0.9754 - val_loss: 0.0800\n",
      "Epoch 437/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9412 - loss: 0.1728 - val_accuracy: 0.9764 - val_loss: 0.0780\n",
      "Epoch 438/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9388 - loss: 0.1789 - val_accuracy: 0.9769 - val_loss: 0.0804\n",
      "Epoch 439/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9416 - loss: 0.1692 - val_accuracy: 0.9751 - val_loss: 0.0804\n",
      "Epoch 440/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9400 - loss: 0.1738 - val_accuracy: 0.9756 - val_loss: 0.0799\n",
      "Epoch 441/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - accuracy: 0.9391 - loss: 0.1779 - val_accuracy: 0.9754 - val_loss: 0.0795\n",
      "Epoch 442/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9412 - loss: 0.1736 - val_accuracy: 0.9772 - val_loss: 0.0773\n",
      "Epoch 443/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.9403 - loss: 0.1783 - val_accuracy: 0.9763 - val_loss: 0.0779\n",
      "Epoch 444/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9414 - loss: 0.1695 - val_accuracy: 0.9756 - val_loss: 0.0796\n",
      "Epoch 445/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9380 - loss: 0.1787 - val_accuracy: 0.9755 - val_loss: 0.0799\n",
      "Epoch 446/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9395 - loss: 0.1724 - val_accuracy: 0.9760 - val_loss: 0.0788\n",
      "Epoch 447/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9384 - loss: 0.1754 - val_accuracy: 0.9760 - val_loss: 0.0784\n",
      "Epoch 448/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9407 - loss: 0.1725 - val_accuracy: 0.9760 - val_loss: 0.0789\n",
      "Epoch 449/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9400 - loss: 0.1699 - val_accuracy: 0.9765 - val_loss: 0.0785\n",
      "Epoch 450/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9427 - loss: 0.1692 - val_accuracy: 0.9761 - val_loss: 0.0787\n",
      "Epoch 451/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9410 - loss: 0.1699 - val_accuracy: 0.9759 - val_loss: 0.0803\n",
      "Epoch 452/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9376 - loss: 0.1770 - val_accuracy: 0.9768 - val_loss: 0.0782\n",
      "Epoch 453/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9414 - loss: 0.1726 - val_accuracy: 0.9760 - val_loss: 0.0789\n",
      "Epoch 454/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.9399 - loss: 0.1733 - val_accuracy: 0.9764 - val_loss: 0.0796\n",
      "Epoch 455/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9427 - loss: 0.1684 - val_accuracy: 0.9763 - val_loss: 0.0790\n",
      "Epoch 456/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9409 - loss: 0.1752 - val_accuracy: 0.9763 - val_loss: 0.0804\n",
      "Epoch 457/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9428 - loss: 0.1704 - val_accuracy: 0.9769 - val_loss: 0.0770\n",
      "Epoch 458/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9407 - loss: 0.1726 - val_accuracy: 0.9763 - val_loss: 0.0781\n",
      "Epoch 459/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9391 - loss: 0.1752 - val_accuracy: 0.9763 - val_loss: 0.0772\n",
      "Epoch 460/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9393 - loss: 0.1693 - val_accuracy: 0.9772 - val_loss: 0.0777\n",
      "Epoch 461/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9377 - loss: 0.1768 - val_accuracy: 0.9772 - val_loss: 0.0768\n",
      "Epoch 462/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9401 - loss: 0.1764 - val_accuracy: 0.9768 - val_loss: 0.0772\n",
      "Epoch 463/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9404 - loss: 0.1726 - val_accuracy: 0.9774 - val_loss: 0.0769\n",
      "Epoch 464/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9431 - loss: 0.1709 - val_accuracy: 0.9775 - val_loss: 0.0774\n",
      "Epoch 465/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9389 - loss: 0.1764 - val_accuracy: 0.9767 - val_loss: 0.0785\n",
      "Epoch 466/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9392 - loss: 0.1791 - val_accuracy: 0.9764 - val_loss: 0.0799\n",
      "Epoch 467/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9426 - loss: 0.1747 - val_accuracy: 0.9772 - val_loss: 0.0775\n",
      "Epoch 468/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9453 - loss: 0.1626 - val_accuracy: 0.9775 - val_loss: 0.0775\n",
      "Epoch 469/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.9427 - loss: 0.1654 - val_accuracy: 0.9764 - val_loss: 0.0781\n",
      "Epoch 470/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9417 - loss: 0.1718 - val_accuracy: 0.9764 - val_loss: 0.0781\n",
      "Epoch 471/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.9393 - loss: 0.1718 - val_accuracy: 0.9765 - val_loss: 0.0774\n",
      "Epoch 472/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.9409 - loss: 0.1694 - val_accuracy: 0.9767 - val_loss: 0.0773\n",
      "Epoch 473/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9416 - loss: 0.1729 - val_accuracy: 0.9774 - val_loss: 0.0769\n",
      "Epoch 474/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.9385 - loss: 0.1748 - val_accuracy: 0.9768 - val_loss: 0.0777\n",
      "Epoch 475/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9440 - loss: 0.1702 - val_accuracy: 0.9773 - val_loss: 0.0774\n",
      "Epoch 476/600\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.9404 - loss: 0.1702 - val_accuracy: 0.9767 - val_loss: 0.0768\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - accuracy: 0.9820 - loss: 0.0549\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9783 - loss: 0.0743\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9719 - loss: 0.0926\n",
      "Training Accuracy: 98.21%\n",
      "Validation Accuracy: 97.72%\n",
      "Test Accuracy: 97.08%\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step\n",
      "Test Accuracy with emotion labels: 97.08%\n",
      "Weighted Precision: 97.10%\n",
      "Weighted F1 Score: 97.06%\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         ALERT       0.97      0.88      0.92      1149\n",
      "         ANGER       0.98      1.00      0.99      1022\n",
      "          FEAR       1.00      1.00      1.00      1039\n",
      "         HAPPY       0.92      0.96      0.94      1074\n",
      "       NEUTRAL       0.97      0.97      0.97      1075\n",
      "RESTED/RELAXED       0.96      0.98      0.97      1175\n",
      "           SAD       0.99      1.00      1.00      1062\n",
      " TENSE/ANXIOUS       0.97      0.99      0.98      1098\n",
      "         TIRED       0.97      0.97      0.97      1104\n",
      "\n",
      "      accuracy                           0.97      9798\n",
      "     macro avg       0.97      0.97      0.97      9798\n",
      "  weighted avg       0.97      0.97      0.97      9798\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1013    0    0   38   21   41    5   12   19]\n",
      " [   0 1022    0    0    0    0    0    0    0]\n",
      " [   0    0 1039    0    0    0    0    0    0]\n",
      " [   6   19    0 1026    9    7    2    1    4]\n",
      " [   3    0    0   15 1043    0    0   10    4]\n",
      " [   4    0    0   17    1 1149    0    0    4]\n",
      " [   0    0    0    0    0    0 1062    0    0]\n",
      " [   6    0    0    7    0    0    3 1082    0]\n",
      " [  12    0    0   10    0    0    0    6 1076]]\n",
      "Emotion: ALERT\n",
      "True Positives (TP): 1013\n",
      "True Negatives (TN): 8618\n",
      "False Positives (FP): 31\n",
      "False Negatives (FN): 136\n",
      "------------------------------\n",
      "Emotion: ANGER\n",
      "True Positives (TP): 1022\n",
      "True Negatives (TN): 8757\n",
      "False Positives (FP): 19\n",
      "False Negatives (FN): 0\n",
      "------------------------------\n",
      "Emotion: FEAR\n",
      "True Positives (TP): 1039\n",
      "True Negatives (TN): 8759\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 0\n",
      "------------------------------\n",
      "Emotion: HAPPY\n",
      "True Positives (TP): 1026\n",
      "True Negatives (TN): 8637\n",
      "False Positives (FP): 87\n",
      "False Negatives (FN): 48\n",
      "------------------------------\n",
      "Emotion: NEUTRAL\n",
      "True Positives (TP): 1043\n",
      "True Negatives (TN): 8692\n",
      "False Positives (FP): 31\n",
      "False Negatives (FN): 32\n",
      "------------------------------\n",
      "Emotion: RESTED/RELAXED\n",
      "True Positives (TP): 1149\n",
      "True Negatives (TN): 8575\n",
      "False Positives (FP): 48\n",
      "False Negatives (FN): 26\n",
      "------------------------------\n",
      "Emotion: SAD\n",
      "True Positives (TP): 1062\n",
      "True Negatives (TN): 8726\n",
      "False Positives (FP): 10\n",
      "False Negatives (FN): 0\n",
      "------------------------------\n",
      "Emotion: TENSE/ANXIOUS\n",
      "True Positives (TP): 1082\n",
      "True Negatives (TN): 8671\n",
      "False Positives (FP): 29\n",
      "False Negatives (FN): 16\n",
      "------------------------------\n",
      "Emotion: TIRED\n",
      "True Positives (TP): 1076\n",
      "True Negatives (TN): 8663\n",
      "False Positives (FP): 31\n",
      "False Negatives (FN): 28\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler  # Using RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Raw_MAIN_DATASET_IMPUTATION_after_deleting_stai_badge_activity_step_goal.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "df = df.drop(['id', 'date'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Emotions', axis=1)\n",
    "y = df['Emotions']\n",
    "\n",
    "# Convert categorical target to numeric using label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Check the initial class distribution\n",
    "print(\"Class distribution before oversampling:\", Counter(y))\n",
    "\n",
    "# Oversampling to handle class imbalance using RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after oversampling\n",
    "print(\"Class distribution after oversampling:\", Counter(y))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Feature Selection\n",
    "selector = SelectKBest(f_classif, k=60)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_val = selector.transform(X_val)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  # Output layer (number of unique emotions)\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,  # Increased epochs\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Convert numeric predictions back to emotion labels\n",
    "y_test_pred_labels = le.inverse_transform(y_test_pred_classes)\n",
    "y_test_true_labels = le.inverse_transform(y_test)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "test_acc = accuracy_score(y_test_true_labels, y_test_pred_labels)\n",
    "print(f\"Test Accuracy with emotion labels: {test_acc * 100:.2f}%\")\n",
    "precision = precision_score(y_test_true_labels, y_test_pred_labels, average='weighted')  # Weighted precision\n",
    "f1 = f1_score(y_test_true_labels, y_test_pred_labels, average='weighted')  # Weighted F1 score\n",
    "\n",
    "print(f\"Weighted Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Weighted F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test_true_labels, y_test_pred_labels)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# Confusion matrix to calculate TP and TN for each emotion class\n",
    "conf_matrix = confusion_matrix(y_test_true_labels, y_test_pred_labels)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Calculate TP, TN, FP, FN for each class\n",
    "n_classes = len(le.classes_)\n",
    "for idx, emotion in enumerate(le.classes_):\n",
    "    # True Positives (TP): Diagonal elements\n",
    "    TP = conf_matrix[idx, idx]\n",
    "\n",
    "    # False Positives (FP): Sum of the current column except the diagonal element\n",
    "    FP = conf_matrix[:, idx].sum() - TP\n",
    "\n",
    "    # False Negatives (FN): Sum of the current row except the diagonal element\n",
    "    FN = conf_matrix[idx, :].sum() - TP\n",
    "\n",
    "    # True Negatives (TN): Total samples - (TP + FP + FN)\n",
    "    TN = conf_matrix.sum() - (TP + FP + FN)\n",
    "\n",
    "    print(f\"Emotion: {emotion}\")\n",
    "    print(f\"True Positives (TP): {TP}\")\n",
    "    print(f\"True Negatives (TN): {TN}\")\n",
    "    print(f\"False Positives (FP): {FP}\")\n",
    "    print(f\"False Negatives (FN): {FN}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
