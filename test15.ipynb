{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 03:11:52.274518: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-01 03:11:52.328317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-01 03:11:52.423883: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-01 03:11:52.448108: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-01 03:11:52.513772: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-01 03:11:56.438264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler  # Using RandomOverSampler\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling: Counter({0: 5443, 3: 587, 5: 480, 4: 451, 8: 207, 7: 204, 6: 59, 1: 2, 2: 1})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Raw_MAIN_DATASET_IMPUTATION_after_deleting_stai_badge_activity_step_goal.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "df = df.drop(['id', 'date'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Emotions', axis=1)\n",
    "y = df['Emotions']\n",
    "\n",
    "# Convert categorical target to numeric using label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Check the initial class distribution\n",
    "print(\"Class distribution before oversampling:\", Counter(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after oversampling: Counter({0: 5443, 3: 5443, 7: 5443, 8: 5443, 4: 5443, 5: 5443, 6: 5443, 1: 5443, 2: 5443})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Oversampling to handle class imbalance using RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after oversampling\n",
    "print(\"Class distribution after oversampling:\", Counter(y))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Feature Selection\n",
    "selector = SelectKBest(f_classif, k=60)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_val = selector.transform(X_val)\n",
    "X_test = selector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2024-10-01 03:12:01.306730: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='linear'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  # Output layer (number of unique emotions)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.2783 - loss: 2.5763 - val_accuracy: 0.5305 - val_loss: 1.3264\n",
      "Epoch 2/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.4270 - loss: 1.8434 - val_accuracy: 0.5942 - val_loss: 1.1755\n",
      "Epoch 3/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.4634 - loss: 1.6271 - val_accuracy: 0.6361 - val_loss: 1.0875\n",
      "Epoch 4/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.4929 - loss: 1.4865 - val_accuracy: 0.6545 - val_loss: 1.0306\n",
      "Epoch 5/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.5150 - loss: 1.3998 - val_accuracy: 0.6711 - val_loss: 0.9805\n",
      "Epoch 6/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.5296 - loss: 1.3382 - val_accuracy: 0.6838 - val_loss: 0.9381\n",
      "Epoch 7/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.5591 - loss: 1.2579 - val_accuracy: 0.6960 - val_loss: 0.9021\n",
      "Epoch 8/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.5727 - loss: 1.1935 - val_accuracy: 0.7081 - val_loss: 0.8704\n",
      "Epoch 9/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.5850 - loss: 1.1507 - val_accuracy: 0.7156 - val_loss: 0.8364\n",
      "Epoch 10/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.5983 - loss: 1.1164 - val_accuracy: 0.7314 - val_loss: 0.8062\n",
      "Epoch 11/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.6099 - loss: 1.0789 - val_accuracy: 0.7364 - val_loss: 0.7794\n",
      "Epoch 12/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.6187 - loss: 1.0476 - val_accuracy: 0.7507 - val_loss: 0.7535\n",
      "Epoch 13/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.6318 - loss: 1.0153 - val_accuracy: 0.7594 - val_loss: 0.7300\n",
      "Epoch 14/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.6452 - loss: 0.9794 - val_accuracy: 0.7614 - val_loss: 0.7091\n",
      "Epoch 15/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.6505 - loss: 0.9640 - val_accuracy: 0.7752 - val_loss: 0.6862\n",
      "Epoch 16/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.6543 - loss: 0.9428 - val_accuracy: 0.7800 - val_loss: 0.6669\n",
      "Epoch 17/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.6701 - loss: 0.9097 - val_accuracy: 0.7890 - val_loss: 0.6501\n",
      "Epoch 18/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.6792 - loss: 0.8840 - val_accuracy: 0.7938 - val_loss: 0.6309\n",
      "Epoch 19/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.6799 - loss: 0.8758 - val_accuracy: 0.8002 - val_loss: 0.6107\n",
      "Epoch 20/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.6916 - loss: 0.8520 - val_accuracy: 0.8080 - val_loss: 0.5979\n",
      "Epoch 21/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.6978 - loss: 0.8350 - val_accuracy: 0.8149 - val_loss: 0.5784\n",
      "Epoch 22/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.7015 - loss: 0.8112 - val_accuracy: 0.8227 - val_loss: 0.5605\n",
      "Epoch 23/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.7091 - loss: 0.8052 - val_accuracy: 0.8312 - val_loss: 0.5451\n",
      "Epoch 24/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7183 - loss: 0.7755 - val_accuracy: 0.8324 - val_loss: 0.5310\n",
      "Epoch 25/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.7216 - loss: 0.7672 - val_accuracy: 0.8401 - val_loss: 0.5190\n",
      "Epoch 26/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.7258 - loss: 0.7531 - val_accuracy: 0.8437 - val_loss: 0.5038\n",
      "Epoch 27/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.7311 - loss: 0.7471 - val_accuracy: 0.8464 - val_loss: 0.4953\n",
      "Epoch 28/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.7329 - loss: 0.7447 - val_accuracy: 0.8489 - val_loss: 0.4834\n",
      "Epoch 29/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.7412 - loss: 0.7155 - val_accuracy: 0.8563 - val_loss: 0.4691\n",
      "Epoch 30/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7497 - loss: 0.7007 - val_accuracy: 0.8616 - val_loss: 0.4606\n",
      "Epoch 31/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7502 - loss: 0.6940 - val_accuracy: 0.8632 - val_loss: 0.4487\n",
      "Epoch 32/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.7583 - loss: 0.6795 - val_accuracy: 0.8645 - val_loss: 0.4381\n",
      "Epoch 33/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7586 - loss: 0.6668 - val_accuracy: 0.8683 - val_loss: 0.4313\n",
      "Epoch 34/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 28ms/step - accuracy: 0.7640 - loss: 0.6636 - val_accuracy: 0.8724 - val_loss: 0.4212\n",
      "Epoch 35/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.7614 - loss: 0.6581 - val_accuracy: 0.8760 - val_loss: 0.4124\n",
      "Epoch 36/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.7685 - loss: 0.6482 - val_accuracy: 0.8794 - val_loss: 0.4047\n",
      "Epoch 37/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.7693 - loss: 0.6415 - val_accuracy: 0.8793 - val_loss: 0.3967\n",
      "Epoch 38/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.7799 - loss: 0.6202 - val_accuracy: 0.8861 - val_loss: 0.3896\n",
      "Epoch 39/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.7780 - loss: 0.6236 - val_accuracy: 0.8840 - val_loss: 0.3840\n",
      "Epoch 40/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.7835 - loss: 0.6116 - val_accuracy: 0.8870 - val_loss: 0.3751\n",
      "Epoch 41/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.7852 - loss: 0.6095 - val_accuracy: 0.8873 - val_loss: 0.3684\n",
      "Epoch 42/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.7876 - loss: 0.5939 - val_accuracy: 0.8902 - val_loss: 0.3606\n",
      "Epoch 43/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.7931 - loss: 0.5893 - val_accuracy: 0.8926 - val_loss: 0.3547\n",
      "Epoch 44/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.7924 - loss: 0.5863 - val_accuracy: 0.8947 - val_loss: 0.3479\n",
      "Epoch 45/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.7970 - loss: 0.5787 - val_accuracy: 0.8944 - val_loss: 0.3427\n",
      "Epoch 46/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 26ms/step - accuracy: 0.7951 - loss: 0.5733 - val_accuracy: 0.8941 - val_loss: 0.3399\n",
      "Epoch 47/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.7976 - loss: 0.5727 - val_accuracy: 0.9002 - val_loss: 0.3336\n",
      "Epoch 48/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.8063 - loss: 0.5556 - val_accuracy: 0.9039 - val_loss: 0.3262\n",
      "Epoch 49/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8025 - loss: 0.5517 - val_accuracy: 0.9021 - val_loss: 0.3206\n",
      "Epoch 50/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8137 - loss: 0.5313 - val_accuracy: 0.9051 - val_loss: 0.3165\n",
      "Epoch 51/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8066 - loss: 0.5371 - val_accuracy: 0.9064 - val_loss: 0.3107\n",
      "Epoch 52/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8110 - loss: 0.5335 - val_accuracy: 0.9081 - val_loss: 0.3049\n",
      "Epoch 53/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8130 - loss: 0.5399 - val_accuracy: 0.9095 - val_loss: 0.3009\n",
      "Epoch 54/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8132 - loss: 0.5229 - val_accuracy: 0.9116 - val_loss: 0.2949\n",
      "Epoch 55/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 26ms/step - accuracy: 0.8211 - loss: 0.5064 - val_accuracy: 0.9127 - val_loss: 0.2903\n",
      "Epoch 56/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8185 - loss: 0.5118 - val_accuracy: 0.9161 - val_loss: 0.2849\n",
      "Epoch 57/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 26ms/step - accuracy: 0.8236 - loss: 0.5076 - val_accuracy: 0.9127 - val_loss: 0.2832\n",
      "Epoch 58/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.8254 - loss: 0.4953 - val_accuracy: 0.9161 - val_loss: 0.2802\n",
      "Epoch 59/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8186 - loss: 0.5080 - val_accuracy: 0.9145 - val_loss: 0.2785\n",
      "Epoch 60/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 26ms/step - accuracy: 0.8254 - loss: 0.4945 - val_accuracy: 0.9172 - val_loss: 0.2766\n",
      "Epoch 61/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8284 - loss: 0.4828 - val_accuracy: 0.9194 - val_loss: 0.2688\n",
      "Epoch 62/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8297 - loss: 0.4820 - val_accuracy: 0.9217 - val_loss: 0.2669\n",
      "Epoch 63/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8312 - loss: 0.4872 - val_accuracy: 0.9240 - val_loss: 0.2641\n",
      "Epoch 64/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8302 - loss: 0.4818 - val_accuracy: 0.9205 - val_loss: 0.2601\n",
      "Epoch 65/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8342 - loss: 0.4770 - val_accuracy: 0.9218 - val_loss: 0.2567\n",
      "Epoch 66/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8354 - loss: 0.4687 - val_accuracy: 0.9242 - val_loss: 0.2534\n",
      "Epoch 67/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8362 - loss: 0.4651 - val_accuracy: 0.9222 - val_loss: 0.2509\n",
      "Epoch 68/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8429 - loss: 0.4492 - val_accuracy: 0.9254 - val_loss: 0.2467\n",
      "Epoch 69/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.8411 - loss: 0.4532 - val_accuracy: 0.9231 - val_loss: 0.2459\n",
      "Epoch 70/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8412 - loss: 0.4517 - val_accuracy: 0.9264 - val_loss: 0.2423\n",
      "Epoch 71/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8426 - loss: 0.4510 - val_accuracy: 0.9275 - val_loss: 0.2409\n",
      "Epoch 72/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8435 - loss: 0.4459 - val_accuracy: 0.9291 - val_loss: 0.2350\n",
      "Epoch 73/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8409 - loss: 0.4581 - val_accuracy: 0.9302 - val_loss: 0.2344\n",
      "Epoch 74/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8511 - loss: 0.4344 - val_accuracy: 0.9319 - val_loss: 0.2330\n",
      "Epoch 75/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8482 - loss: 0.4315 - val_accuracy: 0.9338 - val_loss: 0.2279\n",
      "Epoch 76/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8477 - loss: 0.4348 - val_accuracy: 0.9342 - val_loss: 0.2261\n",
      "Epoch 77/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.8537 - loss: 0.4337 - val_accuracy: 0.9325 - val_loss: 0.2230\n",
      "Epoch 78/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8526 - loss: 0.4165 - val_accuracy: 0.9362 - val_loss: 0.2219\n",
      "Epoch 79/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8490 - loss: 0.4274 - val_accuracy: 0.9357 - val_loss: 0.2190\n",
      "Epoch 80/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8558 - loss: 0.4182 - val_accuracy: 0.9374 - val_loss: 0.2180\n",
      "Epoch 81/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8553 - loss: 0.4101 - val_accuracy: 0.9370 - val_loss: 0.2144\n",
      "Epoch 82/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8525 - loss: 0.4162 - val_accuracy: 0.9371 - val_loss: 0.2137\n",
      "Epoch 83/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8543 - loss: 0.4111 - val_accuracy: 0.9394 - val_loss: 0.2106\n",
      "Epoch 84/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8537 - loss: 0.4133 - val_accuracy: 0.9398 - val_loss: 0.2102\n",
      "Epoch 85/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8616 - loss: 0.3999 - val_accuracy: 0.9380 - val_loss: 0.2085\n",
      "Epoch 86/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.8595 - loss: 0.4037 - val_accuracy: 0.9399 - val_loss: 0.2050\n",
      "Epoch 87/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8624 - loss: 0.3917 - val_accuracy: 0.9418 - val_loss: 0.2029\n",
      "Epoch 88/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.8538 - loss: 0.4150 - val_accuracy: 0.9390 - val_loss: 0.2013\n",
      "Epoch 89/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8637 - loss: 0.3917 - val_accuracy: 0.9418 - val_loss: 0.2005\n",
      "Epoch 90/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8630 - loss: 0.3928 - val_accuracy: 0.9402 - val_loss: 0.1971\n",
      "Epoch 91/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.8630 - loss: 0.3880 - val_accuracy: 0.9419 - val_loss: 0.1959\n",
      "Epoch 92/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8647 - loss: 0.3871 - val_accuracy: 0.9430 - val_loss: 0.1946\n",
      "Epoch 93/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8643 - loss: 0.3885 - val_accuracy: 0.9409 - val_loss: 0.1920\n",
      "Epoch 94/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8667 - loss: 0.3851 - val_accuracy: 0.9409 - val_loss: 0.1904\n",
      "Epoch 95/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8658 - loss: 0.3894 - val_accuracy: 0.9459 - val_loss: 0.1872\n",
      "Epoch 96/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8688 - loss: 0.3765 - val_accuracy: 0.9435 - val_loss: 0.1881\n",
      "Epoch 97/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 28ms/step - accuracy: 0.8702 - loss: 0.3785 - val_accuracy: 0.9450 - val_loss: 0.1884\n",
      "Epoch 98/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8713 - loss: 0.3674 - val_accuracy: 0.9451 - val_loss: 0.1857\n",
      "Epoch 99/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8752 - loss: 0.3667 - val_accuracy: 0.9446 - val_loss: 0.1851\n",
      "Epoch 100/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8671 - loss: 0.3743 - val_accuracy: 0.9463 - val_loss: 0.1811\n",
      "Epoch 101/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8728 - loss: 0.3687 - val_accuracy: 0.9491 - val_loss: 0.1779\n",
      "Epoch 102/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8707 - loss: 0.3701 - val_accuracy: 0.9467 - val_loss: 0.1791\n",
      "Epoch 103/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8723 - loss: 0.3656 - val_accuracy: 0.9486 - val_loss: 0.1779\n",
      "Epoch 104/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8730 - loss: 0.3701 - val_accuracy: 0.9488 - val_loss: 0.1763\n",
      "Epoch 105/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 27ms/step - accuracy: 0.8763 - loss: 0.3580 - val_accuracy: 0.9471 - val_loss: 0.1763\n",
      "Epoch 106/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8736 - loss: 0.3614 - val_accuracy: 0.9487 - val_loss: 0.1736\n",
      "Epoch 107/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8756 - loss: 0.3630 - val_accuracy: 0.9506 - val_loss: 0.1709\n",
      "Epoch 108/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8778 - loss: 0.3545 - val_accuracy: 0.9533 - val_loss: 0.1685\n",
      "Epoch 109/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8823 - loss: 0.3446 - val_accuracy: 0.9495 - val_loss: 0.1688\n",
      "Epoch 110/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.8794 - loss: 0.3481 - val_accuracy: 0.9518 - val_loss: 0.1683\n",
      "Epoch 111/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8771 - loss: 0.3504 - val_accuracy: 0.9509 - val_loss: 0.1677\n",
      "Epoch 112/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8794 - loss: 0.3497 - val_accuracy: 0.9495 - val_loss: 0.1672\n",
      "Epoch 113/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8805 - loss: 0.3461 - val_accuracy: 0.9536 - val_loss: 0.1649\n",
      "Epoch 114/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 29ms/step - accuracy: 0.8786 - loss: 0.3564 - val_accuracy: 0.9530 - val_loss: 0.1626\n",
      "Epoch 115/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.8791 - loss: 0.3395 - val_accuracy: 0.9515 - val_loss: 0.1619\n",
      "Epoch 116/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8820 - loss: 0.3431 - val_accuracy: 0.9528 - val_loss: 0.1614\n",
      "Epoch 117/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8795 - loss: 0.3419 - val_accuracy: 0.9538 - val_loss: 0.1610\n",
      "Epoch 118/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8851 - loss: 0.3322 - val_accuracy: 0.9545 - val_loss: 0.1576\n",
      "Epoch 119/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.8861 - loss: 0.3347 - val_accuracy: 0.9546 - val_loss: 0.1589\n",
      "Epoch 120/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8857 - loss: 0.3322 - val_accuracy: 0.9541 - val_loss: 0.1564\n",
      "Epoch 121/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8839 - loss: 0.3320 - val_accuracy: 0.9571 - val_loss: 0.1562\n",
      "Epoch 122/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8806 - loss: 0.3415 - val_accuracy: 0.9556 - val_loss: 0.1551\n",
      "Epoch 123/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8847 - loss: 0.3350 - val_accuracy: 0.9561 - val_loss: 0.1549\n",
      "Epoch 124/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8821 - loss: 0.3378 - val_accuracy: 0.9556 - val_loss: 0.1548\n",
      "Epoch 125/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8836 - loss: 0.3303 - val_accuracy: 0.9571 - val_loss: 0.1525\n",
      "Epoch 126/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8892 - loss: 0.3235 - val_accuracy: 0.9543 - val_loss: 0.1532\n",
      "Epoch 127/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8848 - loss: 0.3298 - val_accuracy: 0.9574 - val_loss: 0.1517\n",
      "Epoch 128/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8871 - loss: 0.3288 - val_accuracy: 0.9565 - val_loss: 0.1495\n",
      "Epoch 129/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8870 - loss: 0.3240 - val_accuracy: 0.9559 - val_loss: 0.1499\n",
      "Epoch 130/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8915 - loss: 0.3205 - val_accuracy: 0.9587 - val_loss: 0.1484\n",
      "Epoch 131/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8889 - loss: 0.3198 - val_accuracy: 0.9606 - val_loss: 0.1468\n",
      "Epoch 132/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8845 - loss: 0.3299 - val_accuracy: 0.9574 - val_loss: 0.1465\n",
      "Epoch 133/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8891 - loss: 0.3201 - val_accuracy: 0.9588 - val_loss: 0.1460\n",
      "Epoch 134/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8903 - loss: 0.3212 - val_accuracy: 0.9593 - val_loss: 0.1458\n",
      "Epoch 135/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.8943 - loss: 0.3093 - val_accuracy: 0.9607 - val_loss: 0.1437\n",
      "Epoch 136/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8923 - loss: 0.3124 - val_accuracy: 0.9599 - val_loss: 0.1434\n",
      "Epoch 137/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 27ms/step - accuracy: 0.8918 - loss: 0.3061 - val_accuracy: 0.9593 - val_loss: 0.1422\n",
      "Epoch 138/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8914 - loss: 0.3113 - val_accuracy: 0.9610 - val_loss: 0.1408\n",
      "Epoch 139/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.8913 - loss: 0.3121 - val_accuracy: 0.9606 - val_loss: 0.1402\n",
      "Epoch 140/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8953 - loss: 0.3037 - val_accuracy: 0.9597 - val_loss: 0.1408\n",
      "Epoch 141/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.8987 - loss: 0.2985 - val_accuracy: 0.9596 - val_loss: 0.1404\n",
      "Epoch 142/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8933 - loss: 0.3028 - val_accuracy: 0.9608 - val_loss: 0.1395\n",
      "Epoch 143/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8960 - loss: 0.2996 - val_accuracy: 0.9626 - val_loss: 0.1371\n",
      "Epoch 144/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.8957 - loss: 0.2959 - val_accuracy: 0.9621 - val_loss: 0.1363\n",
      "Epoch 145/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.8957 - loss: 0.2995 - val_accuracy: 0.9631 - val_loss: 0.1348\n",
      "Epoch 146/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8961 - loss: 0.2994 - val_accuracy: 0.9625 - val_loss: 0.1344\n",
      "Epoch 147/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8979 - loss: 0.2925 - val_accuracy: 0.9619 - val_loss: 0.1331\n",
      "Epoch 148/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8994 - loss: 0.2967 - val_accuracy: 0.9616 - val_loss: 0.1339\n",
      "Epoch 149/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9012 - loss: 0.2898 - val_accuracy: 0.9638 - val_loss: 0.1335\n",
      "Epoch 150/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8966 - loss: 0.2962 - val_accuracy: 0.9610 - val_loss: 0.1341\n",
      "Epoch 151/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8972 - loss: 0.2980 - val_accuracy: 0.9624 - val_loss: 0.1322\n",
      "Epoch 152/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8971 - loss: 0.2918 - val_accuracy: 0.9638 - val_loss: 0.1314\n",
      "Epoch 153/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9012 - loss: 0.2885 - val_accuracy: 0.9627 - val_loss: 0.1307\n",
      "Epoch 154/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9015 - loss: 0.2884 - val_accuracy: 0.9639 - val_loss: 0.1298\n",
      "Epoch 155/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.8985 - loss: 0.2915 - val_accuracy: 0.9638 - val_loss: 0.1283\n",
      "Epoch 156/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8965 - loss: 0.2965 - val_accuracy: 0.9652 - val_loss: 0.1278\n",
      "Epoch 157/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9055 - loss: 0.2815 - val_accuracy: 0.9649 - val_loss: 0.1285\n",
      "Epoch 158/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9016 - loss: 0.2881 - val_accuracy: 0.9648 - val_loss: 0.1265\n",
      "Epoch 159/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9040 - loss: 0.2810 - val_accuracy: 0.9631 - val_loss: 0.1268\n",
      "Epoch 160/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9004 - loss: 0.2876 - val_accuracy: 0.9626 - val_loss: 0.1269\n",
      "Epoch 161/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9026 - loss: 0.2859 - val_accuracy: 0.9639 - val_loss: 0.1256\n",
      "Epoch 162/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9034 - loss: 0.2813 - val_accuracy: 0.9641 - val_loss: 0.1247\n",
      "Epoch 163/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9034 - loss: 0.2813 - val_accuracy: 0.9672 - val_loss: 0.1238\n",
      "Epoch 164/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9034 - loss: 0.2820 - val_accuracy: 0.9658 - val_loss: 0.1238\n",
      "Epoch 165/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9019 - loss: 0.2808 - val_accuracy: 0.9667 - val_loss: 0.1243\n",
      "Epoch 166/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9053 - loss: 0.2729 - val_accuracy: 0.9680 - val_loss: 0.1208\n",
      "Epoch 167/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9026 - loss: 0.2817 - val_accuracy: 0.9649 - val_loss: 0.1235\n",
      "Epoch 168/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9047 - loss: 0.2776 - val_accuracy: 0.9641 - val_loss: 0.1216\n",
      "Epoch 169/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9053 - loss: 0.2699 - val_accuracy: 0.9671 - val_loss: 0.1204\n",
      "Epoch 170/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9043 - loss: 0.2780 - val_accuracy: 0.9643 - val_loss: 0.1213\n",
      "Epoch 171/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9065 - loss: 0.2678 - val_accuracy: 0.9668 - val_loss: 0.1192\n",
      "Epoch 172/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9065 - loss: 0.2742 - val_accuracy: 0.9681 - val_loss: 0.1204\n",
      "Epoch 173/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9126 - loss: 0.2617 - val_accuracy: 0.9657 - val_loss: 0.1195\n",
      "Epoch 174/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9066 - loss: 0.2729 - val_accuracy: 0.9664 - val_loss: 0.1182\n",
      "Epoch 175/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9122 - loss: 0.2637 - val_accuracy: 0.9681 - val_loss: 0.1182\n",
      "Epoch 176/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9077 - loss: 0.2727 - val_accuracy: 0.9682 - val_loss: 0.1177\n",
      "Epoch 177/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9044 - loss: 0.2746 - val_accuracy: 0.9675 - val_loss: 0.1184\n",
      "Epoch 178/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9098 - loss: 0.2625 - val_accuracy: 0.9694 - val_loss: 0.1147\n",
      "Epoch 179/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9110 - loss: 0.2648 - val_accuracy: 0.9663 - val_loss: 0.1156\n",
      "Epoch 180/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9073 - loss: 0.2659 - val_accuracy: 0.9657 - val_loss: 0.1159\n",
      "Epoch 181/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9086 - loss: 0.2647 - val_accuracy: 0.9659 - val_loss: 0.1165\n",
      "Epoch 182/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9061 - loss: 0.2676 - val_accuracy: 0.9680 - val_loss: 0.1143\n",
      "Epoch 183/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9104 - loss: 0.2632 - val_accuracy: 0.9677 - val_loss: 0.1155\n",
      "Epoch 184/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9092 - loss: 0.2595 - val_accuracy: 0.9677 - val_loss: 0.1148\n",
      "Epoch 185/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9115 - loss: 0.2636 - val_accuracy: 0.9668 - val_loss: 0.1143\n",
      "Epoch 186/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9132 - loss: 0.2549 - val_accuracy: 0.9677 - val_loss: 0.1140\n",
      "Epoch 187/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9071 - loss: 0.2644 - val_accuracy: 0.9682 - val_loss: 0.1151\n",
      "Epoch 188/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9118 - loss: 0.2592 - val_accuracy: 0.9678 - val_loss: 0.1131\n",
      "Epoch 189/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9097 - loss: 0.2608 - val_accuracy: 0.9686 - val_loss: 0.1129\n",
      "Epoch 190/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9136 - loss: 0.2525 - val_accuracy: 0.9682 - val_loss: 0.1113\n",
      "Epoch 191/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9170 - loss: 0.2512 - val_accuracy: 0.9698 - val_loss: 0.1112\n",
      "Epoch 192/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9115 - loss: 0.2580 - val_accuracy: 0.9701 - val_loss: 0.1099\n",
      "Epoch 193/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9109 - loss: 0.2606 - val_accuracy: 0.9678 - val_loss: 0.1115\n",
      "Epoch 194/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9135 - loss: 0.2589 - val_accuracy: 0.9698 - val_loss: 0.1091\n",
      "Epoch 195/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9153 - loss: 0.2456 - val_accuracy: 0.9693 - val_loss: 0.1096\n",
      "Epoch 196/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9136 - loss: 0.2506 - val_accuracy: 0.9690 - val_loss: 0.1095\n",
      "Epoch 197/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9149 - loss: 0.2504 - val_accuracy: 0.9675 - val_loss: 0.1103\n",
      "Epoch 198/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9148 - loss: 0.2482 - val_accuracy: 0.9700 - val_loss: 0.1079\n",
      "Epoch 199/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9126 - loss: 0.2591 - val_accuracy: 0.9699 - val_loss: 0.1096\n",
      "Epoch 200/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9154 - loss: 0.2476 - val_accuracy: 0.9698 - val_loss: 0.1079\n",
      "Epoch 201/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9130 - loss: 0.2480 - val_accuracy: 0.9704 - val_loss: 0.1085\n",
      "Epoch 202/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9092 - loss: 0.2589 - val_accuracy: 0.9696 - val_loss: 0.1085\n",
      "Epoch 203/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9156 - loss: 0.2439 - val_accuracy: 0.9682 - val_loss: 0.1088\n",
      "Epoch 204/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9157 - loss: 0.2474 - val_accuracy: 0.9703 - val_loss: 0.1101\n",
      "Epoch 205/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9130 - loss: 0.2528 - val_accuracy: 0.9705 - val_loss: 0.1090\n",
      "Epoch 206/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9157 - loss: 0.2454 - val_accuracy: 0.9684 - val_loss: 0.1090\n",
      "Epoch 207/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9157 - loss: 0.2546 - val_accuracy: 0.9689 - val_loss: 0.1084\n",
      "Epoch 208/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9143 - loss: 0.2454 - val_accuracy: 0.9691 - val_loss: 0.1077\n",
      "Epoch 209/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9206 - loss: 0.2360 - val_accuracy: 0.9701 - val_loss: 0.1059\n",
      "Epoch 210/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9198 - loss: 0.2415 - val_accuracy: 0.9705 - val_loss: 0.1063\n",
      "Epoch 211/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9178 - loss: 0.2394 - val_accuracy: 0.9703 - val_loss: 0.1061\n",
      "Epoch 212/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 29ms/step - accuracy: 0.9145 - loss: 0.2489 - val_accuracy: 0.9708 - val_loss: 0.1061\n",
      "Epoch 213/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9181 - loss: 0.2455 - val_accuracy: 0.9684 - val_loss: 0.1058\n",
      "Epoch 214/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9174 - loss: 0.2416 - val_accuracy: 0.9718 - val_loss: 0.1041\n",
      "Epoch 215/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9162 - loss: 0.2400 - val_accuracy: 0.9696 - val_loss: 0.1042\n",
      "Epoch 216/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.9143 - loss: 0.2497 - val_accuracy: 0.9715 - val_loss: 0.1029\n",
      "Epoch 217/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9157 - loss: 0.2465 - val_accuracy: 0.9703 - val_loss: 0.1042\n",
      "Epoch 218/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9144 - loss: 0.2449 - val_accuracy: 0.9705 - val_loss: 0.1053\n",
      "Epoch 219/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 28ms/step - accuracy: 0.9201 - loss: 0.2357 - val_accuracy: 0.9713 - val_loss: 0.1037\n",
      "Epoch 220/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9187 - loss: 0.2368 - val_accuracy: 0.9713 - val_loss: 0.1043\n",
      "Epoch 221/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9192 - loss: 0.2420 - val_accuracy: 0.9710 - val_loss: 0.1042\n",
      "Epoch 222/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9177 - loss: 0.2427 - val_accuracy: 0.9703 - val_loss: 0.1046\n",
      "Epoch 223/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9210 - loss: 0.2401 - val_accuracy: 0.9709 - val_loss: 0.1049\n",
      "Epoch 224/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9193 - loss: 0.2348 - val_accuracy: 0.9722 - val_loss: 0.1035\n",
      "Epoch 225/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9199 - loss: 0.2339 - val_accuracy: 0.9710 - val_loss: 0.1033\n",
      "Epoch 226/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9193 - loss: 0.2396 - val_accuracy: 0.9723 - val_loss: 0.1020\n",
      "Epoch 227/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9228 - loss: 0.2327 - val_accuracy: 0.9695 - val_loss: 0.1034\n",
      "Epoch 228/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9194 - loss: 0.2391 - val_accuracy: 0.9695 - val_loss: 0.1020\n",
      "Epoch 229/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9229 - loss: 0.2304 - val_accuracy: 0.9713 - val_loss: 0.1025\n",
      "Epoch 230/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9219 - loss: 0.2247 - val_accuracy: 0.9703 - val_loss: 0.1025\n",
      "Epoch 231/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9198 - loss: 0.2381 - val_accuracy: 0.9704 - val_loss: 0.1012\n",
      "Epoch 232/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9212 - loss: 0.2339 - val_accuracy: 0.9732 - val_loss: 0.1003\n",
      "Epoch 233/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9214 - loss: 0.2299 - val_accuracy: 0.9722 - val_loss: 0.1004\n",
      "Epoch 234/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9208 - loss: 0.2318 - val_accuracy: 0.9735 - val_loss: 0.1004\n",
      "Epoch 235/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9209 - loss: 0.2273 - val_accuracy: 0.9719 - val_loss: 0.1000\n",
      "Epoch 236/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9201 - loss: 0.2323 - val_accuracy: 0.9715 - val_loss: 0.1001\n",
      "Epoch 237/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9191 - loss: 0.2358 - val_accuracy: 0.9736 - val_loss: 0.0986\n",
      "Epoch 238/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9206 - loss: 0.2306 - val_accuracy: 0.9730 - val_loss: 0.0990\n",
      "Epoch 239/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9214 - loss: 0.2300 - val_accuracy: 0.9737 - val_loss: 0.0976\n",
      "Epoch 240/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9237 - loss: 0.2279 - val_accuracy: 0.9730 - val_loss: 0.0972\n",
      "Epoch 241/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - accuracy: 0.9220 - loss: 0.2285 - val_accuracy: 0.9723 - val_loss: 0.0984\n",
      "Epoch 242/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9268 - loss: 0.2198 - val_accuracy: 0.9719 - val_loss: 0.0991\n",
      "Epoch 243/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9222 - loss: 0.2232 - val_accuracy: 0.9744 - val_loss: 0.0960\n",
      "Epoch 244/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9224 - loss: 0.2278 - val_accuracy: 0.9732 - val_loss: 0.0993\n",
      "Epoch 245/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9205 - loss: 0.2298 - val_accuracy: 0.9731 - val_loss: 0.0974\n",
      "Epoch 246/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9201 - loss: 0.2338 - val_accuracy: 0.9728 - val_loss: 0.0978\n",
      "Epoch 247/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9247 - loss: 0.2229 - val_accuracy: 0.9728 - val_loss: 0.0957\n",
      "Epoch 248/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9226 - loss: 0.2258 - val_accuracy: 0.9718 - val_loss: 0.0973\n",
      "Epoch 249/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9249 - loss: 0.2223 - val_accuracy: 0.9722 - val_loss: 0.0961\n",
      "Epoch 250/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9282 - loss: 0.2171 - val_accuracy: 0.9733 - val_loss: 0.0958\n",
      "Epoch 251/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9249 - loss: 0.2186 - val_accuracy: 0.9722 - val_loss: 0.0981\n",
      "Epoch 252/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9198 - loss: 0.2359 - val_accuracy: 0.9736 - val_loss: 0.0964\n",
      "Epoch 253/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9216 - loss: 0.2285 - val_accuracy: 0.9737 - val_loss: 0.0962\n",
      "Epoch 254/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9218 - loss: 0.2239 - val_accuracy: 0.9723 - val_loss: 0.0956\n",
      "Epoch 255/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.9264 - loss: 0.2162 - val_accuracy: 0.9741 - val_loss: 0.0962\n",
      "Epoch 256/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9237 - loss: 0.2200 - val_accuracy: 0.9738 - val_loss: 0.0965\n",
      "Epoch 257/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9253 - loss: 0.2210 - val_accuracy: 0.9730 - val_loss: 0.0950\n",
      "Epoch 258/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9231 - loss: 0.2218 - val_accuracy: 0.9750 - val_loss: 0.0949\n",
      "Epoch 259/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9258 - loss: 0.2165 - val_accuracy: 0.9735 - val_loss: 0.0947\n",
      "Epoch 260/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9235 - loss: 0.2258 - val_accuracy: 0.9728 - val_loss: 0.0958\n",
      "Epoch 261/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9244 - loss: 0.2193 - val_accuracy: 0.9732 - val_loss: 0.0951\n",
      "Epoch 262/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9231 - loss: 0.2250 - val_accuracy: 0.9735 - val_loss: 0.0943\n",
      "Epoch 263/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9282 - loss: 0.2148 - val_accuracy: 0.9719 - val_loss: 0.0933\n",
      "Epoch 264/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9244 - loss: 0.2223 - val_accuracy: 0.9732 - val_loss: 0.0929\n",
      "Epoch 265/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9234 - loss: 0.2225 - val_accuracy: 0.9745 - val_loss: 0.0923\n",
      "Epoch 266/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9252 - loss: 0.2179 - val_accuracy: 0.9740 - val_loss: 0.0941\n",
      "Epoch 267/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9268 - loss: 0.2089 - val_accuracy: 0.9741 - val_loss: 0.0922\n",
      "Epoch 268/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9248 - loss: 0.2143 - val_accuracy: 0.9731 - val_loss: 0.0947\n",
      "Epoch 269/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9269 - loss: 0.2104 - val_accuracy: 0.9750 - val_loss: 0.0910\n",
      "Epoch 270/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9268 - loss: 0.2172 - val_accuracy: 0.9737 - val_loss: 0.0929\n",
      "Epoch 271/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9208 - loss: 0.2288 - val_accuracy: 0.9740 - val_loss: 0.0924\n",
      "Epoch 272/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9240 - loss: 0.2181 - val_accuracy: 0.9749 - val_loss: 0.0915\n",
      "Epoch 273/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9280 - loss: 0.2075 - val_accuracy: 0.9752 - val_loss: 0.0910\n",
      "Epoch 274/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9254 - loss: 0.2158 - val_accuracy: 0.9758 - val_loss: 0.0917\n",
      "Epoch 275/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9279 - loss: 0.2079 - val_accuracy: 0.9742 - val_loss: 0.0917\n",
      "Epoch 276/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9258 - loss: 0.2158 - val_accuracy: 0.9754 - val_loss: 0.0908\n",
      "Epoch 277/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9261 - loss: 0.2118 - val_accuracy: 0.9750 - val_loss: 0.0925\n",
      "Epoch 278/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9280 - loss: 0.2005 - val_accuracy: 0.9736 - val_loss: 0.0915\n",
      "Epoch 279/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9310 - loss: 0.2083 - val_accuracy: 0.9751 - val_loss: 0.0907\n",
      "Epoch 280/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9243 - loss: 0.2180 - val_accuracy: 0.9740 - val_loss: 0.0898\n",
      "Epoch 281/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9288 - loss: 0.2039 - val_accuracy: 0.9745 - val_loss: 0.0893\n",
      "Epoch 282/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9292 - loss: 0.2090 - val_accuracy: 0.9761 - val_loss: 0.0904\n",
      "Epoch 283/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9307 - loss: 0.2085 - val_accuracy: 0.9747 - val_loss: 0.0910\n",
      "Epoch 284/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9277 - loss: 0.2110 - val_accuracy: 0.9745 - val_loss: 0.0910\n",
      "Epoch 285/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9305 - loss: 0.2070 - val_accuracy: 0.9758 - val_loss: 0.0902\n",
      "Epoch 286/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9263 - loss: 0.2136 - val_accuracy: 0.9742 - val_loss: 0.0900\n",
      "Epoch 287/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9310 - loss: 0.2056 - val_accuracy: 0.9763 - val_loss: 0.0895\n",
      "Epoch 288/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9299 - loss: 0.2137 - val_accuracy: 0.9754 - val_loss: 0.0888\n",
      "Epoch 289/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 29ms/step - accuracy: 0.9255 - loss: 0.2123 - val_accuracy: 0.9746 - val_loss: 0.0899\n",
      "Epoch 290/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9311 - loss: 0.2009 - val_accuracy: 0.9756 - val_loss: 0.0900\n",
      "Epoch 291/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9282 - loss: 0.2070 - val_accuracy: 0.9738 - val_loss: 0.0896\n",
      "Epoch 292/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9306 - loss: 0.2031 - val_accuracy: 0.9744 - val_loss: 0.0892\n",
      "Epoch 293/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9308 - loss: 0.2031 - val_accuracy: 0.9749 - val_loss: 0.0891\n",
      "Epoch 294/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9273 - loss: 0.2041 - val_accuracy: 0.9731 - val_loss: 0.0910\n",
      "Epoch 295/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9284 - loss: 0.2052 - val_accuracy: 0.9751 - val_loss: 0.0896\n",
      "Epoch 296/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9290 - loss: 0.2098 - val_accuracy: 0.9754 - val_loss: 0.0897\n",
      "Epoch 297/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9327 - loss: 0.1962 - val_accuracy: 0.9752 - val_loss: 0.0884\n",
      "Epoch 298/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9311 - loss: 0.1995 - val_accuracy: 0.9759 - val_loss: 0.0884\n",
      "Epoch 299/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9315 - loss: 0.2048 - val_accuracy: 0.9759 - val_loss: 0.0880\n",
      "Epoch 300/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 27ms/step - accuracy: 0.9300 - loss: 0.2061 - val_accuracy: 0.9756 - val_loss: 0.0889\n",
      "Epoch 301/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9308 - loss: 0.2039 - val_accuracy: 0.9761 - val_loss: 0.0884\n",
      "Epoch 302/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9271 - loss: 0.2189 - val_accuracy: 0.9755 - val_loss: 0.0887\n",
      "Epoch 303/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9303 - loss: 0.2037 - val_accuracy: 0.9754 - val_loss: 0.0887\n",
      "Epoch 304/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9295 - loss: 0.2038 - val_accuracy: 0.9741 - val_loss: 0.0887\n",
      "Epoch 305/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 27ms/step - accuracy: 0.9322 - loss: 0.1991 - val_accuracy: 0.9747 - val_loss: 0.0880\n",
      "Epoch 306/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9287 - loss: 0.2080 - val_accuracy: 0.9758 - val_loss: 0.0882\n",
      "Epoch 307/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9331 - loss: 0.1945 - val_accuracy: 0.9752 - val_loss: 0.0886\n",
      "Epoch 308/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9299 - loss: 0.2026 - val_accuracy: 0.9752 - val_loss: 0.0901\n",
      "Epoch 309/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9310 - loss: 0.1967 - val_accuracy: 0.9746 - val_loss: 0.0882\n",
      "Epoch 310/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9279 - loss: 0.2096 - val_accuracy: 0.9754 - val_loss: 0.0883\n",
      "Epoch 311/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9308 - loss: 0.1982 - val_accuracy: 0.9763 - val_loss: 0.0886\n",
      "Epoch 312/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9304 - loss: 0.2085 - val_accuracy: 0.9751 - val_loss: 0.0882\n",
      "Epoch 313/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9350 - loss: 0.1930 - val_accuracy: 0.9765 - val_loss: 0.0870\n",
      "Epoch 314/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.9334 - loss: 0.1954 - val_accuracy: 0.9759 - val_loss: 0.0879\n",
      "Epoch 315/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9314 - loss: 0.2024 - val_accuracy: 0.9761 - val_loss: 0.0868\n",
      "Epoch 316/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - accuracy: 0.9344 - loss: 0.1951 - val_accuracy: 0.9763 - val_loss: 0.0868\n",
      "Epoch 317/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9332 - loss: 0.1984 - val_accuracy: 0.9772 - val_loss: 0.0872\n",
      "Epoch 318/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9304 - loss: 0.2024 - val_accuracy: 0.9754 - val_loss: 0.0882\n",
      "Epoch 319/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9335 - loss: 0.2015 - val_accuracy: 0.9758 - val_loss: 0.0869\n",
      "Epoch 320/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9349 - loss: 0.1934 - val_accuracy: 0.9765 - val_loss: 0.0857\n",
      "Epoch 321/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9309 - loss: 0.2014 - val_accuracy: 0.9764 - val_loss: 0.0861\n",
      "Epoch 322/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9333 - loss: 0.1937 - val_accuracy: 0.9750 - val_loss: 0.0865\n",
      "Epoch 323/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9311 - loss: 0.2029 - val_accuracy: 0.9767 - val_loss: 0.0870\n",
      "Epoch 324/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9364 - loss: 0.1917 - val_accuracy: 0.9767 - val_loss: 0.0860\n",
      "Epoch 325/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9302 - loss: 0.2006 - val_accuracy: 0.9747 - val_loss: 0.0882\n",
      "Epoch 326/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9324 - loss: 0.2032 - val_accuracy: 0.9756 - val_loss: 0.0878\n",
      "Epoch 327/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9313 - loss: 0.2060 - val_accuracy: 0.9755 - val_loss: 0.0872\n",
      "Epoch 328/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9317 - loss: 0.2012 - val_accuracy: 0.9754 - val_loss: 0.0871\n",
      "Epoch 329/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9328 - loss: 0.1990 - val_accuracy: 0.9745 - val_loss: 0.0882\n",
      "Epoch 330/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9315 - loss: 0.1992 - val_accuracy: 0.9760 - val_loss: 0.0866\n",
      "Epoch 331/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9314 - loss: 0.1988 - val_accuracy: 0.9758 - val_loss: 0.0857\n",
      "Epoch 332/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9304 - loss: 0.2052 - val_accuracy: 0.9751 - val_loss: 0.0876\n",
      "Epoch 333/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9338 - loss: 0.1898 - val_accuracy: 0.9764 - val_loss: 0.0854\n",
      "Epoch 334/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9334 - loss: 0.1960 - val_accuracy: 0.9764 - val_loss: 0.0861\n",
      "Epoch 335/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9326 - loss: 0.1954 - val_accuracy: 0.9742 - val_loss: 0.0875\n",
      "Epoch 336/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9340 - loss: 0.1988 - val_accuracy: 0.9749 - val_loss: 0.0875\n",
      "Epoch 337/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9339 - loss: 0.1927 - val_accuracy: 0.9764 - val_loss: 0.0851\n",
      "Epoch 338/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9332 - loss: 0.1976 - val_accuracy: 0.9751 - val_loss: 0.0861\n",
      "Epoch 339/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9351 - loss: 0.1931 - val_accuracy: 0.9761 - val_loss: 0.0854\n",
      "Epoch 340/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9331 - loss: 0.1886 - val_accuracy: 0.9733 - val_loss: 0.0867\n",
      "Epoch 341/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 27ms/step - accuracy: 0.9360 - loss: 0.1858 - val_accuracy: 0.9767 - val_loss: 0.0843\n",
      "Epoch 342/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9342 - loss: 0.1881 - val_accuracy: 0.9752 - val_loss: 0.0872\n",
      "Epoch 343/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9325 - loss: 0.1954 - val_accuracy: 0.9752 - val_loss: 0.0861\n",
      "Epoch 344/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9341 - loss: 0.1904 - val_accuracy: 0.9760 - val_loss: 0.0857\n",
      "Epoch 345/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9325 - loss: 0.1979 - val_accuracy: 0.9760 - val_loss: 0.0850\n",
      "Epoch 346/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9389 - loss: 0.1821 - val_accuracy: 0.9765 - val_loss: 0.0852\n",
      "Epoch 347/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9341 - loss: 0.1917 - val_accuracy: 0.9749 - val_loss: 0.0861\n",
      "Epoch 348/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9336 - loss: 0.1952 - val_accuracy: 0.9756 - val_loss: 0.0841\n",
      "Epoch 349/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9337 - loss: 0.1916 - val_accuracy: 0.9760 - val_loss: 0.0843\n",
      "Epoch 350/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9348 - loss: 0.1942 - val_accuracy: 0.9756 - val_loss: 0.0859\n",
      "Epoch 351/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 26ms/step - accuracy: 0.9348 - loss: 0.1906 - val_accuracy: 0.9768 - val_loss: 0.0831\n",
      "Epoch 352/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9370 - loss: 0.1838 - val_accuracy: 0.9754 - val_loss: 0.0848\n",
      "Epoch 353/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 26ms/step - accuracy: 0.9340 - loss: 0.1932 - val_accuracy: 0.9760 - val_loss: 0.0841\n",
      "Epoch 354/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9363 - loss: 0.1910 - val_accuracy: 0.9756 - val_loss: 0.0862\n",
      "Epoch 355/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9370 - loss: 0.1886 - val_accuracy: 0.9756 - val_loss: 0.0852\n",
      "Epoch 356/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9342 - loss: 0.1911 - val_accuracy: 0.9750 - val_loss: 0.0849\n",
      "Epoch 357/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9350 - loss: 0.1904 - val_accuracy: 0.9759 - val_loss: 0.0846\n",
      "Epoch 358/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9344 - loss: 0.1886 - val_accuracy: 0.9765 - val_loss: 0.0833\n",
      "Epoch 359/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9358 - loss: 0.1881 - val_accuracy: 0.9764 - val_loss: 0.0828\n",
      "Epoch 360/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9373 - loss: 0.1831 - val_accuracy: 0.9765 - val_loss: 0.0837\n",
      "Epoch 361/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9329 - loss: 0.1910 - val_accuracy: 0.9752 - val_loss: 0.0829\n",
      "Epoch 362/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9306 - loss: 0.2005 - val_accuracy: 0.9740 - val_loss: 0.0852\n",
      "Epoch 363/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.9372 - loss: 0.1857 - val_accuracy: 0.9761 - val_loss: 0.0836\n",
      "Epoch 364/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9360 - loss: 0.1892 - val_accuracy: 0.9761 - val_loss: 0.0839\n",
      "Epoch 365/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9365 - loss: 0.1817 - val_accuracy: 0.9764 - val_loss: 0.0843\n",
      "Epoch 366/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9354 - loss: 0.1912 - val_accuracy: 0.9752 - val_loss: 0.0850\n",
      "Epoch 367/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9384 - loss: 0.1792 - val_accuracy: 0.9768 - val_loss: 0.0825\n",
      "Epoch 368/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.9337 - loss: 0.1929 - val_accuracy: 0.9745 - val_loss: 0.0830\n",
      "Epoch 369/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9360 - loss: 0.1820 - val_accuracy: 0.9760 - val_loss: 0.0828\n",
      "Epoch 370/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9356 - loss: 0.1844 - val_accuracy: 0.9763 - val_loss: 0.0829\n",
      "Epoch 371/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9357 - loss: 0.1889 - val_accuracy: 0.9756 - val_loss: 0.0843\n",
      "Epoch 372/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9363 - loss: 0.1884 - val_accuracy: 0.9761 - val_loss: 0.0823\n",
      "Epoch 373/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9352 - loss: 0.1882 - val_accuracy: 0.9758 - val_loss: 0.0826\n",
      "Epoch 374/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9347 - loss: 0.1869 - val_accuracy: 0.9767 - val_loss: 0.0822\n",
      "Epoch 375/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9370 - loss: 0.1804 - val_accuracy: 0.9765 - val_loss: 0.0816\n",
      "Epoch 376/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9343 - loss: 0.1864 - val_accuracy: 0.9765 - val_loss: 0.0823\n",
      "Epoch 377/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9356 - loss: 0.1862 - val_accuracy: 0.9754 - val_loss: 0.0826\n",
      "Epoch 378/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9371 - loss: 0.1838 - val_accuracy: 0.9765 - val_loss: 0.0816\n",
      "Epoch 379/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9356 - loss: 0.1814 - val_accuracy: 0.9763 - val_loss: 0.0825\n",
      "Epoch 380/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9364 - loss: 0.1832 - val_accuracy: 0.9756 - val_loss: 0.0826\n",
      "Epoch 381/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9366 - loss: 0.1866 - val_accuracy: 0.9764 - val_loss: 0.0822\n",
      "Epoch 382/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9368 - loss: 0.1850 - val_accuracy: 0.9768 - val_loss: 0.0808\n",
      "Epoch 383/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9325 - loss: 0.1927 - val_accuracy: 0.9759 - val_loss: 0.0820\n",
      "Epoch 384/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9343 - loss: 0.1865 - val_accuracy: 0.9765 - val_loss: 0.0811\n",
      "Epoch 385/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.9402 - loss: 0.1791 - val_accuracy: 0.9768 - val_loss: 0.0822\n",
      "Epoch 386/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9389 - loss: 0.1816 - val_accuracy: 0.9763 - val_loss: 0.0826\n",
      "Epoch 387/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9355 - loss: 0.1873 - val_accuracy: 0.9758 - val_loss: 0.0838\n",
      "Epoch 388/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 28ms/step - accuracy: 0.9369 - loss: 0.1844 - val_accuracy: 0.9754 - val_loss: 0.0836\n",
      "Epoch 389/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.9365 - loss: 0.1810 - val_accuracy: 0.9763 - val_loss: 0.0810\n",
      "Epoch 390/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9362 - loss: 0.1836 - val_accuracy: 0.9754 - val_loss: 0.0824\n",
      "Epoch 391/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9345 - loss: 0.1918 - val_accuracy: 0.9756 - val_loss: 0.0825\n",
      "Epoch 392/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9399 - loss: 0.1778 - val_accuracy: 0.9759 - val_loss: 0.0831\n",
      "Epoch 393/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9362 - loss: 0.1863 - val_accuracy: 0.9760 - val_loss: 0.0807\n",
      "Epoch 394/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.9358 - loss: 0.1851 - val_accuracy: 0.9769 - val_loss: 0.0812\n",
      "Epoch 395/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9376 - loss: 0.1828 - val_accuracy: 0.9775 - val_loss: 0.0809\n",
      "Epoch 396/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9378 - loss: 0.1846 - val_accuracy: 0.9765 - val_loss: 0.0814\n",
      "Epoch 397/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9355 - loss: 0.1864 - val_accuracy: 0.9763 - val_loss: 0.0835\n",
      "Epoch 398/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9370 - loss: 0.1808 - val_accuracy: 0.9770 - val_loss: 0.0818\n",
      "Epoch 399/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9384 - loss: 0.1836 - val_accuracy: 0.9759 - val_loss: 0.0820\n",
      "Epoch 400/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9376 - loss: 0.1815 - val_accuracy: 0.9764 - val_loss: 0.0825\n",
      "Epoch 401/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9386 - loss: 0.1806 - val_accuracy: 0.9774 - val_loss: 0.0804\n",
      "Epoch 402/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9379 - loss: 0.1831 - val_accuracy: 0.9769 - val_loss: 0.0804\n",
      "Epoch 403/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9385 - loss: 0.1786 - val_accuracy: 0.9760 - val_loss: 0.0803\n",
      "Epoch 404/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9364 - loss: 0.1872 - val_accuracy: 0.9759 - val_loss: 0.0811\n",
      "Epoch 405/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9372 - loss: 0.1837 - val_accuracy: 0.9764 - val_loss: 0.0810\n",
      "Epoch 406/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9400 - loss: 0.1742 - val_accuracy: 0.9768 - val_loss: 0.0816\n",
      "Epoch 407/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 28ms/step - accuracy: 0.9365 - loss: 0.1833 - val_accuracy: 0.9768 - val_loss: 0.0800\n",
      "Epoch 408/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9390 - loss: 0.1784 - val_accuracy: 0.9772 - val_loss: 0.0809\n",
      "Epoch 409/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9405 - loss: 0.1749 - val_accuracy: 0.9770 - val_loss: 0.0803\n",
      "Epoch 410/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9395 - loss: 0.1803 - val_accuracy: 0.9767 - val_loss: 0.0805\n",
      "Epoch 411/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9377 - loss: 0.1778 - val_accuracy: 0.9764 - val_loss: 0.0803\n",
      "Epoch 412/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9382 - loss: 0.1782 - val_accuracy: 0.9775 - val_loss: 0.0797\n",
      "Epoch 413/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9388 - loss: 0.1774 - val_accuracy: 0.9765 - val_loss: 0.0800\n",
      "Epoch 414/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9413 - loss: 0.1711 - val_accuracy: 0.9777 - val_loss: 0.0791\n",
      "Epoch 415/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9401 - loss: 0.1751 - val_accuracy: 0.9773 - val_loss: 0.0807\n",
      "Epoch 416/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9431 - loss: 0.1717 - val_accuracy: 0.9770 - val_loss: 0.0804\n",
      "Epoch 417/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9384 - loss: 0.1791 - val_accuracy: 0.9767 - val_loss: 0.0786\n",
      "Epoch 418/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9389 - loss: 0.1761 - val_accuracy: 0.9768 - val_loss: 0.0794\n",
      "Epoch 419/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9384 - loss: 0.1780 - val_accuracy: 0.9770 - val_loss: 0.0791\n",
      "Epoch 420/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9396 - loss: 0.1800 - val_accuracy: 0.9772 - val_loss: 0.0783\n",
      "Epoch 421/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9399 - loss: 0.1751 - val_accuracy: 0.9765 - val_loss: 0.0798\n",
      "Epoch 422/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9426 - loss: 0.1723 - val_accuracy: 0.9769 - val_loss: 0.0789\n",
      "Epoch 423/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9423 - loss: 0.1717 - val_accuracy: 0.9764 - val_loss: 0.0800\n",
      "Epoch 424/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9399 - loss: 0.1826 - val_accuracy: 0.9761 - val_loss: 0.0798\n",
      "Epoch 425/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9413 - loss: 0.1709 - val_accuracy: 0.9768 - val_loss: 0.0797\n",
      "Epoch 426/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9377 - loss: 0.1790 - val_accuracy: 0.9763 - val_loss: 0.0797\n",
      "Epoch 427/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9368 - loss: 0.1773 - val_accuracy: 0.9765 - val_loss: 0.0782\n",
      "Epoch 428/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9390 - loss: 0.1794 - val_accuracy: 0.9772 - val_loss: 0.0789\n",
      "Epoch 429/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9405 - loss: 0.1738 - val_accuracy: 0.9768 - val_loss: 0.0785\n",
      "Epoch 430/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9408 - loss: 0.1731 - val_accuracy: 0.9768 - val_loss: 0.0785\n",
      "Epoch 431/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9389 - loss: 0.1767 - val_accuracy: 0.9773 - val_loss: 0.0790\n",
      "Epoch 432/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9392 - loss: 0.1746 - val_accuracy: 0.9761 - val_loss: 0.0790\n",
      "Epoch 433/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.9412 - loss: 0.1688 - val_accuracy: 0.9774 - val_loss: 0.0772\n",
      "Epoch 434/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9419 - loss: 0.1748 - val_accuracy: 0.9770 - val_loss: 0.0766\n",
      "Epoch 435/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9433 - loss: 0.1671 - val_accuracy: 0.9773 - val_loss: 0.0777\n",
      "Epoch 436/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9436 - loss: 0.1691 - val_accuracy: 0.9764 - val_loss: 0.0787\n",
      "Epoch 437/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.9415 - loss: 0.1723 - val_accuracy: 0.9769 - val_loss: 0.0771\n",
      "Epoch 438/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9379 - loss: 0.1812 - val_accuracy: 0.9763 - val_loss: 0.0776\n",
      "Epoch 439/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.9422 - loss: 0.1675 - val_accuracy: 0.9770 - val_loss: 0.0768\n",
      "Epoch 440/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9394 - loss: 0.1762 - val_accuracy: 0.9767 - val_loss: 0.0781\n",
      "Epoch 441/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9402 - loss: 0.1682 - val_accuracy: 0.9768 - val_loss: 0.0785\n",
      "Epoch 442/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.9398 - loss: 0.1741 - val_accuracy: 0.9777 - val_loss: 0.0777\n",
      "Epoch 443/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9385 - loss: 0.1766 - val_accuracy: 0.9767 - val_loss: 0.0773\n",
      "Epoch 444/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.9387 - loss: 0.1740 - val_accuracy: 0.9768 - val_loss: 0.0786\n",
      "Epoch 445/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9418 - loss: 0.1725 - val_accuracy: 0.9763 - val_loss: 0.0796\n",
      "Epoch 446/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9435 - loss: 0.1653 - val_accuracy: 0.9758 - val_loss: 0.0790\n",
      "Epoch 447/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9422 - loss: 0.1719 - val_accuracy: 0.9761 - val_loss: 0.0801\n",
      "Epoch 448/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9422 - loss: 0.1721 - val_accuracy: 0.9773 - val_loss: 0.0768\n",
      "Epoch 449/700\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.9422 - loss: 0.1728 - val_accuracy: 0.9777 - val_loss: 0.0769\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with Adam optimizer\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=700,  # Increased epochs\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.9793 - loss: 0.0572\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9799 - loss: 0.0715\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9671 - loss: 0.0942\n",
      "Training Accuracy: 97.95%\n",
      "Validation Accuracy: 97.70%\n",
      "Test Accuracy: 96.82%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Convert numeric predictions back to emotion labels\n",
    "y_test_pred_labels = le.inverse_transform(y_test_pred_classes)\n",
    "y_test_true_labels = le.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with emotion labels: 96.82%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate and print accuracy\n",
    "test_acc = accuracy_score(y_test_true_labels, y_test_pred_labels)\n",
    "print(f\"Test Accuracy with emotion labels: {test_acc * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
