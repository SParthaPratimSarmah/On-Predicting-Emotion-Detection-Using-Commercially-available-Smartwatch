{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 23:18:39.257849: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-04 23:18:39.385232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-04 23:18:39.498408: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-04 23:18:39.520505: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-04 23:18:39.573410: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 23:18:43.888359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in dataset:\n",
      " id                       0\n",
      "date                     0\n",
      "nightly_temperature      0\n",
      "nremhr                   0\n",
      "rmssd                    0\n",
      "                        ..\n",
      "WORK/SCHOOL              0\n",
      "positive_affect_score    0\n",
      "negative_affect_score    0\n",
      "stai_stress              0\n",
      "Emotions                 0\n",
      "Length: 67, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fac/krishnandu/.local/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-04 23:18:47.329336: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.3479 - loss: 1.8591 - val_accuracy: 0.5894 - val_loss: 1.2118\n",
      "Epoch 2/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.5179 - loss: 1.3072 - val_accuracy: 0.6569 - val_loss: 1.0327\n",
      "Epoch 3/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.5770 - loss: 1.1528 - val_accuracy: 0.6865 - val_loss: 0.9112\n",
      "Epoch 4/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.6039 - loss: 1.0687 - val_accuracy: 0.7177 - val_loss: 0.8444\n",
      "Epoch 5/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6266 - loss: 0.9977 - val_accuracy: 0.7294 - val_loss: 0.7926\n",
      "Epoch 6/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6405 - loss: 0.9582 - val_accuracy: 0.7467 - val_loss: 0.7589\n",
      "Epoch 7/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.6630 - loss: 0.9094 - val_accuracy: 0.7540 - val_loss: 0.7155\n",
      "Epoch 8/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6723 - loss: 0.8781 - val_accuracy: 0.7687 - val_loss: 0.6795\n",
      "Epoch 9/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6803 - loss: 0.8477 - val_accuracy: 0.7834 - val_loss: 0.6500\n",
      "Epoch 10/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6911 - loss: 0.8334 - val_accuracy: 0.7938 - val_loss: 0.6245\n",
      "Epoch 11/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6944 - loss: 0.8157 - val_accuracy: 0.7886 - val_loss: 0.5988\n",
      "Epoch 12/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7000 - loss: 0.7952 - val_accuracy: 0.8077 - val_loss: 0.5771\n",
      "Epoch 13/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7172 - loss: 0.7685 - val_accuracy: 0.8181 - val_loss: 0.5670\n",
      "Epoch 14/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7223 - loss: 0.7513 - val_accuracy: 0.8196 - val_loss: 0.5368\n",
      "Epoch 15/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7272 - loss: 0.7393 - val_accuracy: 0.8317 - val_loss: 0.5281\n",
      "Epoch 16/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.7303 - loss: 0.7230 - val_accuracy: 0.8344 - val_loss: 0.5054\n",
      "Epoch 17/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7314 - loss: 0.7238 - val_accuracy: 0.8392 - val_loss: 0.5083\n",
      "Epoch 18/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7387 - loss: 0.7068 - val_accuracy: 0.8440 - val_loss: 0.4815\n",
      "Epoch 19/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.7394 - loss: 0.7012 - val_accuracy: 0.8491 - val_loss: 0.4755\n",
      "Epoch 20/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7434 - loss: 0.6902 - val_accuracy: 0.8486 - val_loss: 0.4613\n",
      "Epoch 21/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7454 - loss: 0.6916 - val_accuracy: 0.8478 - val_loss: 0.4517\n",
      "Epoch 22/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.7521 - loss: 0.6724 - val_accuracy: 0.8493 - val_loss: 0.4475\n",
      "Epoch 23/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7538 - loss: 0.6634 - val_accuracy: 0.8621 - val_loss: 0.4395\n",
      "Epoch 24/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7561 - loss: 0.6553 - val_accuracy: 0.8617 - val_loss: 0.4298\n",
      "Epoch 25/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7618 - loss: 0.6464 - val_accuracy: 0.8653 - val_loss: 0.4126\n",
      "Epoch 26/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7614 - loss: 0.6466 - val_accuracy: 0.8636 - val_loss: 0.4148\n",
      "Epoch 27/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7707 - loss: 0.6134 - val_accuracy: 0.8682 - val_loss: 0.4125\n",
      "Epoch 28/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7700 - loss: 0.6226 - val_accuracy: 0.8694 - val_loss: 0.4015\n",
      "Epoch 29/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7655 - loss: 0.6263 - val_accuracy: 0.8750 - val_loss: 0.3987\n",
      "Epoch 30/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7688 - loss: 0.6190 - val_accuracy: 0.8751 - val_loss: 0.3963\n",
      "Epoch 31/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7723 - loss: 0.6136 - val_accuracy: 0.8701 - val_loss: 0.3864\n",
      "Epoch 32/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7735 - loss: 0.6120 - val_accuracy: 0.8723 - val_loss: 0.3875\n",
      "Epoch 33/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7746 - loss: 0.6146 - val_accuracy: 0.8739 - val_loss: 0.3740\n",
      "Epoch 34/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7742 - loss: 0.6074 - val_accuracy: 0.8766 - val_loss: 0.3697\n",
      "Epoch 35/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7834 - loss: 0.5792 - val_accuracy: 0.8747 - val_loss: 0.3694\n",
      "Epoch 36/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7788 - loss: 0.5906 - val_accuracy: 0.8817 - val_loss: 0.3634\n",
      "Epoch 37/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7774 - loss: 0.5926 - val_accuracy: 0.8775 - val_loss: 0.3714\n",
      "Epoch 38/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7835 - loss: 0.5835 - val_accuracy: 0.8787 - val_loss: 0.3631\n",
      "Epoch 39/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.7805 - loss: 0.5890 - val_accuracy: 0.8816 - val_loss: 0.3591\n",
      "Epoch 40/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7851 - loss: 0.5801 - val_accuracy: 0.8834 - val_loss: 0.3593\n",
      "Epoch 41/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7841 - loss: 0.5764 - val_accuracy: 0.8854 - val_loss: 0.3570\n",
      "Epoch 42/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7842 - loss: 0.5739 - val_accuracy: 0.8893 - val_loss: 0.3429\n",
      "Epoch 43/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7856 - loss: 0.5709 - val_accuracy: 0.8835 - val_loss: 0.3458\n",
      "Epoch 44/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7895 - loss: 0.5664 - val_accuracy: 0.8903 - val_loss: 0.3440\n",
      "Epoch 45/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7902 - loss: 0.5649 - val_accuracy: 0.8902 - val_loss: 0.3336\n",
      "Epoch 46/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7922 - loss: 0.5709 - val_accuracy: 0.8921 - val_loss: 0.3340\n",
      "Epoch 47/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.7921 - loss: 0.5603 - val_accuracy: 0.8918 - val_loss: 0.3395\n",
      "Epoch 48/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7954 - loss: 0.5451 - val_accuracy: 0.8951 - val_loss: 0.3289\n",
      "Epoch 49/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7918 - loss: 0.5572 - val_accuracy: 0.8979 - val_loss: 0.3242\n",
      "Epoch 50/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7957 - loss: 0.5502 - val_accuracy: 0.8937 - val_loss: 0.3216\n",
      "Epoch 51/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7971 - loss: 0.5531 - val_accuracy: 0.8905 - val_loss: 0.3298\n",
      "Epoch 52/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7955 - loss: 0.5493 - val_accuracy: 0.8968 - val_loss: 0.3195\n",
      "Epoch 53/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.7977 - loss: 0.5363 - val_accuracy: 0.8973 - val_loss: 0.3154\n",
      "Epoch 54/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8002 - loss: 0.5386 - val_accuracy: 0.8965 - val_loss: 0.3187\n",
      "Epoch 55/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.7953 - loss: 0.5384 - val_accuracy: 0.8916 - val_loss: 0.3241\n",
      "Epoch 56/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7995 - loss: 0.5385 - val_accuracy: 0.8912 - val_loss: 0.3212\n",
      "Epoch 57/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8007 - loss: 0.5308 - val_accuracy: 0.8960 - val_loss: 0.3132\n",
      "Epoch 58/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7988 - loss: 0.5405 - val_accuracy: 0.8976 - val_loss: 0.3141\n",
      "Epoch 59/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8035 - loss: 0.5399 - val_accuracy: 0.9014 - val_loss: 0.3123\n",
      "Epoch 60/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7996 - loss: 0.5415 - val_accuracy: 0.9034 - val_loss: 0.3026\n",
      "Epoch 61/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8002 - loss: 0.5254 - val_accuracy: 0.9014 - val_loss: 0.3071\n",
      "Epoch 62/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.8053 - loss: 0.5227 - val_accuracy: 0.9029 - val_loss: 0.2984\n",
      "Epoch 63/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8089 - loss: 0.5163 - val_accuracy: 0.9038 - val_loss: 0.3049\n",
      "Epoch 64/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8080 - loss: 0.5192 - val_accuracy: 0.9061 - val_loss: 0.2966\n",
      "Epoch 65/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8083 - loss: 0.5119 - val_accuracy: 0.9018 - val_loss: 0.2922\n",
      "Epoch 66/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8055 - loss: 0.5250 - val_accuracy: 0.9088 - val_loss: 0.2951\n",
      "Epoch 67/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8082 - loss: 0.5085 - val_accuracy: 0.9048 - val_loss: 0.2969\n",
      "Epoch 68/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8073 - loss: 0.5212 - val_accuracy: 0.9025 - val_loss: 0.2992\n",
      "Epoch 69/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8080 - loss: 0.5225 - val_accuracy: 0.9032 - val_loss: 0.2939\n",
      "Epoch 70/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8052 - loss: 0.5134 - val_accuracy: 0.9102 - val_loss: 0.2853\n",
      "Epoch 71/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8093 - loss: 0.5108 - val_accuracy: 0.9041 - val_loss: 0.2937\n",
      "Epoch 72/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8167 - loss: 0.5034 - val_accuracy: 0.9127 - val_loss: 0.2873\n",
      "Epoch 73/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8115 - loss: 0.5039 - val_accuracy: 0.9081 - val_loss: 0.2851\n",
      "Epoch 74/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8099 - loss: 0.5003 - val_accuracy: 0.9078 - val_loss: 0.2850\n",
      "Epoch 75/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8125 - loss: 0.5088 - val_accuracy: 0.9092 - val_loss: 0.2761\n",
      "Epoch 76/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8178 - loss: 0.4938 - val_accuracy: 0.9109 - val_loss: 0.2749\n",
      "Epoch 77/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8151 - loss: 0.5040 - val_accuracy: 0.9113 - val_loss: 0.2853\n",
      "Epoch 78/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8143 - loss: 0.4952 - val_accuracy: 0.9154 - val_loss: 0.2805\n",
      "Epoch 79/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8135 - loss: 0.4996 - val_accuracy: 0.9131 - val_loss: 0.2749\n",
      "Epoch 80/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8197 - loss: 0.4908 - val_accuracy: 0.9144 - val_loss: 0.2709\n",
      "Epoch 81/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8146 - loss: 0.5016 - val_accuracy: 0.9189 - val_loss: 0.2745\n",
      "Epoch 82/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.8207 - loss: 0.4915 - val_accuracy: 0.9167 - val_loss: 0.2740\n",
      "Epoch 83/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8120 - loss: 0.4959 - val_accuracy: 0.9090 - val_loss: 0.2746\n",
      "Epoch 84/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8233 - loss: 0.4959 - val_accuracy: 0.9144 - val_loss: 0.2733\n",
      "Epoch 85/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8180 - loss: 0.4973 - val_accuracy: 0.9121 - val_loss: 0.2734\n",
      "Epoch 86/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8193 - loss: 0.4855 - val_accuracy: 0.9149 - val_loss: 0.2690\n",
      "Epoch 87/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8117 - loss: 0.4976 - val_accuracy: 0.9169 - val_loss: 0.2661\n",
      "Epoch 88/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8184 - loss: 0.4901 - val_accuracy: 0.9161 - val_loss: 0.2713\n",
      "Epoch 89/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8195 - loss: 0.4903 - val_accuracy: 0.9203 - val_loss: 0.2674\n",
      "Epoch 90/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8215 - loss: 0.4782 - val_accuracy: 0.9212 - val_loss: 0.2612\n",
      "Epoch 91/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8180 - loss: 0.4881 - val_accuracy: 0.9203 - val_loss: 0.2636\n",
      "Epoch 92/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8168 - loss: 0.4860 - val_accuracy: 0.9227 - val_loss: 0.2625\n",
      "Epoch 93/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8225 - loss: 0.4788 - val_accuracy: 0.9220 - val_loss: 0.2569\n",
      "Epoch 94/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8217 - loss: 0.4792 - val_accuracy: 0.9206 - val_loss: 0.2587\n",
      "Epoch 95/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8212 - loss: 0.4807 - val_accuracy: 0.9229 - val_loss: 0.2586\n",
      "Epoch 96/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8241 - loss: 0.4813 - val_accuracy: 0.9226 - val_loss: 0.2530\n",
      "Epoch 97/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8242 - loss: 0.4718 - val_accuracy: 0.9187 - val_loss: 0.2497\n",
      "Epoch 98/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8216 - loss: 0.4771 - val_accuracy: 0.9191 - val_loss: 0.2599\n",
      "Epoch 99/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8263 - loss: 0.4735 - val_accuracy: 0.9196 - val_loss: 0.2575\n",
      "Epoch 100/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8274 - loss: 0.4706 - val_accuracy: 0.9161 - val_loss: 0.2629\n",
      "Epoch 101/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8227 - loss: 0.4884 - val_accuracy: 0.9236 - val_loss: 0.2527\n",
      "Epoch 102/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8252 - loss: 0.4831 - val_accuracy: 0.9201 - val_loss: 0.2594\n",
      "Epoch 103/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8238 - loss: 0.4784 - val_accuracy: 0.9212 - val_loss: 0.2547\n",
      "Epoch 104/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8259 - loss: 0.4728 - val_accuracy: 0.9167 - val_loss: 0.2577\n",
      "Epoch 105/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8277 - loss: 0.4698 - val_accuracy: 0.9215 - val_loss: 0.2499\n",
      "Epoch 106/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8237 - loss: 0.4736 - val_accuracy: 0.9233 - val_loss: 0.2534\n",
      "Epoch 107/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8224 - loss: 0.4784 - val_accuracy: 0.9190 - val_loss: 0.2550\n",
      "Epoch 108/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.8288 - loss: 0.4629 - val_accuracy: 0.9236 - val_loss: 0.2528\n",
      "Epoch 109/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8287 - loss: 0.4663 - val_accuracy: 0.9228 - val_loss: 0.2446\n",
      "Epoch 110/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8279 - loss: 0.4642 - val_accuracy: 0.9275 - val_loss: 0.2384\n",
      "Epoch 111/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8317 - loss: 0.4606 - val_accuracy: 0.9270 - val_loss: 0.2425\n",
      "Epoch 112/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8305 - loss: 0.4558 - val_accuracy: 0.9226 - val_loss: 0.2496\n",
      "Epoch 113/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8274 - loss: 0.4690 - val_accuracy: 0.9233 - val_loss: 0.2489\n",
      "Epoch 114/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8251 - loss: 0.4765 - val_accuracy: 0.9251 - val_loss: 0.2456\n",
      "Epoch 115/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8294 - loss: 0.4584 - val_accuracy: 0.9212 - val_loss: 0.2454\n",
      "Epoch 116/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8323 - loss: 0.4492 - val_accuracy: 0.9205 - val_loss: 0.2455\n",
      "Epoch 117/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8271 - loss: 0.4695 - val_accuracy: 0.9255 - val_loss: 0.2370\n",
      "Epoch 118/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8288 - loss: 0.4687 - val_accuracy: 0.9255 - val_loss: 0.2434\n",
      "Epoch 119/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.4585 - val_accuracy: 0.9214 - val_loss: 0.2455\n",
      "Epoch 120/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8277 - loss: 0.4699 - val_accuracy: 0.9201 - val_loss: 0.2391\n",
      "Epoch 121/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8332 - loss: 0.4502 - val_accuracy: 0.9177 - val_loss: 0.2523\n",
      "Epoch 122/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8288 - loss: 0.4640 - val_accuracy: 0.9347 - val_loss: 0.2369\n",
      "Epoch 123/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8364 - loss: 0.4480 - val_accuracy: 0.9250 - val_loss: 0.2361\n",
      "Epoch 124/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8317 - loss: 0.4514 - val_accuracy: 0.9247 - val_loss: 0.2450\n",
      "Epoch 125/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8341 - loss: 0.4549 - val_accuracy: 0.9300 - val_loss: 0.2365\n",
      "Epoch 126/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8330 - loss: 0.4566 - val_accuracy: 0.9254 - val_loss: 0.2350\n",
      "Epoch 127/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8369 - loss: 0.4439 - val_accuracy: 0.9265 - val_loss: 0.2340\n",
      "Epoch 128/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8308 - loss: 0.4674 - val_accuracy: 0.9218 - val_loss: 0.2484\n",
      "Epoch 129/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8381 - loss: 0.4441 - val_accuracy: 0.9291 - val_loss: 0.2352\n",
      "Epoch 130/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8316 - loss: 0.4560 - val_accuracy: 0.9286 - val_loss: 0.2368\n",
      "Epoch 131/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8332 - loss: 0.4564 - val_accuracy: 0.9196 - val_loss: 0.2459\n",
      "Epoch 132/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8311 - loss: 0.4571 - val_accuracy: 0.9270 - val_loss: 0.2359\n",
      "Epoch 133/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8363 - loss: 0.4455 - val_accuracy: 0.9254 - val_loss: 0.2374\n",
      "Epoch 134/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8357 - loss: 0.4508 - val_accuracy: 0.9280 - val_loss: 0.2357\n",
      "Epoch 135/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8321 - loss: 0.4566 - val_accuracy: 0.9291 - val_loss: 0.2285\n",
      "Epoch 136/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8395 - loss: 0.4384 - val_accuracy: 0.9282 - val_loss: 0.2280\n",
      "Epoch 137/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8410 - loss: 0.4414 - val_accuracy: 0.9292 - val_loss: 0.2310\n",
      "Epoch 138/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8358 - loss: 0.4480 - val_accuracy: 0.9229 - val_loss: 0.2351\n",
      "Epoch 139/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8331 - loss: 0.4524 - val_accuracy: 0.9307 - val_loss: 0.2325\n",
      "Epoch 140/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8350 - loss: 0.4400 - val_accuracy: 0.9278 - val_loss: 0.2278\n",
      "Epoch 141/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8406 - loss: 0.4296 - val_accuracy: 0.9273 - val_loss: 0.2318\n",
      "Epoch 142/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8354 - loss: 0.4549 - val_accuracy: 0.9269 - val_loss: 0.2309\n",
      "Epoch 143/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8394 - loss: 0.4379 - val_accuracy: 0.9297 - val_loss: 0.2273\n",
      "Epoch 144/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8377 - loss: 0.4458 - val_accuracy: 0.9297 - val_loss: 0.2285\n",
      "Epoch 145/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8376 - loss: 0.4423 - val_accuracy: 0.9261 - val_loss: 0.2300\n",
      "Epoch 146/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8377 - loss: 0.4448 - val_accuracy: 0.9269 - val_loss: 0.2282\n",
      "Epoch 147/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8401 - loss: 0.4398 - val_accuracy: 0.9335 - val_loss: 0.2253\n",
      "Epoch 148/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8336 - loss: 0.4587 - val_accuracy: 0.9296 - val_loss: 0.2268\n",
      "Epoch 149/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8438 - loss: 0.4400 - val_accuracy: 0.9287 - val_loss: 0.2281\n",
      "Epoch 150/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8387 - loss: 0.4326 - val_accuracy: 0.9270 - val_loss: 0.2250\n",
      "Epoch 151/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8350 - loss: 0.4522 - val_accuracy: 0.9302 - val_loss: 0.2229\n",
      "Epoch 152/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8400 - loss: 0.4399 - val_accuracy: 0.9316 - val_loss: 0.2223\n",
      "Epoch 153/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8392 - loss: 0.4355 - val_accuracy: 0.9337 - val_loss: 0.2228\n",
      "Epoch 154/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8383 - loss: 0.4418 - val_accuracy: 0.9264 - val_loss: 0.2210\n",
      "Epoch 155/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8432 - loss: 0.4293 - val_accuracy: 0.9192 - val_loss: 0.2262\n",
      "Epoch 156/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8430 - loss: 0.4347 - val_accuracy: 0.9260 - val_loss: 0.2352\n",
      "Epoch 157/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8406 - loss: 0.4391 - val_accuracy: 0.9330 - val_loss: 0.2220\n",
      "Epoch 158/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8395 - loss: 0.4366 - val_accuracy: 0.9252 - val_loss: 0.2218\n",
      "Epoch 159/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8406 - loss: 0.4370 - val_accuracy: 0.9195 - val_loss: 0.2324\n",
      "Epoch 160/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8403 - loss: 0.4253 - val_accuracy: 0.9301 - val_loss: 0.2249\n",
      "Epoch 161/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8418 - loss: 0.4331 - val_accuracy: 0.9338 - val_loss: 0.2207\n",
      "Epoch 162/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8393 - loss: 0.4276 - val_accuracy: 0.9335 - val_loss: 0.2221\n",
      "Epoch 163/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8448 - loss: 0.4267 - val_accuracy: 0.9292 - val_loss: 0.2239\n",
      "Epoch 164/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8443 - loss: 0.4275 - val_accuracy: 0.9356 - val_loss: 0.2183\n",
      "Epoch 165/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8387 - loss: 0.4328 - val_accuracy: 0.9310 - val_loss: 0.2237\n",
      "Epoch 166/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8367 - loss: 0.4440 - val_accuracy: 0.9296 - val_loss: 0.2190\n",
      "Epoch 167/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8430 - loss: 0.4321 - val_accuracy: 0.9305 - val_loss: 0.2168\n",
      "Epoch 168/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8439 - loss: 0.4294 - val_accuracy: 0.9284 - val_loss: 0.2201\n",
      "Epoch 169/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8426 - loss: 0.4358 - val_accuracy: 0.9371 - val_loss: 0.2168\n",
      "Epoch 170/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8390 - loss: 0.4369 - val_accuracy: 0.9362 - val_loss: 0.2139\n",
      "Epoch 171/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8460 - loss: 0.4162 - val_accuracy: 0.9279 - val_loss: 0.2223\n",
      "Epoch 172/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8398 - loss: 0.4343 - val_accuracy: 0.9363 - val_loss: 0.2138\n",
      "Epoch 173/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8423 - loss: 0.4265 - val_accuracy: 0.9307 - val_loss: 0.2214\n",
      "Epoch 174/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8461 - loss: 0.4259 - val_accuracy: 0.9370 - val_loss: 0.2134\n",
      "Epoch 175/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8438 - loss: 0.4299 - val_accuracy: 0.9335 - val_loss: 0.2136\n",
      "Epoch 176/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8470 - loss: 0.4259 - val_accuracy: 0.9362 - val_loss: 0.2078\n",
      "Epoch 177/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8481 - loss: 0.4165 - val_accuracy: 0.9395 - val_loss: 0.2132\n",
      "Epoch 178/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8413 - loss: 0.4352 - val_accuracy: 0.9329 - val_loss: 0.2094\n",
      "Epoch 179/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8437 - loss: 0.4250 - val_accuracy: 0.9274 - val_loss: 0.2077\n",
      "Epoch 180/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8463 - loss: 0.4304 - val_accuracy: 0.9386 - val_loss: 0.2104\n",
      "Epoch 181/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8477 - loss: 0.4197 - val_accuracy: 0.9363 - val_loss: 0.2000\n",
      "Epoch 182/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8444 - loss: 0.4338 - val_accuracy: 0.9374 - val_loss: 0.2071\n",
      "Epoch 183/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8436 - loss: 0.4240 - val_accuracy: 0.9361 - val_loss: 0.2099\n",
      "Epoch 184/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8480 - loss: 0.4170 - val_accuracy: 0.9324 - val_loss: 0.2108\n",
      "Epoch 185/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8488 - loss: 0.4147 - val_accuracy: 0.9398 - val_loss: 0.2100\n",
      "Epoch 186/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8480 - loss: 0.4115 - val_accuracy: 0.9376 - val_loss: 0.2032\n",
      "Epoch 187/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8483 - loss: 0.4209 - val_accuracy: 0.9330 - val_loss: 0.2155\n",
      "Epoch 188/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8422 - loss: 0.4221 - val_accuracy: 0.9338 - val_loss: 0.2120\n",
      "Epoch 189/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8508 - loss: 0.4117 - val_accuracy: 0.9246 - val_loss: 0.2149\n",
      "Epoch 190/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8473 - loss: 0.4196 - val_accuracy: 0.9335 - val_loss: 0.2067\n",
      "Epoch 191/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8501 - loss: 0.4211 - val_accuracy: 0.9376 - val_loss: 0.2109\n",
      "Epoch 192/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8470 - loss: 0.4205 - val_accuracy: 0.9288 - val_loss: 0.2087\n",
      "Epoch 193/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - accuracy: 0.8457 - loss: 0.4230 - val_accuracy: 0.9372 - val_loss: 0.2039\n",
      "Epoch 194/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8503 - loss: 0.4124 - val_accuracy: 0.9300 - val_loss: 0.2071\n",
      "Epoch 195/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8552 - loss: 0.4097 - val_accuracy: 0.9377 - val_loss: 0.2032\n",
      "Epoch 196/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8490 - loss: 0.4174 - val_accuracy: 0.9325 - val_loss: 0.2077\n",
      "Epoch 197/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8448 - loss: 0.4209 - val_accuracy: 0.9393 - val_loss: 0.2031\n",
      "Epoch 198/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8463 - loss: 0.4212 - val_accuracy: 0.9340 - val_loss: 0.2061\n",
      "Epoch 199/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8504 - loss: 0.4115 - val_accuracy: 0.9384 - val_loss: 0.2011\n",
      "Epoch 200/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8453 - loss: 0.4222 - val_accuracy: 0.9367 - val_loss: 0.2050\n",
      "Epoch 201/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8494 - loss: 0.4096 - val_accuracy: 0.9340 - val_loss: 0.2047\n",
      "Epoch 202/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8512 - loss: 0.4125 - val_accuracy: 0.9368 - val_loss: 0.2066\n",
      "Epoch 203/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8545 - loss: 0.4108 - val_accuracy: 0.9353 - val_loss: 0.1986\n",
      "Epoch 204/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8496 - loss: 0.4143 - val_accuracy: 0.9409 - val_loss: 0.2007\n",
      "Epoch 205/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8517 - loss: 0.4126 - val_accuracy: 0.9375 - val_loss: 0.2057\n",
      "Epoch 206/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8468 - loss: 0.4208 - val_accuracy: 0.9379 - val_loss: 0.2046\n",
      "Epoch 207/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8518 - loss: 0.4218 - val_accuracy: 0.9422 - val_loss: 0.1985\n",
      "Epoch 208/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8494 - loss: 0.4270 - val_accuracy: 0.9370 - val_loss: 0.2028\n",
      "Epoch 209/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8492 - loss: 0.4163 - val_accuracy: 0.9398 - val_loss: 0.2022\n",
      "Epoch 210/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8518 - loss: 0.4119 - val_accuracy: 0.9375 - val_loss: 0.1975\n",
      "Epoch 211/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8520 - loss: 0.4082 - val_accuracy: 0.9463 - val_loss: 0.1922\n",
      "Epoch 212/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8557 - loss: 0.4015 - val_accuracy: 0.9411 - val_loss: 0.1962\n",
      "Epoch 213/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8536 - loss: 0.4066 - val_accuracy: 0.9400 - val_loss: 0.1970\n",
      "Epoch 214/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8539 - loss: 0.4051 - val_accuracy: 0.9390 - val_loss: 0.1937\n",
      "Epoch 215/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8550 - loss: 0.4068 - val_accuracy: 0.9398 - val_loss: 0.1957\n",
      "Epoch 216/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8546 - loss: 0.4054 - val_accuracy: 0.9391 - val_loss: 0.1935\n",
      "Epoch 217/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8534 - loss: 0.4073 - val_accuracy: 0.9455 - val_loss: 0.1923\n",
      "Epoch 218/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8605 - loss: 0.3923 - val_accuracy: 0.9441 - val_loss: 0.1936\n",
      "Epoch 219/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8535 - loss: 0.4040 - val_accuracy: 0.9414 - val_loss: 0.1970\n",
      "Epoch 220/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8557 - loss: 0.3997 - val_accuracy: 0.9314 - val_loss: 0.2021\n",
      "Epoch 221/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8510 - loss: 0.4167 - val_accuracy: 0.9380 - val_loss: 0.1981\n",
      "Epoch 222/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8513 - loss: 0.4047 - val_accuracy: 0.9471 - val_loss: 0.1922\n",
      "Epoch 223/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8556 - loss: 0.4041 - val_accuracy: 0.9403 - val_loss: 0.1913\n",
      "Epoch 224/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8551 - loss: 0.3969 - val_accuracy: 0.9399 - val_loss: 0.1885\n",
      "Epoch 225/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8563 - loss: 0.4139 - val_accuracy: 0.9399 - val_loss: 0.1936\n",
      "Epoch 226/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8527 - loss: 0.4024 - val_accuracy: 0.9384 - val_loss: 0.1958\n",
      "Epoch 227/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8574 - loss: 0.3959 - val_accuracy: 0.9460 - val_loss: 0.1919\n",
      "Epoch 228/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8568 - loss: 0.3979 - val_accuracy: 0.9391 - val_loss: 0.1977\n",
      "Epoch 229/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8559 - loss: 0.3977 - val_accuracy: 0.9430 - val_loss: 0.1885\n",
      "Epoch 230/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8582 - loss: 0.3902 - val_accuracy: 0.9453 - val_loss: 0.1894\n",
      "Epoch 231/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8551 - loss: 0.3997 - val_accuracy: 0.9293 - val_loss: 0.2113\n",
      "Epoch 232/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8513 - loss: 0.4114 - val_accuracy: 0.9361 - val_loss: 0.1993\n",
      "Epoch 233/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8516 - loss: 0.4097 - val_accuracy: 0.9428 - val_loss: 0.1929\n",
      "Epoch 234/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8545 - loss: 0.3969 - val_accuracy: 0.9432 - val_loss: 0.1904\n",
      "Epoch 235/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8485 - loss: 0.4161 - val_accuracy: 0.9454 - val_loss: 0.1899\n",
      "Epoch 236/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8522 - loss: 0.3942 - val_accuracy: 0.9455 - val_loss: 0.1871\n",
      "Epoch 237/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8551 - loss: 0.3980 - val_accuracy: 0.9418 - val_loss: 0.1938\n",
      "Epoch 238/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8547 - loss: 0.3985 - val_accuracy: 0.9418 - val_loss: 0.1923\n",
      "Epoch 239/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8534 - loss: 0.3938 - val_accuracy: 0.9442 - val_loss: 0.1910\n",
      "Epoch 240/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8534 - loss: 0.4045 - val_accuracy: 0.9431 - val_loss: 0.1883\n",
      "Epoch 241/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8575 - loss: 0.3917 - val_accuracy: 0.9422 - val_loss: 0.1886\n",
      "Epoch 242/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8589 - loss: 0.3959 - val_accuracy: 0.9400 - val_loss: 0.1904\n",
      "Epoch 243/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8514 - loss: 0.4053 - val_accuracy: 0.9418 - val_loss: 0.1920\n",
      "Epoch 244/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8540 - loss: 0.4103 - val_accuracy: 0.9434 - val_loss: 0.1846\n",
      "Epoch 245/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8556 - loss: 0.3982 - val_accuracy: 0.9449 - val_loss: 0.1848\n",
      "Epoch 246/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8544 - loss: 0.4026 - val_accuracy: 0.9411 - val_loss: 0.1870\n",
      "Epoch 247/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8565 - loss: 0.3995 - val_accuracy: 0.9444 - val_loss: 0.1848\n",
      "Epoch 248/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8550 - loss: 0.3987 - val_accuracy: 0.9379 - val_loss: 0.1938\n",
      "Epoch 249/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8573 - loss: 0.3930 - val_accuracy: 0.9439 - val_loss: 0.1886\n",
      "Epoch 250/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8589 - loss: 0.3940 - val_accuracy: 0.9455 - val_loss: 0.1848\n",
      "Epoch 251/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8621 - loss: 0.3834 - val_accuracy: 0.9456 - val_loss: 0.1885\n",
      "Epoch 252/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8562 - loss: 0.3956 - val_accuracy: 0.9353 - val_loss: 0.1948\n",
      "Epoch 253/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8577 - loss: 0.3978 - val_accuracy: 0.9432 - val_loss: 0.1886\n",
      "Epoch 254/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8587 - loss: 0.3956 - val_accuracy: 0.9445 - val_loss: 0.1866\n",
      "Epoch 255/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8565 - loss: 0.3868 - val_accuracy: 0.9463 - val_loss: 0.1797\n",
      "Epoch 256/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8543 - loss: 0.4006 - val_accuracy: 0.9418 - val_loss: 0.1863\n",
      "Epoch 257/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8573 - loss: 0.3979 - val_accuracy: 0.9432 - val_loss: 0.1871\n",
      "Epoch 258/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.8555 - loss: 0.3973 - val_accuracy: 0.9425 - val_loss: 0.1859\n",
      "Epoch 259/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8613 - loss: 0.3906 - val_accuracy: 0.9455 - val_loss: 0.1822\n",
      "Epoch 260/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8590 - loss: 0.3889 - val_accuracy: 0.9430 - val_loss: 0.1820\n",
      "Epoch 261/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8613 - loss: 0.3938 - val_accuracy: 0.9422 - val_loss: 0.1872\n",
      "Epoch 262/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8599 - loss: 0.3901 - val_accuracy: 0.9469 - val_loss: 0.1816\n",
      "Epoch 263/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8564 - loss: 0.4006 - val_accuracy: 0.9478 - val_loss: 0.1802\n",
      "Epoch 264/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8509 - loss: 0.4093 - val_accuracy: 0.9417 - val_loss: 0.1837\n",
      "Epoch 265/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8553 - loss: 0.3967 - val_accuracy: 0.9426 - val_loss: 0.1835\n",
      "Epoch 266/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8598 - loss: 0.3887 - val_accuracy: 0.9440 - val_loss: 0.1846\n",
      "Epoch 267/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8574 - loss: 0.3893 - val_accuracy: 0.9451 - val_loss: 0.1833\n",
      "Epoch 268/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8586 - loss: 0.3945 - val_accuracy: 0.9430 - val_loss: 0.1851\n",
      "Epoch 269/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8539 - loss: 0.4038 - val_accuracy: 0.9398 - val_loss: 0.1871\n",
      "Epoch 270/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8526 - loss: 0.4049 - val_accuracy: 0.9450 - val_loss: 0.1806\n",
      "Epoch 271/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8574 - loss: 0.3923 - val_accuracy: 0.9407 - val_loss: 0.1852\n",
      "Epoch 272/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8561 - loss: 0.3938 - val_accuracy: 0.9414 - val_loss: 0.1812\n",
      "Epoch 273/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8633 - loss: 0.3785 - val_accuracy: 0.9376 - val_loss: 0.1938\n",
      "Epoch 274/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8552 - loss: 0.4055 - val_accuracy: 0.9428 - val_loss: 0.1818\n",
      "Epoch 275/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8603 - loss: 0.3927 - val_accuracy: 0.9458 - val_loss: 0.1776\n",
      "Epoch 276/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8618 - loss: 0.3856 - val_accuracy: 0.9405 - val_loss: 0.1895\n",
      "Epoch 277/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8654 - loss: 0.3782 - val_accuracy: 0.9427 - val_loss: 0.1873\n",
      "Epoch 278/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8633 - loss: 0.3858 - val_accuracy: 0.9428 - val_loss: 0.1825\n",
      "Epoch 279/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8582 - loss: 0.3930 - val_accuracy: 0.9465 - val_loss: 0.1746\n",
      "Epoch 280/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8617 - loss: 0.3822 - val_accuracy: 0.9442 - val_loss: 0.1790\n",
      "Epoch 281/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8619 - loss: 0.3809 - val_accuracy: 0.9419 - val_loss: 0.1819\n",
      "Epoch 282/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8603 - loss: 0.3901 - val_accuracy: 0.9473 - val_loss: 0.1798\n",
      "Epoch 283/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8626 - loss: 0.3826 - val_accuracy: 0.9435 - val_loss: 0.1829\n",
      "Epoch 284/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8600 - loss: 0.3933 - val_accuracy: 0.9448 - val_loss: 0.1792\n",
      "Epoch 285/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8540 - loss: 0.4004 - val_accuracy: 0.9495 - val_loss: 0.1769\n",
      "Epoch 286/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8558 - loss: 0.4008 - val_accuracy: 0.9416 - val_loss: 0.1892\n",
      "Epoch 287/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8610 - loss: 0.3864 - val_accuracy: 0.9451 - val_loss: 0.1757\n",
      "Epoch 288/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8596 - loss: 0.3826 - val_accuracy: 0.9458 - val_loss: 0.1776\n",
      "Epoch 289/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8624 - loss: 0.3889 - val_accuracy: 0.9459 - val_loss: 0.1730\n",
      "Epoch 290/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8638 - loss: 0.3748 - val_accuracy: 0.9462 - val_loss: 0.1746\n",
      "Epoch 291/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8612 - loss: 0.3888 - val_accuracy: 0.9458 - val_loss: 0.1721\n",
      "Epoch 292/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8619 - loss: 0.3864 - val_accuracy: 0.9462 - val_loss: 0.1764\n",
      "Epoch 293/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8572 - loss: 0.3930 - val_accuracy: 0.9445 - val_loss: 0.1782\n",
      "Epoch 294/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8626 - loss: 0.3897 - val_accuracy: 0.9448 - val_loss: 0.1772\n",
      "Epoch 295/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8574 - loss: 0.3931 - val_accuracy: 0.9474 - val_loss: 0.1792\n",
      "Epoch 296/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8676 - loss: 0.3745 - val_accuracy: 0.9477 - val_loss: 0.1773\n",
      "Epoch 297/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8638 - loss: 0.3833 - val_accuracy: 0.9450 - val_loss: 0.1769\n",
      "Epoch 298/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8600 - loss: 0.3904 - val_accuracy: 0.9454 - val_loss: 0.1780\n",
      "Epoch 299/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8602 - loss: 0.3863 - val_accuracy: 0.9474 - val_loss: 0.1759\n",
      "Epoch 300/300\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8532 - loss: 0.4046 - val_accuracy: 0.9450 - val_loss: 0.1780\n",
      "\u001b[1m980/980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9574 - loss: 0.1471\n",
      "Training Accuracy: 0.9570\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9407 - loss: 0.1846\n",
      "Validation Accuracy: 0.9450\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9449 - loss: 0.1748\n",
      "Test Accuracy: 0.9434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Raw_MAIN_DATASET_IMPUTATION_after_deleting_stai_badge_activity_step_goal.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in dataset:\\n\", data.isnull().sum())\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "data['Emotions'] = label_encoder.fit_transform(data['Emotions'])\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(['Emotions', 'id', 'date'], axis=1)  # Drop non-numeric features\n",
    "y = data['Emotions']\n",
    "\n",
    "# Apply Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled dataset into training (64%) and temporary testing set (36%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.36, random_state=42)\n",
    "\n",
    "# Split the temporary testing set into validation (16%) and testing (20%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=20/36, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a simple feedforward neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Output layer for the number of classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=300, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "train_loss, train_accuracy = model.evaluate(X_train_scaled, y_train)\n",
    "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
